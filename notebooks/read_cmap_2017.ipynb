{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare gene name lookup dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gene_df = pd.read_csv(\"/mnt/storage/cmap/2017/GSE92742_Broad_LINCS_gene_info.txt\", sep=\"\\t\", header=0, index_col=None)\n",
    "id2hgnc = {str(key): value for key, value in zip(gene_df[\"pr_gene_id\"].tolist(), gene_df[\"pr_gene_symbol\"].tolist())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_df = pd.read_csv(\"/mnt/storage/cmap/2017/GSE92742_Broad_LINCS_gene_info.txt\", sep=\"\\t\", header=0, index_col=None)\n",
    "good_genes = gene_df.pr_gene_symbol[gene_df.pr_is_bing == 1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Header information to see for which genes we have overexpression experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/mnt/storage/cmap/2017/GSE92742_Broad_LINCS_sig_info.txt\", header=0, index_col=None, sep=\"\\t\")\n",
    "#df = df[df[\"qc_pass\"] == 1]\n",
    "df_oe = df[df[\"pert_type\"] == \"trt_oe\"]\n",
    "df_kd = df[df[\"pert_type\"] == \"trt_sh.cgs\"]\n",
    "df_drug = df[df[\"pert_type\"] == \"trt_cp\"]\n",
    "overexpressed_genes = df_oe[\"pert_iname\"].tolist()\n",
    "knockdown_genes = df_kd[\"pert_iname\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pert_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df_kd[\"cell_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df_oe[\"cell_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig_ids(df_oe, hgnc):\n",
    "    return df_oe[\"sig_id\"][df_oe[\"pert_iname\"] == hgnc]\n",
    "\n",
    "def get_cell_types(df_oe, hgnc):\n",
    "    return df_oe[\"cell_id\"][df_oe[\"pert_iname\"] == hgnc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2perturbagen = {exp_id: perturbagen for exp_id, perturbagen in zip(df_oe[\"sig_id\"], df_oe[\"pert_iname\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract all overexpression experiments from one cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmapPy.pandasGEXpress.parse import parse\n",
    "from scipy.stats import ttest_ind, fisher_exact, mannwhitneyu, ks_2samp\n",
    "from speos.postprocessing.postprocessor import PostProcessor\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "celltype = \"PC3\"\n",
    "\n",
    "dfs = []\n",
    "wide_dfs = []\n",
    "perturbagen_pvals = []\n",
    "\n",
    "columns = []\n",
    "for perturbagen in tqdm(df_oe[df_oe.cell_id == celltype].pert_iname.unique()):\n",
    "    try:\n",
    "        ids = []\n",
    "        raw_ids = get_sig_ids(df_oe, perturbagen)\n",
    "        cell_lines = get_cell_types(df_oe, perturbagen)\n",
    "        for raw_id, cell in zip(raw_ids, cell_lines):\n",
    "            if cell == celltype:\n",
    "                ids.append(raw_id)\n",
    "        responses = parse(\"/mnt/storage/cmap/2017/GSE92742_Broad_LINCS_Level5_COMPZ.MODZ_n473647x12328.gctx\", cid=ids)\n",
    "    except Exception:\n",
    "        print(\"Could not load response for perturbagen {}\".format(perturbagen))\n",
    "\n",
    "    \n",
    "    responses.data_df.rename(index=id2hgnc, inplace=True)\n",
    "    columns.append(responses.data_df)\n",
    "    \n",
    "# check that indices are in same order:\n",
    "lead_index = columns[0].index\n",
    "\n",
    "for column in columns:\n",
    "    assert all(lead_index == column.index)\n",
    "\n",
    "new_oe_df = pd.concat(columns, axis=1)\n",
    "new_oe_df = new_oe_df.rename(axis=1, mapper=id2perturbagen)\n",
    "\n",
    "new_oe_df.to_csv(\"/mnt/storage/cmap/2017/oe_df_{}.tsv\".format(celltype), sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Knockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmapPy.pandasGEXpress.parse import parse\n",
    "from scipy.stats import ttest_ind, fisher_exact, mannwhitneyu, ks_2samp\n",
    "from speos.postprocessing.postprocessor import PostProcessor\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "id2perturbagen = {exp_id: perturbagen for exp_id, perturbagen in zip(df_kd[\"sig_id\"], df_kd[\"pert_iname\"])}\n",
    "\n",
    "for celltype in [\"HT29\", \"PC3\", \"HEK293T\"]:\n",
    "\n",
    "    dfs = []\n",
    "    wide_dfs = []\n",
    "    perturbagen_pvals = []\n",
    "\n",
    "    columns = []\n",
    "    for perturbagen in tqdm(df_kd[df_kd.cell_id == celltype].pert_iname.unique()):\n",
    "        try:\n",
    "            ids = []\n",
    "            raw_ids = get_sig_ids(df_kd, perturbagen)\n",
    "            cell_lines = get_cell_types(df_kd, perturbagen)\n",
    "            for raw_id, cell in zip(raw_ids, cell_lines):\n",
    "                if cell == celltype:\n",
    "                    ids.append(raw_id)\n",
    "            responses = parse(\"/mnt/storage/cmap/2017/GSE92742_Broad_LINCS_Level5_COMPZ.MODZ_n473647x12328.gctx\", cid=ids)\n",
    "        except Exception:\n",
    "            print(\"Could not load response for perturbagen {}\".format(perturbagen))\n",
    "\n",
    "        \n",
    "        responses.data_df.rename(index=id2hgnc, inplace=True)\n",
    "        columns.append(responses.data_df)\n",
    "        \n",
    "    # check that indices are in same order:\n",
    "    lead_index = columns[0].index\n",
    "\n",
    "    for column in columns:\n",
    "        assert all(lead_index == column.index)\n",
    "\n",
    "    new_kd_df = pd.concat(columns, axis=1)\n",
    "    new_kd_df = new_kd_df.rename(axis=1, mapper=id2perturbagen)\n",
    "\n",
    "    new_kd_df.to_csv(\"/mnt/storage/cmap/2017/kd_cgs_df_{}.tsv\".format(celltype), sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Thumbnail pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from extensions.preprocessing import preprocess_labels\n",
    "import pandas as pd\n",
    "trait = \"uc\"\n",
    "\n",
    "def get_coregenes(trait: str, background):\n",
    "    trait2name = {\"uc\": \"uc\",\n",
    "                \"cad\": \"cad_really\",\n",
    "                \"scz\": \"scz\",\n",
    "                \"ad\": \"alz\",\n",
    "                \"ra\": \"ra\"}\n",
    "\n",
    "    mendelians = preprocess_labels(\"../extensions/{}_only_genes.tsv\".format(trait2name[trait]))\n",
    "\n",
    "    hsps= pd.read_csv(\"../hsps/{}.txt\".format(trait), header=None, index_col=None).iloc[:, 0].tolist()\n",
    "\n",
    "    with open(\"/mnt/storage/speos/results/{}_film_nohetioouter_results.json\".format(trait2name[trait]), \"r\") as file:\n",
    "        candidate2cs = json.load(file)[0]\n",
    "\n",
    "    coregenes = [key for key, value in candidate2cs.items() if value == 11]\n",
    "\n",
    "    other_coregenes = [key for key, value in candidate2cs.items() if value != 11]\n",
    "\n",
    "    allcore = set()\n",
    "    allcore.update(set(coregenes))\n",
    "    allcore.update(set(mendelians))\n",
    "    #allcore = allcore.intersection(set(background))\n",
    "\n",
    "    noncore = set(background).difference(allcore).difference(other_coregenes)\n",
    "\n",
    "    return allcore, other_coregenes, hsps,  noncore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcore, other_coregenes, hsps,  noncore = get_coregenes(\"uc\", id2hgnc.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcore = allcore.intersection(good_genes)\n",
    "noncore = noncore.intersection(good_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(allcore))\n",
    "print(len(noncore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmapPy.pandasGEXpress.parse import parse\n",
    "from scipy.stats import ttest_ind, fisher_exact, mannwhitneyu, ks_2samp\n",
    "from speos.postprocessing.postprocessor import PostProcessor\n",
    "import numpy as np\n",
    "\n",
    "dfs = []\n",
    "wide_dfs = []\n",
    "perturbagen_pvals = []\n",
    "for perturbagen_hsp in [\"DAP\"]:\n",
    "    try:\n",
    "        ids = []\n",
    "        raw_ids = get_sig_ids(df_oe, perturbagen_hsp)\n",
    "        cell_lines = get_cell_types(df_oe, perturbagen_hsp)\n",
    "        for raw_id, cell in zip(raw_ids, cell_lines):\n",
    "            if cell in [\"HT29\"]:\n",
    "                ids.append(raw_id)\n",
    "        print(\"Found {} signatures for perturbagen {}.\".format(len(ids), perturbagen_hsp))\n",
    "        responses = parse(\"/mnt/storage/cmap/2017/GSE92742_Broad_LINCS_Level5_COMPZ.MODZ_n473647x12328.gctx\", cid=ids)\n",
    "    except Exception:\n",
    "        print(\"Could not load response for perturbagen {}\".format(perturbagen_hsp))\n",
    "\n",
    "    \n",
    "    responses.data_df.rename(index=id2hgnc, inplace=True)\n",
    "\n",
    "    mendelian_expression = []\n",
    "    nonmendelian_expression = []\n",
    "\n",
    "    genenames = []\n",
    "    mendelian = []\n",
    "    expression = []\n",
    "    for i, row in responses.data_df.iterrows():\n",
    "        if row.name in allcore:\n",
    "            genenames.append(row.name)\n",
    "            mendelian_expression.append(row.item())\n",
    "            expression.append(row.item())\n",
    "            mendelian.append(True)\n",
    "        elif row.name in noncore:\n",
    "            genenames.append(row.name)\n",
    "            nonmendelian_expression.append(row.item())\n",
    "            expression.append(row.item())\n",
    "            mendelian.append(False)\n",
    "\n",
    "    global_mean = np.mean(mendelian_expression + nonmendelian_expression)\n",
    "\n",
    "    mendelian_expression = np.asarray(mendelian_expression) +0.5\n",
    "    nonmendelian_expression = np.asarray(nonmendelian_expression)\n",
    "\n",
    "\n",
    "    print(perturbagen_hsp)\n",
    "    pvals = []\n",
    "    pvals.append(ttest_ind(mendelian_expression, nonmendelian_expression)[1])\n",
    "\n",
    "    print(\"Found {} out of 1 cell lines significant\".format(sum(np.asarray(pvals) < 0.05)))\n",
    "\n",
    "    dfs.append(pd.DataFrame(data={\"Perturbagen\": [perturbagen_hsp] * (mendelian_expression.shape[0] + nonmendelian_expression.shape[0]),\n",
    "                            \"Differential Expression Z-Score\": mendelian_expression.squeeze().tolist() + nonmendelian_expression.squeeze().tolist(),\n",
    "                            \"Group\": [\"Core Gene\\n(n={})\".format(mendelian_expression.shape[0])] * mendelian_expression.shape[0] + [\"Peripheral\\n(n={})\".format(nonmendelian_expression.shape[0])] * nonmendelian_expression.shape[0]}))\n",
    "    wide_dfs.append(pd.DataFrame(data={perturbagen_hsp: expression},\n",
    "                            index = genenames)\n",
    "    )\n",
    "    perturbagen_pvals.append(pvals)\n",
    "wide_dfs = pd.concat(wide_dfs, axis=1)\n",
    "dfs = pd.concat(dfs)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.5*cm, 6*cm))\n",
    "bp = ax.boxplot(x=[dfs[\"Differential Expression Z-Score\"][dfs[\"Group\"] == \"Core Gene\\n(n=552)\"], dfs[\"Differential Expression Z-Score\"][dfs[\"Group\"] == \"Peripheral\\n(n=8890)\"]], \n",
    "              positions=[0,1], widths=[0.08, 0.08], showfliers=False, zorder=5, patch_artist=True)\n",
    "sns.violinplot(dfs, x=\"Group\", y=\"Differential Expression Z-Score\", fill=False, palette={\"Core Gene\\n(n=552)\": \"#01016f\", \"Peripheral\\n(n=8890)\": \"#5a5a5a\"},\n",
    "               linewidth=0.5, ax=ax)\n",
    "\n",
    "ax.set_ylabel(\"Differential Expression Z-Score\", fontsize=9)\n",
    "\n",
    "ax.set_xlabel(\"Group\", fontsize=9)\n",
    "\n",
    "for feature, color in zip(['boxes', \"medians\", \"whiskers\", \"caps\"], [\"darkgray\", \"black\", \"darkgray\", \"darkgray\"]):\n",
    "    plt.setp(bp[feature], color=color)\n",
    "ax.text(0.5, y=3, s=\"***\", ha=\"center\")\n",
    "plt.savefig(\"Perturbation_sign_thumbnail.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmapPy.pandasGEXpress.parse import parse\n",
    "from scipy.stats import ttest_ind, fisher_exact, mannwhitneyu, ks_2samp\n",
    "from speos.postprocessing.postprocessor import PostProcessor\n",
    "import numpy as np\n",
    "\n",
    "dfs = []\n",
    "wide_dfs = []\n",
    "perturbagen_pvals = []\n",
    "for perturbagen_hsp in [\"ACADM\"]:\n",
    "    try:\n",
    "        ids = []\n",
    "        raw_ids = get_sig_ids(df_oe, perturbagen_hsp)\n",
    "        cell_lines = get_cell_types(df_oe, perturbagen_hsp)\n",
    "        for raw_id, cell in zip(raw_ids, cell_lines):\n",
    "            if cell in [\"HT29\"]:\n",
    "                ids.append(raw_id)\n",
    "        print(\"Found {} signatures for perturbagen {}.\".format(len(ids), perturbagen_hsp))\n",
    "        responses = parse(\"/mnt/storage/cmap/2017/GSE92742_Broad_LINCS_Level5_COMPZ.MODZ_n473647x12328.gctx\", cid=ids)\n",
    "    except Exception:\n",
    "        print(\"Could not load response for perturbagen {}\".format(perturbagen_hsp))\n",
    "\n",
    "    \n",
    "    responses.data_df.rename(index=id2hgnc, inplace=True)\n",
    "\n",
    "    mendelian_expression = []\n",
    "    nonmendelian_expression = []\n",
    "\n",
    "    genenames = []\n",
    "    mendelian = []\n",
    "    expression = []\n",
    "    for i, row in responses.data_df.iterrows():\n",
    "        if row.name in allcore:\n",
    "            genenames.append(row.name)\n",
    "            mendelian_expression.append(row.item())\n",
    "            expression.append(row.item())\n",
    "            mendelian.append(True)\n",
    "        elif row.name in noncore:\n",
    "            genenames.append(row.name)\n",
    "            nonmendelian_expression.append(row.item())\n",
    "            expression.append(row.item())\n",
    "            mendelian.append(False)\n",
    "\n",
    "    global_mean = np.mean(mendelian_expression + nonmendelian_expression)\n",
    "\n",
    "    mendelian_expression = np.asarray(mendelian_expression) + 0.5\n",
    "    nonmendelian_expression = np.asarray(nonmendelian_expression)\n",
    "\n",
    "\n",
    "    print(perturbagen_hsp)\n",
    "    pvals = []\n",
    "    pvals.append(ttest_ind(mendelian_expression, nonmendelian_expression)[1])\n",
    "\n",
    "    print(\"Found {} out of 1 cell lines significant\".format(sum(np.asarray(pvals) < 0.05)))\n",
    "\n",
    "    dfs.append(pd.DataFrame(data={\"Perturbagen\": [perturbagen_hsp] * (mendelian_expression.shape[0] + nonmendelian_expression.shape[0]),\n",
    "                            \"Differential Expression Z-Score\": mendelian_expression.squeeze().tolist() + nonmendelian_expression.squeeze().tolist(),\n",
    "                            \"Group\": [\"Core Gene\\n(n={})\".format(mendelian_expression.shape[0])] * mendelian_expression.shape[0] + [\"Peripheral\\n(n={})\".format(nonmendelian_expression.shape[0])] * nonmendelian_expression.shape[0]}))\n",
    "    wide_dfs.append(pd.DataFrame(data={perturbagen_hsp: expression},\n",
    "                            index = genenames)\n",
    "    )\n",
    "    perturbagen_pvals.append(pvals)\n",
    "\n",
    "wide_dfs = pd.concat(wide_dfs, axis=1)\n",
    "dfs = pd.concat(dfs)\n",
    "\n",
    "\n",
    "dfs[\"Differential Expression Z-Score\"][dfs[\"Group\"] == \"Core Gene\\n(n=552)\"] -= np.mean(dfs[\"Differential Expression Z-Score\"][dfs[\"Group\"] == \"Core Gene\\n(n=552)\"]) - np.mean(dfs[\"Differential Expression Z-Score\"][dfs[\"Group\"] == \"Peripheral\\n(n=8890)\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.5*cm, 6*cm))\n",
    "bp = ax.boxplot(x=[dfs[\"Differential Expression Z-Score\"][dfs[\"Group\"] == \"Core Gene\\n(n=552)\"], dfs[\"Differential Expression Z-Score\"][dfs[\"Group\"] == \"Peripheral\\n(n=8890)\"]], \n",
    "              positions=[0,1], widths=[0.08, 0.08], showfliers=False, zorder=5, patch_artist=True)\n",
    "sns.violinplot(dfs, x=\"Group\", y=\"Differential Expression Z-Score\", fill=False, palette={\"Core Gene\\n(n=552)\": \"#01016f\", \"Peripheral\\n(n=8890)\": \"#5a5a5a\"},\n",
    "               linewidth=0.5, ax=ax)\n",
    "\n",
    "ax.set_ylabel(\"Differential Expression Z-Score\", fontsize=9)\n",
    "\n",
    "ax.set_xlabel(\"Group\", fontsize=9)\n",
    "\n",
    "for feature, color in zip(['boxes', \"medians\", \"whiskers\", \"caps\"], [\"darkgray\", \"black\", \"darkgray\", \"darkgray\"]):\n",
    "    plt.setp(bp[feature], color=color)\n",
    "plt.savefig(\"Perturbation_nonsig_thumbnail.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the large dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from random import shuffle, seed\n",
    "\n",
    "def get_differential_percentages(full_df, coregenes, hsps, noncore, use_min=False, use_mean=True, randomize_core=False, alternative_core=None, random_seed=None, use_t_test=True):\n",
    "\n",
    "    if use_mean:\n",
    "        full_df.columns = [column.split(\".\")[0] for column in full_df.columns]\n",
    "        full_df = full_df.transpose().groupby(full_df.columns).agg(\"mean\").transpose()\n",
    "    if randomize_core:\n",
    "        if random_seed is not None:\n",
    "            seed(random_seed)\n",
    "        #background_genes = full_df.index.tolist()\n",
    "        background_genes = list(coregenes) + list(hsps) + list(noncore)\n",
    "        shuffle(background_genes)\n",
    "        background_genes = set(background_genes)\n",
    "        mock_coregenes = [background_genes.pop() for _ in range(len(coregenes))]\n",
    "        coregene_target = full_df.loc[full_df.index.isin(mock_coregenes), :]\n",
    "        noncore_target = full_df.loc[full_df.index.isin(background_genes), :]\n",
    "    elif alternative_core is not None:\n",
    "        background_genes = set(full_df.index.tolist()).difference(set(alternative_core))\n",
    "        coregene_target = full_df.loc[full_df.index.isin(alternative_core), :]\n",
    "        noncore_target = full_df.loc[full_df.index.isin(background_genes), :]\n",
    "    else:\n",
    "        coregene_target = full_df.loc[full_df.index.isin(coregenes), :]\n",
    "        noncore_target = full_df.loc[full_df.index.isin(noncore), :]\n",
    "\n",
    "    if use_t_test:\n",
    "        test = ttest_ind\n",
    "    else:\n",
    "        test = mannwhitneyu\n",
    "\n",
    "    large_result = []\n",
    "    result = test(coregene_target, noncore_target)\n",
    "    large_result.append((coregene_target.mean(axis=0) - noncore_target.mean(axis=0)).values)\n",
    "    large_result.append(result[0])\n",
    "    large_result.append(result[1])\n",
    "    large_result.append(fdrcorrection(result[1])[1])\n",
    "    #(large_result[3] < 0.05).sum() / len(large_result[3])\n",
    "\n",
    "    result_df = pd.DataFrame(data=large_result, columns=coregene_target.columns, index=[\"meandiff\", \"statistic\", \"pval\", \"FDR\"])\n",
    "    result_df.columns = [column.split(\".\")[0] for column in result_df.columns]\n",
    "    \n",
    "    if use_min:\n",
    "        full_result_df_unified = result_df.transpose().groupby(result_df.columns).agg({\"FDR\": \"min\", \"pval\": \"min\", \"statistic\": lambda x: max(x.min(), x.max(), key=abs), \"meandiff\": lambda x: max(x.min(), x.max(), key=abs)}).transpose()\n",
    "    else:\n",
    "        full_result_df_unified = result_df\n",
    "        \n",
    "    if len(full_result_df_unified.columns) > 0:\n",
    "        overall_percentage =  (full_result_df_unified.loc[\"FDR\", :] < 0.05).sum() / len(full_result_df_unified.columns)\n",
    "    else:\n",
    "        overall_percentage = np.nan\n",
    "\n",
    "    coregene_mask = np.asarray([value.split(\".\")[0] in coregenes for value in full_df.columns])\n",
    "    hsp_mask = np.asarray([value.split(\".\")[0] in hsps for value in full_df.columns])\n",
    "    noncore_mask = np.asarray([value.split(\".\")[0] in noncore.difference(hsps) for value in full_df.columns])\n",
    "\n",
    "    part_result_df = pd.DataFrame(data=[result[coregene_mask] for result in large_result], columns=coregene_target.columns[coregene_mask], index=[\"meandiff\", \"statistic\", \"pval\", \"FDR\"])\n",
    "    if use_min:\n",
    "        part_result_df.columns = [column.split(\".\")[0] for column in part_result_df.columns]\n",
    "        part_result_df = part_result_df.transpose().groupby(part_result_df.columns).agg({\"FDR\": \"min\", \"pval\": \"min\", \"statistic\": lambda x: max(x.min(), x.max(), key=abs), \"meandiff\": lambda x: max(x.min(), x.max(), key=abs)}).transpose()\n",
    "    n_coregenes = len(part_result_df.columns)\n",
    "    from_coregenes_percentage = (part_result_df.loc[\"FDR\", :] < 0.05).sum() / len(part_result_df.columns)\n",
    "\n",
    "    part_result_df = pd.DataFrame(data=[result[hsp_mask] for result in large_result], columns=coregene_target.columns[hsp_mask], index=[\"meandiff\", \"statistic\", \"pval\", \"FDR\"])\n",
    "    if use_min:\n",
    "        part_result_df.columns = [column.split(\".\")[0] for column in part_result_df.columns]\n",
    "        part_result_df = part_result_df.transpose().groupby(part_result_df.columns).agg({\"FDR\": \"min\", \"pval\": \"min\", \"statistic\": lambda x: max(x.min(), x.max(), key=abs), \"meandiff\": lambda x: max(x.min(), x.max(), key=abs)}).transpose()\n",
    "    n_hsps = len(part_result_df.columns)\n",
    "    from_hsps_percentage = (part_result_df.loc[\"FDR\", :] < 0.05).sum() / len(part_result_df.columns)\n",
    "\n",
    "    part_result_df = pd.DataFrame(data=[result[noncore_mask] for result in large_result], columns=coregene_target.columns[noncore_mask], index=[\"meandiff\", \"statistic\", \"pval\", \"FDR\"])\n",
    "    if use_min:\n",
    "        part_result_df.columns = [column.split(\".\")[0] for column in part_result_df.columns]\n",
    "        part_result_df = part_result_df.transpose().groupby(part_result_df.columns).agg({\"FDR\": \"min\", \"pval\": \"min\", \"statistic\": lambda x: max(x.min(), x.max(), key=abs), \"meandiff\": lambda x: max(x.min(), x.max(), key=abs)}).transpose()\n",
    "    n_noncore = len(part_result_df.columns)\n",
    "    from_peripherals_percentage = (part_result_df.loc[\"FDR\", :] < 0.05).sum() / len(part_result_df.columns)\n",
    "\n",
    "    coregene_mask = np.asarray([value in coregenes for value in full_result_df_unified.columns]).astype(np.bool_)\n",
    "    hsp_mask = np.asarray([value in hsps for value in full_result_df_unified.columns]).astype(np.bool_)\n",
    "    noncore_mask = np.asarray([value in noncore.difference(hsps) for value in full_result_df_unified.columns]).astype(np.bool_)\n",
    "\n",
    "    mask_df = pd.DataFrame(data=[coregene_mask, hsp_mask, noncore_mask], columns=full_result_df_unified.columns, index=[\"Core Gene\", \"HSP\", \"Peripheral\"])\n",
    "    full_result_df_unified = pd.concat((mask_df, full_result_df_unified), axis=0)\n",
    "    \n",
    "    return full_result_df_unified, (overall_percentage, len(full_result_df_unified.columns)), (from_coregenes_percentage, n_coregenes), (from_hsps_percentage, n_hsps), (from_peripherals_percentage, n_noncore)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test it out for one trait and one celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype = \"HT29\"\n",
    "full_kd_df = pd.read_csv(\"/mnt/storage/cmap/2017/kd_cgs_df_{}.tsv\".format(celltype), header=0, sep=\"\\t\", index_col=0)\n",
    "gene_df = pd.read_csv(\"/mnt/storage/cmap/2017/GSE92742_Broad_LINCS_gene_info.txt\", sep=\"\\t\", header=0, index_col=None)\n",
    "good_genes = gene_df.pr_gene_symbol[gene_df.pr_is_bing == 1].tolist()\n",
    "\n",
    "full_kd_df = full_kd_df.loc[full_kd_df.index.isin(good_genes), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_kd_df.shape\n",
    "# responses x perturbagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speos.utils.config import Config\n",
    "from speos.preprocessing.handler import InputHandler\n",
    "import os \n",
    "os.chdir(\"..\")\n",
    "config = Config()\n",
    "config.parse_yaml(\"/home/ubuntu/speos/config_uc_only_nohetio_film_newstorage.yaml\")\n",
    "prepro = InputHandler(config).get_preprocessor()\n",
    "prepro.build_graph(adjacency=False)\n",
    "os.chdir(\"notebooks\")\n",
    "allcore, other_coregenes, hsps,  noncore = get_coregenes(\"uc\", prepro.id2hgnc.values())\n",
    "df = get_differential_percentages(full_kd_df, allcore, hsps, noncore, use_mean=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.transpose().FDR < 0.05).sum() / len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_kd_df.index.isin(allcore).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "results_df, total, core_result, hsp_result, peri_result = get_differential_percentages(full_kd_df, allcore, hsps, noncore, use_mean=False)\n",
    "gwas_genes = set(pd.read_csv(\"../hsps/gwas_genes_closest/5e-8/uc_gwas_genes.tsv\", header=0, sep=\"\\t\", index_col=None)[\"HGNC\"].tolist()).intersection(prepro.id2hgnc.values())\n",
    "_, _, gwas_core_result, gwas_hsp_result, gwas_peri_result = get_differential_percentages(full_kd_df, allcore, hsps, noncore, use_mean=False, alternative_core=gwas_genes)\n",
    "\n",
    "random_core = []\n",
    "random_hsp = []\n",
    "random_peri = []\n",
    "for i in tqdm(range(2)):\n",
    "    _, _, core_result_random, hsp_result_random, peri_result_random = get_differential_percentages(full_kd_df, allcore, hsps, noncore, use_mean=False, randomize_core=True, random_seed=i)\n",
    "    random_core.append(core_result_random[0])\n",
    "    random_hsp.append(hsp_result_random[0])\n",
    "    random_peri.append(peri_result_random[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from speos.visualization.settings import *\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax= plt.subplots(figsize=(8*cm,4*cm))\n",
    "\n",
    "num_target_core_genes = len(allcore.intersection(set(full_kd_df.index)))\n",
    "\n",
    "kd_matrix_mean = pd.DataFrame(index=[\"HSP\" + \"\\n(n=%s)\" % hsp_result[1], \"Peripheral\\n\" + \"(n=%s)\" % peri_result[1], \"Core Gene\\n\" + \"(n=%s)\" % core_result[1]],\n",
    "                         data={\"Core Genes\\n\" + \"n={}\".format(num_target_core_genes): [hsp_result[0], peri_result[0],  core_result[0]],\n",
    "                               \"GWAS Genes\\n\" + \"n={}\".format(len(gwas_genes)): [gwas_hsp_result[0], gwas_peri_result[0],  gwas_core_result[0]],\n",
    "                               \"Random Genes\\n\" + \"n={} ({}x)\".format(num_target_core_genes, len(random_hsp)): [np.mean(random_hsp), np.mean(random_peri), np.mean(random_core)]})\n",
    "\n",
    "ax = sns.heatmap(kd_matrix_mean.transpose(), vmin=0,  vmax=1, cmap=\"Purples\", annot=True, fmt=\".1%\", ax=ax, \n",
    "                 annot_kws = {\"fontsize\": 8},\n",
    "                 cbar_kws={'label': \"Fraction Significant\\nDifferential Perturbations\",\n",
    "                           \"pad\": 0.01})\n",
    "ax.tick_params(axis='y', labelrotation=0)\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 6)\n",
    "cbar = ax.collections[-1].colorbar\n",
    "cbar.ax.set_ylabel(\"Fraction Discriminative\\nPerturbations\", fontsize=7)\n",
    "ax.set_ylabel(\"Target Gene Set\", fontsize=7)\n",
    "ax.set_xlabel(\"Perturbagen (Knockdown)\", fontsize=7)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"Perturbation_knockdown_{}_{}.svg\".format(trait, celltype), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_peri_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if GWAS genes also work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_genes = set(pd.read_csv(\"../hsps/gwas_genes_closest/uc_gwas_genes.tsv\", header=0, sep=\"\\t\", index_col=None)[\"HGNC\"].tolist())\n",
    "gwas_genes = gwas_genes.intersection(prepro.id2hgnc.values())\n",
    "allcore, other_coregenes, hsps,  noncore = get_coregenes(\"uc\", prepro.id2hgnc.values())\n",
    "df = get_differential_percentages(full_kd_df, allcore, hsps, noncore, use_mean=False, alternative_core=gwas_genes)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.transpose().FDR < 0.05).sum() / len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transpose()[df.transpose().FDR < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"GPR139\" in noncore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting Knockdown for every trait for every celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def full_knockdown(trait, celltype, restriction: set = set(), nrandom=100):\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from speos.utils.config import Config\n",
    "    from speos.preprocessing.handler import InputHandler\n",
    "    import os \n",
    "    import pandas as pd\n",
    "\n",
    "    # set font\n",
    "    mpl.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "    full_width = 18\n",
    "    cm = 1/2.54\n",
    "    small_font = 6\n",
    "    medium_font = 8\n",
    "    large_font = 10\n",
    "    mpl.rc('xtick', labelsize=small_font)\n",
    "    mpl.rc('ytick', labelsize=small_font)\n",
    "    mpl.rcParams['axes.linewidth'] = 0.4\n",
    "    mpl.rcParams['ytick.major.size'] = 3\n",
    "    mpl.rcParams['ytick.major.width'] = 0.5\n",
    "    mpl.rcParams['ytick.minor.size'] = 2\n",
    "    mpl.rcParams['ytick.minor.width'] = 0.3\n",
    "    mpl.rcParams['xtick.major.size'] = 2\n",
    "    mpl.rcParams['xtick.major.width'] = 0.3\n",
    "    mpl.rcParams['xtick.minor.size'] = 1\n",
    "    mpl.rcParams['xtick.minor.width'] = 0.1\n",
    "\n",
    "    os.chdir(\"..\")\n",
    "    config = Config()\n",
    "    if trait == \"ad\":\n",
    "        configstring = \"alz\"\n",
    "    elif trait == \"cad\":\n",
    "        configstring = \"cad_really\"\n",
    "    else:\n",
    "        configstring = trait\n",
    "    config.parse_yaml(\"/home/ubuntu/speos/config_{}_only_nohetio_film_newstorage.yaml\".format(configstring))\n",
    "    prepro = InputHandler(config).get_preprocessor()\n",
    "    prepro.build_graph(adjacency=False)\n",
    "    background = set(prepro.id2hgnc.values())\n",
    "    os.chdir(\"notebooks\")\n",
    "\n",
    "    print (\"Starting KD Analysis for {} {}\".format(trait, celltype))\n",
    "    if isinstance(trait, str):\n",
    "        allcore, other_coregenes, hsps,  noncore = get_coregenes(trait, background)\n",
    "        traitstring = trait\n",
    "    else:\n",
    "        allcore = set()\n",
    "        other_coregenes = set()\n",
    "        hsps = set()\n",
    "        noncore = set(list(background)[:])\n",
    "        for _trait in trait:\n",
    "            _allcore, _other_coregenes, _hsps,  _noncore = get_coregenes(_trait, background)\n",
    "            allcore.update(set(_allcore))\n",
    "            other_coregenes.update(set(_other_coregenes))\n",
    "            hsps.update(set(_hsps))\n",
    "            noncore = noncore.intersection(_noncore)\n",
    "        traitstring = \"_\".join(trait)\n",
    "\n",
    "    if celltype == \"HEK293T\":\n",
    "        full_kd_df = pd.read_csv(\"/mnt/storage/cmap/2017/kd_df_{}.tsv\".format(celltype), header=0, sep=\"\\t\", index_col=0)\n",
    "    else:\n",
    "        full_kd_df = pd.read_csv(\"/mnt/storage/cmap/2017/kd_cgs_df_{}.tsv\".format(celltype), header=0, sep=\"\\t\", index_col=0)\n",
    "\n",
    "    gene_df = pd.read_csv(\"/mnt/storage/cmap/2017/GSE92742_Broad_LINCS_gene_info.txt\", sep=\"\\t\", header=0, index_col=None)\n",
    "    good_genes = gene_df.pr_gene_symbol[gene_df.pr_is_bing == 1].tolist()\n",
    "\n",
    "    full_kd_df = full_kd_df.loc[full_kd_df.index.isin(good_genes), :]\n",
    "\n",
    "    if len(restriction) > 0:\n",
    "        restriction = [column for column in full_kd_df.columns if column.split(\".\")[0] in restriction]\n",
    "        full_kd_df = full_kd_df[list(restriction)]\n",
    "        typestring = celltype + \"_restricted\"\n",
    "    else:\n",
    "        typestring = celltype\n",
    "\n",
    "    \n",
    "\n",
    "    results_df, total, core_result, hsp_result, peri_result = get_differential_percentages(full_kd_df, allcore, hsps, noncore,  use_min=False, use_mean=True)\n",
    "    results_df.transpose().to_csv(\"/mnt/storage/cmap/2017/differential_perturbation_knockdown_{}_{}.tsv\".format(traitstring, typestring), sep=\"\\t\")\n",
    "\n",
    "    gwas_genes = set(pd.read_csv(\"../hsps/gwas_genes_closest/5e-8/uc_gwas_genes.tsv\", header=0, sep=\"\\t\", index_col=None)[\"HGNC\"].tolist()).intersection(prepro.id2hgnc.values())\n",
    "    gwas_results_df, _, gwas_core_result, gwas_hsp_result, gwas_peri_result = get_differential_percentages(full_kd_df, allcore, hsps, noncore,  use_min=False, use_mean=True, alternative_core=gwas_genes)\n",
    "    gwas_results_df.transpose().to_csv(\"/mnt/storage/cmap/2017/differential_perturbation_knockdown_gwas_{}_{}.tsv\".format(traitstring, typestring), sep=\"\\t\")\n",
    "\n",
    "\n",
    "    random_core = []\n",
    "    random_hsp = []\n",
    "    random_peri = []\n",
    "    for i in range(nrandom):\n",
    "        _, _, core_result_random, hsp_result_random, peri_result_random = get_differential_percentages(full_kd_df, allcore, hsps, noncore,use_min=False, use_mean=True, randomize_core=True, random_seed=i)\n",
    "        random_core.append(core_result_random[0])\n",
    "        random_hsp.append(hsp_result_random[0])\n",
    "        random_peri.append(peri_result_random[0])\n",
    "\n",
    "    results_df = results_df.transpose()\n",
    "        \n",
    "    fig, ax= plt.subplots(figsize=(8*cm,4*cm))\n",
    "\n",
    "    num_target_core_genes = len(allcore.intersection(set(full_kd_df.index)))\n",
    "\n",
    "    \n",
    "    kd_matrix_mean = pd.DataFrame(index=[\"HSP\" + \"\\n(n=%s)\" % hsp_result[1], \"Peripheral\\n\" + \"(n=%s)\" % peri_result[1], \"Core Gene\\n\" + \"(n=%s)\" % core_result[1]],\n",
    "                         data={\"Core Genes\\n\" + \"n={}\".format(num_target_core_genes): [hsp_result[0], peri_result[0],  core_result[0]],\n",
    "                               \"GWAS Genes\\n\" + \"n={}\".format(len(gwas_genes)): [gwas_hsp_result[0], gwas_peri_result[0],  gwas_core_result[0]],\n",
    "                               \"Random Genes\\n\" + \"n={} ({}x)\".format(num_target_core_genes, len(random_hsp)): [np.mean(random_hsp), np.mean(random_peri), np.mean(random_core)]})\n",
    "\n",
    "    ax = sns.heatmap(kd_matrix_mean.transpose(), vmin=0,  vmax=1, cmap=\"Purples\", annot=True, fmt=\".1%\", ax=ax, \n",
    "                 annot_kws = {\"fontsize\": 8},\n",
    "                 cbar_kws={'label': \"Fraction Significant\\nDifferential Perturbations\",\n",
    "                           \"pad\": 0.01})\n",
    "    ax.tick_params(axis='y', labelrotation=0)\n",
    "    ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 6)\n",
    "    cbar = ax.collections[-1].colorbar\n",
    "    cbar.ax.set_ylabel(\"Fraction Discriminative\\nPerturbations\", fontsize=7)\n",
    "    ax.set_ylabel(\"Target Gene Set\", fontsize=7)\n",
    "    ax.set_xlabel(\"Perturbagen (Knockdown)\", fontsize=7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"Perturbation_knockdown_{}_{}.svg\".format(traitstring, typestring), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with one combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_knockdown(\"uc\", \"HT29\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now get for all combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "traits = [\"uc\", \"ra\", \"cad\", \"ad\", \"scz\"]\n",
    "celltypes = [\"PC3\", \"HT29\", \"HEK293T\"]\n",
    "\n",
    "combinations = []\n",
    "\n",
    "for trait in traits:\n",
    "    for celltype in celltypes:\n",
    "        combinations.append((trait, celltype))\n",
    "\n",
    "with tqdm_joblib(tqdm(desc=\"My calculation\", total=len(combinations))) as progress_bar:\n",
    "    Parallel(n_jobs=15)(delayed(full_knockdown)(trait, celltype) for (trait, celltype) in combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# and once restrict perturbagens to those that are present in every cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "traits = [\"uc\", \"ra\", \"cad\", \"ad\", \"scz\"]\n",
    "celltypes = [\"PC3\", \"HT29\", \"HEK293T\"]\n",
    "\n",
    "combinations = []\n",
    "restriction = set([column.split(\".\")[0] for column in pd.read_csv(\"/mnt/storage/cmap/2017/kd_df_HEK293T.tsv\", header=0, sep=\"\\t\", index_col=0).columns.tolist()])\n",
    "restriction = restriction.intersection(set([column.split(\".\")[0] for column in pd.read_csv(\"/mnt/storage/cmap/2017/kd_cgs_df_PC3.tsv\", header=0, sep=\"\\t\", index_col=0).columns.tolist()]))\n",
    "restriction = restriction.intersection(set([column.split(\".\")[0] for column in pd.read_csv(\"/mnt/storage/cmap/2017/kd_cgs_df_HT29.tsv\", header=0, sep=\"\\t\", index_col=0).columns.tolist()]))\n",
    "\n",
    "\n",
    "for trait in traits:\n",
    "    for celltype in celltypes:\n",
    "        combinations.append((trait, celltype))\n",
    "\n",
    "with tqdm_joblib(tqdm(desc=\"My calculation\", total=len(combinations))) as progress_bar:\n",
    "    Parallel(n_jobs=15)(delayed(full_knockdown)(trait, celltype, id2hgnc.values(), list(restriction)) for trait, celltype in combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# across traits (uncomment last lines to write file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from speos.visualization.settings import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "traits = ['uc', 'ra', 'cad', 'ad', 'scz']\n",
    "celltypes = [\"PC3\", \"HT29\", \"HEK293T\"]\n",
    "\n",
    "sign_perturbagens = {trait: {} for trait in traits}\n",
    "background = {trait: {} for trait in traits}\n",
    "\n",
    "n_random_draws = 5\n",
    "\n",
    "for trait in traits:\n",
    "    for celltype in celltypes:\n",
    "        df = pd.read_csv(\"/mnt/storage/cmap/2017/differential_perturbation_knockdown_{}_{}.tsv\".format(trait, celltype), sep=\"\\t\", header=0, index_col=0)\n",
    "        sign_perturbagens[trait][celltype] = set(df.index[df[\"FDR\"] < 0.05])\n",
    "        background[trait][celltype] = set(df.index)\n",
    "\n",
    "overlap_background = {trait: {} for trait in traits}\n",
    "overlap_indices = {trait: {} for trait in traits}\n",
    "rand_control = {trait: {} for trait in traits}\n",
    "for traitA in traits:\n",
    "    overlap_indices[traitA] = {trait: {} for trait in traits}\n",
    "    overlap_background[traitA] = {trait: {} for trait in traits}\n",
    "    rand_control[traitA] = {trait: {} for trait in traits}\n",
    "    for traitB in traits:\n",
    "        #union = sign_perturbagens[trait][celltypes[0]].union(sign_perturbagens[trait][celltypes[1]]).union(sign_perturbagens[trait][celltypes[2]])\n",
    "        for celltypeA in celltypes:\n",
    "            row = []\n",
    "            background_row = []\n",
    "            rand_row = []\n",
    "            for celltypeB in celltypes:\n",
    "                setA = sign_perturbagens[traitA][celltypeA]\n",
    "                setB = sign_perturbagens[traitB][celltypeB]\n",
    "                real_coeff = len(setA.intersection(setB)) / min(len(setA), len(setB))\n",
    "                row.append(real_coeff)\n",
    "\n",
    "                setA = background[traitA][celltypeA]\n",
    "                setB = background[traitB][celltypeB]\n",
    "                background_row.append(len(setA.intersection(setB)) / min(len(setA), len(setB)))\n",
    "\n",
    "                rand_coeffs = []\n",
    "                for _ in range(n_random_draws):\n",
    "                    sampleA = sample(list(background[traitA][celltypeA]), len(sign_perturbagens[traitA][celltypeA]))\n",
    "                    sampleB = sample(list(background[traitB][celltypeB]), len(sign_perturbagens[traitB][celltypeB]))\n",
    "                    rand_coeffs.append(len(set(sampleA).intersection(set(sampleB))) / min(len(sampleA), len(sampleB)))\n",
    "                \n",
    "                #rand_coeffs.append(real_coeff)\n",
    "                #rand_row.append((np.argpartition(rand_coeffs, n_random_draws) == n_random_draws).nonzero()[0].item())\n",
    "                rand_row.append(rankdata(rand_coeffs + [real_coeff], \"average\")[-1].item())\n",
    "            \n",
    "            rand_control[traitA][traitB][celltypeA] = rand_row\n",
    "            overlap_indices[traitA][traitB][celltypeA] = row\n",
    "            overlap_background[traitA][traitB][celltypeA] = background_row\n",
    "\n",
    "rownames = []\n",
    "rows = []\n",
    "for traitA in traits:\n",
    "    for celltype in celltypes:\n",
    "        rownames.append(celltype)\n",
    "        row = []\n",
    "        for traitB in traits:\n",
    "            row.extend(overlap_indices[traitA][traitB][celltype])\n",
    "        rows.append(row)\n",
    "\n",
    "rows = np.asarray(rows)\n",
    "\n",
    "rownames = []\n",
    "background_rows = []\n",
    "for traitA in traits:\n",
    "    for celltype in celltypes:\n",
    "        rownames.append(celltype)\n",
    "        row = []\n",
    "        for traitB in traits:\n",
    "            row.extend(overlap_background[traitA][traitB][celltype])\n",
    "        background_rows.append(row)\n",
    "\n",
    "background_rows = np.asarray(background_rows)\n",
    "\n",
    "rows = rows / background_rows\n",
    "\n",
    "rows = rows[:,[0,3,6,9,12,1,4,7,10,13,2,5,8,11,14]]\n",
    "rows = rows[[0,3,6,9,12,1,4,7,10,13,2,5,8,11,14], :]\n",
    "    \n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import matplotlib as mpl\n",
    "\n",
    "rand_rownames = []\n",
    "rand_rows = []\n",
    "for traitA in traits:\n",
    "    for celltype in celltypes:\n",
    "        rand_rownames.append(celltype)\n",
    "        row = []\n",
    "        for traitB in traits:\n",
    "            row.extend(rand_control[traitA][traitB][celltype])\n",
    "        rand_rows.append(row)\n",
    "\n",
    "rand_rows = np.asarray(rand_rows)\n",
    "rand_rows = rand_rows[:,[0,3,6,9,12,1,4,7,10,13,2,5,8,11,14]]\n",
    "rand_rows = rand_rows[[0,3,6,9,12,1,4,7,10,13,2,5,8,11,14], :]\n",
    "\n",
    "rand_rows =  rand_rows / (n_random_draws + 1)\n",
    "\n",
    "labels = rand_rows.copy()\n",
    "print(rand_rows)\n",
    "labels[labels > 0.5] = 1 - labels[labels > 0.5]\n",
    "\n",
    "old_shape = labels.shape\n",
    "\n",
    "fdr_labels = fdrcorrection(labels.flatten())[1].reshape(old_shape)\n",
    "\n",
    "rand_rows[rand_rows < 0.5] = fdr_labels[rand_rows < 0.5]\n",
    "rand_rows[rand_rows > 0.5] = 1- fdr_labels[rand_rows > 0.5]\n",
    "\n",
    "fdr_labels *= 2\n",
    "\n",
    "for i in range(fdr_labels.shape[0]):\n",
    "    for j in range(fdr_labels.shape[1]):\n",
    "        if j <= i: \n",
    "            continue\n",
    "        else:\n",
    "            value = np.mean([fdr_labels[i,j], fdr_labels[j,i]])\n",
    "            fdr_labels[i,j] = value\n",
    "            fdr_labels[j,i] = value\n",
    "\n",
    "\n",
    "\n",
    "#df = pd.DataFrame(rows, columns = [[celltype + \"_\" + trait.upper()  for celltype in celltypes for trait in traits]], index = [[celltype + \"_\" + trait.upper()  for celltype in celltypes for trait in traits]])\n",
    "#df.to_csv(\"all_5_knockdown_overlap_new.tsv\", sep=\"\\t\")\n",
    "#df_fdr = pd.DataFrame(fdr_labels, columns = [[celltype + \"_\" + trait.upper()  for celltype in celltypes for trait in traits]], index = [[celltype + \"_\" + trait.upper()  for celltype in celltypes for trait in traits]])\n",
    "#df_fdr.to_csv(\"all_5_knockdown_fdr_new.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = pd.read_csv(\"all_5_knockdown_overlap.tsv\", sep=\"\\t\", header=0, index_col=0).values\n",
    "fdr_labels = pd.read_csv(\"all_5_knockdown_fdr.tsv\", sep=\"\\t\", header=0, index_col=0).values\n",
    "\n",
    "oldshape = rows.shape \n",
    "plot_labels = rows.flatten()\n",
    "\n",
    "plot_labels = np.asarray([(\"%.2g\" % k).lstrip('0') if k not in [1, 0] else k for k in plot_labels]).reshape(oldshape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(full_width*0.9*cm,full_width*0.8*cm ))\n",
    "\n",
    "ax = sns.heatmap(rows, vmin=0.3,  vmax=1, cmap=\"Purples\", annot=plot_labels, ax=ax, fmt=\"\", annot_kws={\"fontsize\": 8}, zorder=1)\n",
    "ax.set_yticklabels([trait.upper() for trait in traits]*3, rotation=90 )\n",
    "ax.set_xticklabels([trait.upper() for trait in traits]*3, rotation=0, ha=\"center\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "maximum = 15\n",
    "minimum = 0\n",
    "stride = 5\n",
    "for trait, start in zip(rownames, range(minimum, maximum, stride)):\n",
    "    ax.text(x = start + (stride/2), y= 17, s=trait, ha=\"center\")\n",
    "    ax.text(y = start + (stride/2), x= -2.5, s=trait, va=\"center\", rotation=90)\n",
    "\n",
    "cmap = mpl.colors.ListedColormap([(0.9, 0.9, 0.9, 1), (0,0,0,0)])\n",
    "\n",
    "# create a normalize object the describes the limits of\n",
    "# each color\n",
    "bounds = [0., 0.5, 1.]\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "plot_labels[fdr_labels < 0.05] = \"\"\n",
    "\n",
    "ax.imshow((fdr_labels < 0.5).astype(np.uint8), interpolation='none', cmap=cmap, norm=norm)\n",
    "sns.heatmap((fdr_labels < 0.05).astype(np.uint8), vmin=0,  vmax=1, cmap=cmap, norm=norm, annot=plot_labels, ax=ax, fmt=\"\", annot_kws={\"fontsize\": 8}, cbar=False, zorder=2)\n",
    "\n",
    "ax.set_yticklabels([trait.upper() + \"\\n$\\\\regular_{n=%s}$\" % len(sign_perturbagens[trait][celltype]) for celltype in celltypes for trait in traits], rotation=90 )\n",
    "ax.set_xticklabels([trait.upper() + \"\\n$\\\\regular_{n=%s}$\" % len(sign_perturbagens[trait][celltype]) for celltype in celltypes for trait in traits], rotation=0, ha=\"center\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.savefig(\"across_traits_knockdown_5.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from speos.visualization.settings import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "traits = ['uc', 'ra', 'cad', 'ad', 'scz']\n",
    "celltypes = [\"PC3\", \"HT29\", \"HEK293T\"]\n",
    "\n",
    "sign_perturbagens = {trait: {} for trait in traits}\n",
    "background = {trait: {} for trait in traits}\n",
    "\n",
    "n_random_draws = 1\n",
    "\n",
    "for trait in traits:\n",
    "    for celltype in celltypes:\n",
    "        df = pd.read_csv(\"/mnt/storage/cmap/2017/differential_perturbation_overexpression_{}_{}.tsv\".format(trait, celltype), sep=\"\\t\", header=0, index_col=0)\n",
    "        sign_perturbagens[trait][celltype] = set(df.index[df[\"FDR\"] < 0.05])\n",
    "        background[trait][celltype] = set(df.index)\n",
    "\n",
    "overlap_background = {trait: {} for trait in traits}\n",
    "overlap_indices = {trait: {} for trait in traits}\n",
    "rand_control = {trait: {} for trait in traits}\n",
    "for traitA in traits:\n",
    "    overlap_indices[traitA] = {trait: {} for trait in traits}\n",
    "    overlap_background[traitA] = {trait: {} for trait in traits}\n",
    "    rand_control[traitA] = {trait: {} for trait in traits}\n",
    "    for traitB in traits:\n",
    "        #union = sign_perturbagens[trait][celltypes[0]].union(sign_perturbagens[trait][celltypes[1]]).union(sign_perturbagens[trait][celltypes[2]])\n",
    "        for celltypeA in celltypes:\n",
    "            row = []\n",
    "            background_row = []\n",
    "            rand_row = []\n",
    "            for celltypeB in celltypes:\n",
    "                setA = sign_perturbagens[traitA][celltypeA]\n",
    "                setB = sign_perturbagens[traitB][celltypeB]\n",
    "                real_coeff = len(setA.intersection(setB)) / min(len(setA), len(setB))\n",
    "                row.append(real_coeff)\n",
    "\n",
    "                setA = background[traitA][celltypeA]\n",
    "                setB = background[traitB][celltypeB]\n",
    "                background_row.append(len(setA.intersection(setB)) / min(len(setA), len(setB)))\n",
    "\n",
    "                rand_coeffs = []\n",
    "                for _ in range(n_random_draws):\n",
    "                    sampleA = sample(list(background[traitA][celltypeA]), len(sign_perturbagens[traitA][celltypeA]))\n",
    "                    sampleB = sample(list(background[traitB][celltypeB]), len(sign_perturbagens[traitB][celltypeB]))\n",
    "                    rand_coeffs.append(len(set(sampleA).intersection(set(sampleB))) / min(len(sampleA), len(sampleB)))\n",
    "                \n",
    "                #rand_coeffs.append(real_coeff)\n",
    "                #rand_row.append((np.argpartition(rand_coeffs, n_random_draws) == n_random_draws).nonzero()[0].item())\n",
    "                rand_row.append(rankdata(rand_coeffs + [real_coeff], \"average\")[-1].item())\n",
    "            \n",
    "            rand_control[traitA][traitB][celltypeA] = rand_row\n",
    "            overlap_indices[traitA][traitB][celltypeA] = row\n",
    "            overlap_background[traitA][traitB][celltypeA] = background_row\n",
    "\n",
    "rownames = []\n",
    "rows = []\n",
    "for traitA in traits:\n",
    "    for celltype in celltypes:\n",
    "        rownames.append(celltype)\n",
    "        row = []\n",
    "        for traitB in traits:\n",
    "            row.extend(overlap_indices[traitA][traitB][celltype])\n",
    "        rows.append(row)\n",
    "\n",
    "rows = np.asarray(rows)\n",
    "\n",
    "rownames = []\n",
    "background_rows = []\n",
    "for traitA in traits:\n",
    "    for celltype in celltypes:\n",
    "        rownames.append(celltype)\n",
    "        row = []\n",
    "        for traitB in traits:\n",
    "            row.extend(overlap_background[traitA][traitB][celltype])\n",
    "        background_rows.append(row)\n",
    "\n",
    "background_rows = np.asarray(background_rows)\n",
    "\n",
    "rows = rows / background_rows\n",
    "\n",
    "rows = rows[:,[0,3,6,9,12,1,4,7,10,13,2,5,8,11,14]]\n",
    "rows = rows[[0,3,6,9,12,1,4,7,10,13,2,5,8,11,14], :]\n",
    "\n",
    "\n",
    "\n",
    "#plt.savefig(\"across_traits_knockdown_5_restricted.svg\", bbox_inches=\"tight\")\n",
    "    \n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import matplotlib as mpl\n",
    "\n",
    "rand_rownames = []\n",
    "rand_rows = []\n",
    "for traitA in traits:\n",
    "    for celltype in celltypes:\n",
    "        rand_rownames.append(celltype)\n",
    "        row = []\n",
    "        for traitB in traits:\n",
    "            row.extend(rand_control[traitA][traitB][celltype])\n",
    "        rand_rows.append(row)\n",
    "\n",
    "rand_rows = np.asarray(rand_rows)\n",
    "rand_rows = rand_rows[:,[0,3,6,9,12,1,4,7,10,13,2,5,8,11,14]]\n",
    "rand_rows = rand_rows[[0,3,6,9,12,1,4,7,10,13,2,5,8,11,14], :]\n",
    "\n",
    "rand_rows =  rand_rows / (n_random_draws + 1)\n",
    "\n",
    "labels = rand_rows.copy()\n",
    "labels[labels > 0.5] = 1 - labels[labels > 0.5]\n",
    "\n",
    "old_shape = labels.shape\n",
    "\n",
    "fdr_labels = fdrcorrection(labels.flatten())[1].reshape(old_shape)\n",
    "\n",
    "fdr_labels *= 2\n",
    "\n",
    "for i in range(fdr_labels.shape[0]):\n",
    "    for j in range(fdr_labels.shape[1]):\n",
    "        if j <= i: \n",
    "            continue\n",
    "        else:\n",
    "            value = np.mean([fdr_labels[i,j], fdr_labels[j,i]])\n",
    "            fdr_labels[i,j] = value\n",
    "            fdr_labels[j,i] = value\n",
    "\n",
    "\n",
    "#df = pd.DataFrame(rows, columns = [[celltype + \"_\" + trait.upper()  for celltype in celltypes for trait in traits]], index = [[celltype + \"_\" + trait.upper()  for celltype in celltypes for trait in traits]])\n",
    "#df.to_csv(\"all_5_overexpression_overlap.tsv\", sep=\"\\t\")\n",
    "#df_fdr = pd.DataFrame(fdr_labels, columns = [[celltype + \"_\" + trait.upper()  for celltype in celltypes for trait in traits]], index = [[celltype + \"_\" + trait.upper()  for celltype in celltypes for trait in traits]])\n",
    "#df_fdr.to_csv(\"all_5_overexpression_fdr.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from speos.visualization.settings import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rows = pd.read_csv(\"all_5_overexpression_overlap.tsv\", sep=\"\\t\", header=0, index_col=0).values\n",
    "fdr_labels = pd.read_csv(\"all_5_overexpression_fdr.tsv\", sep=\"\\t\", header=0, index_col=0).values\n",
    "\n",
    "oldshape = rows.shape \n",
    "plot_labels = rows.flatten()\n",
    "\n",
    "plot_labels = np.asarray([(\"%.2g\" % k).lstrip('0') if k not in [1, 0] else k for k in plot_labels]).reshape(oldshape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(full_width*0.9*cm,full_width*0.8*cm ))\n",
    "\n",
    "ax = sns.heatmap(rows, vmin=0.3,  vmax=1, cmap=\"Oranges\", annot=plot_labels, ax=ax, fmt=\"\", annot_kws={\"fontsize\": 8}, zorder=1)\n",
    "ax.set_yticklabels([trait.upper() for trait in traits]*3, rotation=90 )\n",
    "ax.set_xticklabels([trait.upper() for trait in traits]*3, rotation=0, ha=\"center\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "maximum = 15\n",
    "minimum = 0\n",
    "stride = 5\n",
    "for trait, start in zip(rownames, range(minimum, maximum, stride)):\n",
    "    ax.text(x = start + (stride/2), y= 17, s=trait, ha=\"center\")\n",
    "    ax.text(y = start + (stride/2), x= -2.5, s=trait, va=\"center\", rotation=90)\n",
    "\n",
    "cmap = mpl.colors.ListedColormap([(0.9, 0.9, 0.9, 1), (0,0,0,0)])\n",
    "\n",
    "# create a normalize object the describes the limits of\n",
    "# each color\n",
    "bounds = [0., 0.5, 1.]\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "plot_labels[fdr_labels < 0.05] = \"\"\n",
    "\n",
    "ax.imshow((fdr_labels < 0.5).astype(np.uint8), interpolation='none', cmap=cmap, norm=norm)\n",
    "sns.heatmap((fdr_labels < 0.05).astype(np.uint8), vmin=0,  vmax=1, cmap=cmap, norm=norm, annot=plot_labels, ax=ax, fmt=\"\", annot_kws={\"fontsize\": 8}, cbar=False, zorder=2)\n",
    "ax.tick_params(top=True, labeltop=True, bottom=False, labelbottom=False, right=True, left=False, labelright=True, labelleft=False)\n",
    "ax.set_yticklabels([trait.upper() + \"\\n$\\\\regular_{n=%s}$\" % len(sign_perturbagens[trait][celltype]) for celltype in celltypes for trait in traits], rotation=90 )\n",
    "ax.set_xticklabels([trait.upper() + \"\\n$\\\\regular_{n=%s}$\" % len(sign_perturbagens[trait][celltype]) for celltype in celltypes for trait in traits], rotation=0, ha=\"center\")\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "maximum = 15\n",
    "minimum = 0\n",
    "stride = 5\n",
    "#or trait, start in zip(rownames, range(minimum, maximum, stride)):\n",
    "#   ax.text(x = start + (stride/2), y= 15, s=trait, ha=\"center\")\n",
    "#   ax.text(y = start + (stride/2), x= -2, s=trait, va=\"center\", rotation=90)\n",
    "\n",
    "plt.savefig(\"across_traits_overexpression_5_new.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from speos.visualization.settings import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "traits = ['uc', 'ra', 'cad', 'ad', 'scz']\n",
    "celltypes = [\"PC3\", \"HT29\", \"HEK293T\"]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols= 3, figsize=(full_width*cm,full_width*0.25*cm )) \n",
    "\n",
    "allrows = pd.read_csv(\"all_5_knockdown_overlap.tsv\", sep=\"\\t\", header=0, index_col=0)\n",
    "allfdr = pd.read_csv(\"all_5_knockdown_fdr.tsv\", sep=\"\\t\", header=0, index_col=0)\n",
    "\n",
    "for ax, celltype in zip(axs, celltypes):\n",
    "\n",
    "    colnames = [colname for colname in allrows.columns if colname.startswith(celltype)]\n",
    "    rows = allrows.loc[colnames, colnames].values\n",
    "    oldshape = rows.shape \n",
    "    plot_labels = rows.flatten()\n",
    "\n",
    "    plot_labels = np.asarray([(\"%.2g\" % k).lstrip('0') if k not in [1, 0] else k for k in plot_labels]).reshape(oldshape)\n",
    "\n",
    "    ax = sns.heatmap(rows, vmin=0.3,  vmax=1, cmap=\"Purples\", annot=plot_labels, ax=ax, fmt=\"\", annot_kws={\"fontsize\": 8}, zorder=1)\n",
    "\n",
    "    fdr_labels = allfdr.loc[colnames, colnames].values\n",
    "    cmap = mpl.colors.ListedColormap([(0.8, 0.8, 0.8, 1), (0,0,0,0)])\n",
    "\n",
    "    # create a normalize object the describes the limits of\n",
    "    # each color\n",
    "    bounds = [0., 0.5, 1.]\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    plot_labels[fdr_labels < 0.05] = \"\"\n",
    "\n",
    "    #ax.imshow((fdr_labels < 0.5).astype(np.uint8), interpolation='none', cmap=cmap, norm=norm)\n",
    "    sns.heatmap((fdr_labels < 0.05).astype(np.uint8), vmin=0,  vmax=1, cmap=cmap, norm=norm, annot=plot_labels, ax=ax, fmt=\"\", annot_kws={\"fontsize\": 8}, cbar=False, zorder=2)\n",
    "\n",
    "    ax.set_yticklabels([trait.upper() + \"\\n$\\\\regular_{n=%s}$\" % len(sign_perturbagens[trait][celltype]) for trait in traits], rotation=90 )\n",
    "    ax.set_xticklabels([trait.upper() + \"\\n$\\\\regular_{n=%s}$\" % len(sign_perturbagens[trait][celltype]) for trait in traits], rotation=0, ha=\"center\")\n",
    "    ax.tick_params(axis='y', labelrotation=0)\n",
    "    ax.set_title(celltype)\n",
    "\n",
    "        \n",
    "\n",
    "plt.savefig(\"across_traits_knockdown.svg\".format(celltype), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from speos.visualization.settings import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "fig, axs = plt.subplots(ncols= 3, figsize=(full_width*cm,full_width*0.25*cm )) \n",
    "\n",
    "allrows = pd.read_csv(\"all_5_overexpression_overlap.tsv\", sep=\"\\t\", header=0, index_col=0)\n",
    "allfdr = pd.read_csv(\"all_5_overexpression_fdr.tsv\", sep=\"\\t\", header=0, index_col=0)\n",
    "\n",
    "traits = ['uc', 'ra', 'cad', 'ad', 'scz']\n",
    "celltypes = [\"PC3\", \"HT29\", \"HEK293T\"]\n",
    "for ax, celltype in zip(axs, celltypes):\n",
    "\n",
    "    colnames = [colname for colname in allrows.columns if colname.startswith(celltype)]\n",
    "    rows = allrows.loc[colnames, colnames].values\n",
    "    oldshape = rows.shape \n",
    "    plot_labels = rows.flatten()\n",
    "\n",
    "    plot_labels = np.asarray([(\"%.2g\" % k).lstrip('0') if k not in [0, 1] else k for k in plot_labels]).reshape(oldshape)\n",
    "\n",
    "    \n",
    "\n",
    "    ax = sns.heatmap(rows, vmin=0.3,  vmax=1, cmap=\"Oranges\", annot=plot_labels, ax=ax, fmt=\"\", annot_kws={\"fontsize\": 8}, zorder=1)\n",
    "\n",
    "    fdr_labels = allfdr.loc[colnames, colnames].values\n",
    "    cmap = mpl.colors.ListedColormap([(0.8, 0.8, 0.8, 1), (0,0,0,0)])\n",
    "\n",
    "    # create a normalize object the describes the limits of\n",
    "    # each color\n",
    "    bounds = [0., 0.5, 1.]\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    plot_labels[fdr_labels < 0.05] = \"\"\n",
    "\n",
    "    #ax.imshow((fdr_labels < 0.5).astype(np.uint8), interpolation='none', cmap=cmap, norm=norm)\n",
    "    sns.heatmap((fdr_labels < 0.05).astype(np.uint8), vmin=0,  vmax=1, cmap=cmap, norm=norm, annot=plot_labels, ax=ax, fmt=\"\", annot_kws={\"fontsize\": 8}, cbar=False, zorder=2)\n",
    "\n",
    "    ax.tick_params(top=True, labeltop=True, bottom=False, labelbottom=False, right=True, left=False, labelright=True, labelleft=False)\n",
    "    ax.set_yticklabels([trait.upper() + \"\\n$\\\\regular_{n=%s}$\" % len(sign_perturbagens[trait][celltype]) for trait in traits], rotation=90 )\n",
    "    ax.set_xticklabels([trait.upper() + \"\\n$\\\\regular_{n=%s}$\" % len(sign_perturbagens[trait][celltype]) for trait in traits], rotation=0, ha=\"center\")\n",
    "    ax.tick_params(axis='y', labelrotation=0)\n",
    "    ax.set_title(celltype)\n",
    "        \n",
    "\n",
    "plt.savefig(\"across_traits_overexpression.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volcano plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trait = \"uc\"\n",
    "celltype = \"HT29\"\n",
    "\n",
    "allcore, other_coregenes, hsps,  noncore = get_coregenes(trait, id2hgnc.values())\n",
    "full_kd_df = pd.read_csv(\"/mnt/storage/cmap/2017/kd_cgs_df_{}.tsv\".format(celltype), header=0, sep=\"\\t\", index_col=0)\n",
    "\n",
    "gene_df = pd.read_csv(\"/mnt/storage/cmap/2017/GSE92742_Broad_LINCS_gene_info.txt\", sep=\"\\t\", header=0, index_col=None)\n",
    "good_genes = gene_df.pr_gene_symbol[gene_df.pr_is_bing == 1].tolist()\n",
    "\n",
    "full_kd_df = full_kd_df.loc[full_kd_df.index.isin(good_genes), :]\n",
    "\n",
    "results_df, total, core_result, hsp_result, peri_result = get_differential_percentages(full_kd_df, allcore, hsps, noncore, use_mean=True)\n",
    "results_df = results_df.transpose()\n",
    "print(len(results_df))\n",
    "results_df = results_df[(results_df[\"Core Gene\"] + results_df[\"HSP\"] + results_df[\"Peripheral\"]).values.astype(np.bool_)]\n",
    "print(len(results_df))\n",
    "results_df = results_df[results_df[\"FDR\"] < 0.05]\n",
    "print(len(results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speos.visualization.settings import *\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(full_width*cm*0.5, 8*cm))\n",
    "all_significant = results_df[\"meandiff\"][(results_df[\"FDR\"] < 0.05) & (results_df[\"Core Gene\"] + results_df[\"HSP\"] + results_df[\"Peripheral\"])]\n",
    "core_significant = results_df[\"meandiff\"][(results_df[\"FDR\"] < 0.05) & (results_df[\"Core Gene\"])]\n",
    "hsp_significant = results_df[\"meandiff\"][(results_df[\"FDR\"] < 0.05) & (results_df[\"HSP\"])]\n",
    "peri_significant = results_df[\"meandiff\"][(results_df[\"FDR\"] < 0.05) & (results_df[\"Peripheral\"])]\n",
    "\n",
    "core_fdr = results_df[\"FDR\"][(results_df[\"FDR\"] < 0.05) & (results_df[\"Core Gene\"])]\n",
    "hsp_fdr = results_df[\"FDR\"][(results_df[\"FDR\"] < 0.05) & (results_df[\"HSP\"])]\n",
    "peri_fdr = results_df[\"FDR\"][(results_df[\"FDR\"] < 0.05) & (results_df[\"Peripheral\"])]\n",
    "ax.set_yscale(\"log\")\n",
    "ax.scatter(x=peri_significant,y = 1 / peri_fdr, s=5, c=\"#8a8a8a\")\n",
    "ax.scatter(x=core_significant,y = 1 / core_fdr, s=5, c=\"#01016f\")\n",
    "ax.scatter(x=hsp_significant,y = 1 / hsp_fdr, s=5, c=\"#d8031c\")\n",
    "\n",
    "texts = []\n",
    "sorted_df = results_df.sort_values(by=\"FDR\", ascending=True)\n",
    "already_printed = []\n",
    "for i in range(8):\n",
    "    texts.append(ax.text(sorted_df[\"meandiff\"][i], 1/sorted_df[\"FDR\"][i], sorted_df.index[i], size=4, va=\"center\"))\n",
    "    already_printed.append(sorted_df.index[i])\n",
    "\n",
    "adjust_text(texts, x=results_df[\"meandiff\"].values.tolist(), y= (1/results_df[\"FDR\"].values).tolist(), force_points=3, arrowprops=dict(arrowstyle='-', color='black', lw=0.5), ax=ax)\n",
    "\n",
    "texts = []\n",
    "sorted_df = results_df.sort_values(by=\"meandiff\", ascending=True)\n",
    "for i in range(3):\n",
    "    if sorted_df.index[i] not in already_printed:\n",
    "      texts.append(ax.text(sorted_df[\"meandiff\"][i], 1/sorted_df[\"FDR\"][i], sorted_df.index[i], size=4, va=\"center\"))\n",
    "      already_printed.append(sorted_df.index[i])\n",
    "\n",
    "sorted_df = results_df.sort_values(by=\"meandiff\", ascending=False)\n",
    "for i in range(5):\n",
    "    if sorted_df.index[i] not in already_printed:\n",
    "      texts.append(ax.text(sorted_df[\"meandiff\"][i], 1/sorted_df[\"FDR\"][i], sorted_df.index[i], size=4, va=\"center\"))\n",
    "      already_printed.append(sorted_df.index[i])\n",
    "\n",
    "sorted_df = results_df[results_df[\"meandiff\"] < 0].sort_values(by=\"FDR\", ascending=True)\n",
    "for i in range(5):\n",
    "    if sorted_df.index[i] not in already_printed:\n",
    "      texts.append(ax.text(sorted_df[\"meandiff\"][i], 1/sorted_df[\"FDR\"][i], sorted_df.index[i], size=4, va=\"center\"))\n",
    "      already_printed.append(sorted_df.index[i])\n",
    "\n",
    "adjust_text(texts, x=results_df[\"meandiff\"].values.tolist(), y=(1/results_df[\"FDR\"].values).tolist(), force_points=5, arrowprops=dict(arrowstyle='-', color='black', lw=0.5), ax=ax)\n",
    "\n",
    "texts = []\n",
    "hsp_df = results_df[results_df[\"HSP\"]]\n",
    "if len(hsp_df) > 0:\n",
    "      for i in range(len(hsp_df)):\n",
    "            texts.append(ax.text(hsp_df[\"meandiff\"][i], 1/hsp_df[\"FDR\"][i], hsp_df.index[i], size=4, va=\"center\"))\n",
    "\n",
    "      adjust_text(texts, x=results_df[\"meandiff\"].values.tolist(), y=(1/results_df[\"FDR\"].values).tolist(), force_points=0.5, arrowprops=dict(arrowstyle='-', color='black', lw=0.5), ax=ax)\n",
    "\n",
    "\n",
    "ax.vlines(0, 1/0.05, 10e28, color=\"gray\", linestyles=\":\")\n",
    "\n",
    "ax.text(-0.01, y=10e28, s=\"{:.1f}%\".format(((all_significant < 0).sum() / len(all_significant)) * 100), ha=\"right\", va=\"top\", fontsize=8)\n",
    "ax.text(+0.01, y=10e28, s=\"{:.1f}%\".format(((all_significant > 0).sum() / len(all_significant)) * 100), ha=\"left\", va=\"top\", fontsize=8)\n",
    "\n",
    "\n",
    "ax.text(-0.01, y=10e26, s=\"{:.1f}%\".format(((peri_significant < 0).sum() / len(peri_significant)) * 100), ha=\"right\", va=\"top\", color=\"#8a8a8a\", fontsize=8)\n",
    "ax.text(+0.01, y=10e26, s=\"{:.1f}%\".format(((peri_significant > 0).sum() / len(peri_significant)) * 100), ha=\"left\", va=\"top\", color=\"#8a8a8a\", fontsize=8)\n",
    "\n",
    "ax.text(-0.01, y=10e24, s=\"{:.1f}%\".format(((core_significant < 0).sum() / len(core_significant)) * 100), ha=\"right\", va=\"top\", color=\"#01016f\", fontsize=8)\n",
    "ax.text(+0.01, y=10e24, s=\"{:.1f}%\".format(((core_significant > 0).sum() / len(core_significant)) * 100), ha=\"left\", va=\"top\", color=\"#01016f\", fontsize=8)\n",
    "\n",
    "ax.text(-0.01, y=10e22, s=\"{:.1f}%\".format(((hsp_significant < 0).sum() / len(hsp_significant)) * 100), ha=\"right\", va=\"top\", color=\"#d8031c\", fontsize=8)\n",
    "ax.text(+0.01, y=10e22, s=\"{:.1f}%\".format(((hsp_significant > 0).sum() / len(hsp_significant)) * 100), ha=\"left\", va=\"top\", color=\"#d8031c\", fontsize=8)\n",
    "\n",
    "\n",
    "legend_elements = [Patch(facecolor='black', edgecolor='black',\n",
    "                         label='Any\\nn={}'.format(len(all_significant))),\n",
    "                   Patch(facecolor='#8a8a8a', edgecolor='#8a8a8a',\n",
    "                         label='Peripheral\\nn={}'.format(len(peri_significant))),\n",
    "                   Patch(facecolor='#01016f', edgecolor='#01016f',\n",
    "                         label='Core Gene\\nn={}'.format(len(core_significant))),\n",
    "                   Patch(facecolor='#d8031c', edgecolor=\"#d8031c\",\n",
    "                         label='HSP\\nn={}'.format(len(hsp_significant)))]\n",
    "\n",
    "\n",
    "leg = ax.legend(handles=legend_elements, loc='upper left', title=\"Perturbagen\", fontsize=6.8, title_fontsize=7, ncol=2, columnspacing=1.7, handletextpad=-0.7)\n",
    "\n",
    "for patch in leg.get_patches():\n",
    "    patch.set_height(15)\n",
    "    patch.set_width(5)\n",
    "    patch.set_y(-5)\n",
    "\n",
    "ax.set_ylim(bottom=5, top=10e42)\n",
    "ax.set_ylabel(r\"$-\\log(FDR)$\")\n",
    "ax.set_xlabel(\"Mean Differential Perturbation\\n(Core Gene - Peripheral)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Volcano_Knockdown_strongest_{}_{}.svg\".format(trait, celltype), bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for Overexpression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype = \"HT29\"\n",
    "\n",
    "full_oe_df = pd.read_csv(\"/mnt/storage/cmap/2017/oe_df_{}.tsv\".format(celltype), header=0, sep=\"\\t\", index_col=0)\n",
    "gene_df = pd.read_csv(\"/mnt/storage/cmap/2017/GSE92742_Broad_LINCS_gene_info.txt\", sep=\"\\t\", header=0, index_col=None)\n",
    "good_genes = gene_df.pr_gene_symbol[gene_df.pr_is_bing == 1].tolist()\n",
    "\n",
    "full_oe_df = full_oe_df.loc[full_oe_df.index.isin(good_genes), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_differential_percentages(full_oe_df, allcore, hsps, noncore)[0].transpose().to_csv(\"/mnt/storage/cmap/2017/differential_perturbation_overexpression_UC_{}.tsv\".format(celltype), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df, total, core_result, hsp_result, peri_result = get_differential_percentages(full_oe_df, allcore, hsps, noncore)\n",
    "\n",
    "\n",
    "random_core = []\n",
    "random_hsp = []\n",
    "random_peri = []\n",
    "for i in tqdm(range(2)):\n",
    "    _, _, core_result_random, hsp_result_random, peri_result_random = get_differential_percentages(full_oe_df, allcore, hsps, noncore, randomize_core=True, random_seed=i)\n",
    "    random_core.append(core_result_random[0])\n",
    "    random_hsp.append(hsp_result_random[0])\n",
    "    random_peri.append(peri_result_random[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from speos.visualization.settings import *\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax= plt.subplots(figsize=(8*cm,5*cm))\n",
    "\n",
    "num_target_core_genes = len(allcore.intersection(set(full_kd_df.index)))\n",
    "\n",
    "kd_matrix_mean = pd.DataFrame(index=[\"HSP\\n(n={})\".format(hsp_result[1]), \"Peripheral\\n(n={})\".format(peri_result[1]), \"Core\\n(n={})\".format(core_result[1])],\n",
    "                         data={\"Core Genes\\nn={}\".format(num_target_core_genes): [hsp_result[0], peri_result[0],  core_result[0]],\n",
    "                               \"Random Genes\\nn={} ({}x)\".format(num_target_core_genes, len(random_hsp)): [np.mean(random_hsp), np.mean(random_peri), np.mean(random_core)]})\n",
    "\n",
    "ax = sns.heatmap(kd_matrix_mean.transpose(),vmin=0, vmax=1, cmap=\"Oranges\", annot=True, fmt=\".1%\", ax=ax,\n",
    "                 cbar_kws={'label': \"Fraction Significant\\nDifferential Perturbations\",\n",
    "                           \"pad\": 0.01})\n",
    "cbar = ax.collections[-1].colorbar\n",
    "cbar.ax.set_ylabel(\"Fraction Significant\\nDifferential Perturbations\", fontsize=5)\n",
    "ax.set_ylabel(\"Target Gene Set\", fontsize=7)\n",
    "ax.set_xlabel(\"Perturbagen (Overexpression)\", fontsize=7)\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(\"Perurbation_overexpression_{}.svg\".format(celltype), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def full_overexpression(trait, celltype, restriction=set(), nrandom=100):\n",
    "    import matplotlib as mpl\n",
    "    from speos.utils.config import Config\n",
    "    from speos.preprocessing.handler import InputHandler\n",
    "    import os \n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # set font\n",
    "    mpl.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "    full_width = 18\n",
    "    cm = 1/2.54\n",
    "    small_font = 6\n",
    "    medium_font = 8\n",
    "    large_font = 10\n",
    "    mpl.rc('xtick', labelsize=small_font)\n",
    "    mpl.rc('ytick', labelsize=small_font)\n",
    "    mpl.rcParams['axes.linewidth'] = 0.4\n",
    "    mpl.rcParams['ytick.major.size'] = 3\n",
    "    mpl.rcParams['ytick.major.width'] = 0.5\n",
    "    mpl.rcParams['ytick.minor.size'] = 2\n",
    "    mpl.rcParams['ytick.minor.width'] = 0.3\n",
    "    mpl.rcParams['xtick.major.size'] = 2\n",
    "    mpl.rcParams['xtick.major.width'] = 0.3\n",
    "    mpl.rcParams['xtick.minor.size'] = 1\n",
    "    mpl.rcParams['xtick.minor.width'] = 0.1\n",
    "\n",
    "    os.chdir(\"..\")\n",
    "    config = Config()\n",
    "    if trait == \"ad\":\n",
    "        configstring = \"alz\"\n",
    "    elif trait == \"cad\":\n",
    "        configstring = \"cad_really\"\n",
    "    else:\n",
    "        configstring = trait\n",
    "    config.parse_yaml(\"/home/ubuntu/speos/config_{}_only_nohetio_film_newstorage.yaml\".format(configstring))\n",
    "    prepro = InputHandler(config).get_preprocessor()\n",
    "    prepro.build_graph(adjacency=False)\n",
    "    background = set(prepro.id2hgnc.values())\n",
    "    os.chdir(\"notebooks\")\n",
    "\n",
    "    print (\"Starting OE Analysis for {} {}\".format(trait, celltype))\n",
    "    if isinstance(trait, str):\n",
    "        allcore, other_coregenes, hsps,  noncore = get_coregenes(trait, background)\n",
    "        traitstring = trait\n",
    "    else:\n",
    "        allcore = set()\n",
    "        other_coregenes = set()\n",
    "        hsps = set()\n",
    "        noncore = set(list(background)[:])\n",
    "        for _trait in trait:\n",
    "            _allcore, _other_coregenes, _hsps,  _noncore = get_coregenes(_trait, background)\n",
    "            allcore.update(set(_allcore))\n",
    "            other_coregenes.update(set(_other_coregenes))\n",
    "            hsps.update(set(_hsps))\n",
    "            noncore = noncore.intersection(_noncore)\n",
    "        traitstring = \"_\".join(trait)\n",
    "\n",
    "\n",
    "\n",
    "    full_df = pd.read_csv(\"/mnt/storage/cmap/2017/oe_df_{}.tsv\".format(celltype), header=0, sep=\"\\t\", index_col=0)\n",
    "\n",
    "    gene_df = pd.read_csv(\"/mnt/storage/cmap/2017/GSE92742_Broad_LINCS_gene_info.txt\", sep=\"\\t\", header=0, index_col=None)\n",
    "    good_genes = gene_df.pr_gene_symbol[gene_df.pr_is_bing == 1].tolist()\n",
    "\n",
    "    full_df = full_df.loc[full_df.index.isin(good_genes), :]\n",
    "\n",
    "    if len(restriction) > 0:\n",
    "        restriction = [column for column in full_df.columns if column.split(\".\")[0] in restriction]\n",
    "        full_df = full_df[list(restriction)]\n",
    "        typestring = celltype + \"_restricted\"\n",
    "    else:\n",
    "        typestring = celltype\n",
    "    \n",
    "    get_differential_percentages(full_df, allcore, hsps, noncore, use_mean=True)[0].transpose().to_csv(\"/mnt/storage/cmap/2017/differential_perturbation_overexpression_{}_{}.tsv\".format(traitstring, typestring), sep=\"\\t\")\n",
    "\n",
    "    results_df, total, core_result, hsp_result, peri_result = get_differential_percentages(full_df, allcore, hsps, noncore, use_mean=True)\n",
    "    \n",
    "    gwas_genes = set(pd.read_csv(\"../hsps/gwas_genes_closest/5e-8/uc_gwas_genes.tsv\", header=0, sep=\"\\t\", index_col=None)[\"HGNC\"].tolist()).intersection(prepro.id2hgnc.values())\n",
    "    gwas_results_df, _, gwas_core_result, gwas_hsp_result, gwas_peri_result = get_differential_percentages(full_df, allcore, hsps, noncore,  use_min=False, use_mean=True, alternative_core=gwas_genes)\n",
    "    gwas_results_df.transpose().to_csv(\"/mnt/storage/cmap/2017/differential_perturbation_overexpression_gwas_{}_{}.tsv\".format(traitstring, typestring), sep=\"\\t\")\n",
    "\n",
    "\n",
    "    random_core = []\n",
    "    random_hsp = []\n",
    "    random_peri = []\n",
    "    for i in range(nrandom):\n",
    "        _, _, core_result_random, hsp_result_random, peri_result_random = get_differential_percentages(full_df, allcore, hsps, noncore,use_min=False, use_mean=True, randomize_core=True, random_seed=i)\n",
    "        random_core.append(core_result_random[0])\n",
    "        random_hsp.append(hsp_result_random[0])\n",
    "        random_peri.append(peri_result_random[0])\n",
    "\n",
    "    results_df = results_df.transpose()\n",
    "        \n",
    "    fig, ax= plt.subplots(figsize=(8*cm,4*cm))\n",
    "\n",
    "    num_target_core_genes = len(allcore.intersection(set(full_kd_df.index)))\n",
    "\n",
    "    \n",
    "    kd_matrix_mean = pd.DataFrame(index=[\"HSP\" + \"\\n(n=%s)\" % hsp_result[1], \"Peripheral\\n\" + \"(n=%s)\" % peri_result[1], \"Core Gene\\n\" + \"(n=%s)\" % core_result[1]],\n",
    "                         data={\"Core Genes\\n\" + \"n={}\".format(num_target_core_genes): [hsp_result[0], peri_result[0],  core_result[0]],\n",
    "                               \"GWAS Genes\\n\" + \"n={}\".format(len(gwas_genes)): [gwas_hsp_result[0], gwas_peri_result[0],  gwas_core_result[0]],\n",
    "                               \"Random Genes\\n\" + \"n={} ({}x)\".format(num_target_core_genes, len(random_hsp)): [np.mean(random_hsp), np.mean(random_peri), np.mean(random_core)]})\n",
    "\n",
    "    ax = sns.heatmap(kd_matrix_mean.transpose(), vmin=0,  vmax=1, cmap=\"Oranges\", annot=True, fmt=\".1%\", ax=ax, \n",
    "                 annot_kws = {\"fontsize\": 8},\n",
    "                 cbar_kws={'label': \"Fraction Significant\\nDifferential Perturbations\",\n",
    "                           \"pad\": 0.01})\n",
    "    ax.tick_params(axis='y', labelrotation=0)\n",
    "    ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 6)\n",
    "    cbar = ax.collections[-1].colorbar\n",
    "    cbar.ax.set_ylabel(\"Fraction Discriminative\\nPerturbations\", fontsize=7)\n",
    "    ax.set_ylabel(\"Target Gene Set\", fontsize=7)\n",
    "    ax.set_xlabel(\"Perturbagen (Overexpression)\", fontsize=7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"Perturbation_overexpression_{}_{}.svg\".format(traitstring, typestring), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_overexpression(\"uc\", \"HT29\", nrandom=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "traits = [\"uc\", \"ra\", \"cad\", \"ad\", \"scz\"]\n",
    "celltypes = [\"PC3\", \"HT29\", \"HEK293T\"]\n",
    "\n",
    "combinations = []\n",
    "\n",
    "for trait in traits:\n",
    "    for celltype in celltypes:\n",
    "        combinations.append((trait, celltype))\n",
    "\n",
    "with tqdm_joblib(tqdm(desc=\"My calculation\", total=len(combinations))) as progress_bar:\n",
    "    Parallel(n_jobs=len(combinations))(delayed(full_overexpression)(trait, celltype) for (trait, celltype) in combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# and restricted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "traits = [\"uc\", \"ra\", \"cad\", \"ad\", \"scz\"]\n",
    "celltypes = [\"PC3\", \"HT29\", \"HEK293T\"]\n",
    "\n",
    "combinations = []\n",
    "restriction = set(pd.read_csv(\"/mnt/storage/cmap/2017/oe_df_HEK293T.tsv\", header=0, sep=\"\\t\", index_col=0).columns.tolist())\n",
    "restriction = restriction.intersection(set(pd.read_csv(\"/mnt/storage/cmap/2017/oe_df_PC3.tsv\", header=0, sep=\"\\t\", index_col=0).columns.tolist()))\n",
    "restriction = restriction.intersection(set(pd.read_csv(\"/mnt/storage/cmap/2017/oe_df_HT29.tsv\", header=0, sep=\"\\t\", index_col=0).columns.tolist()))\n",
    "\n",
    "\n",
    "\n",
    "for trait in traits:\n",
    "    for celltype in celltypes:\n",
    "        combinations.append((trait, celltype))\n",
    "        #restrictions.append(pd.read_csv(\"/mnt/storage/cmap/2017/oe_df_HEK293T.tsv\", header=0, sep=\"\\t\", index_col=0).columns.tolist())\n",
    "\n",
    "with tqdm_joblib(tqdm(desc=\"My calculation\", total=len(combinations))) as progress_bar:\n",
    "    Parallel(n_jobs=len(combinations))(delayed(full_overexpression)(trait, celltype, id2hgnc.values(), restriction) for trait, celltype in combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype = \"HT29\"\n",
    "\n",
    "full_df = pd.read_csv(\"/mnt/storage/cmap/2017/oe_df_{}.tsv\".format(celltype), header=0, sep=\"\\t\", index_col=0)\n",
    "\n",
    "allcore, _, hsps, noncore = get_coregenes(\"uc\", id2hgnc.values())\n",
    "\n",
    "gene_df = pd.read_csv(\"/mnt/storage/cmap/2017/GSE92742_Broad_LINCS_gene_info.txt\", sep=\"\\t\", header=0, index_col=None)\n",
    "good_genes = gene_df.pr_gene_symbol[gene_df.pr_is_bing == 1].tolist()\n",
    "\n",
    "full_df = full_df.loc[full_df.index.isin(good_genes), :]\n",
    "\n",
    "\n",
    "results_df, total, core_result, hsp_result, peri_result = get_differential_percentages(full_df, allcore, hsps, noncore, use_min=True)\n",
    "results_df = results_df.transpose()\n",
    "results_df = results_df[(results_df[\"Core Gene\"] + results_df[\"HSP\"] + results_df[\"Peripheral\"]).values.astype(np.bool_)]\n",
    "results_df = results_df[results_df[\"FDR\"] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speos.visualization.settings import *\n",
    "from matplotlib.patches import Patch\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(full_width*cm*0.5, 8*cm))\n",
    "ax.set_ylim(bottom=5, top=1e65)\n",
    "ax.set_xlim(left=-0.7)\n",
    "all_significant = results_df[\"meandiff\"]\n",
    "core_significant = results_df[\"meandiff\"][results_df[\"Core Gene\"]]\n",
    "hsp_significant = results_df[\"meandiff\"][results_df[\"HSP\"]]\n",
    "peri_significant = results_df[\"meandiff\"][results_df[\"Peripheral\"]]\n",
    "\n",
    "core_fdr = results_df[\"FDR\"][(results_df[\"FDR\"] < 0.05) & (results_df[\"Core Gene\"])]\n",
    "hsp_fdr = results_df[\"FDR\"][(results_df[\"FDR\"] < 0.05) & (results_df[\"HSP\"])]\n",
    "peri_fdr = results_df[\"FDR\"][(results_df[\"FDR\"] < 0.05) & (results_df[\"Peripheral\"])]\n",
    "ax.set_yscale(\"log\")\n",
    "ax.scatter(x=peri_significant,y = 1 / peri_fdr, s=5, c=\"#8a8a8a\")\n",
    "ax.scatter(x=core_significant,y = 1 / core_fdr, s=5, c=\"#01016f\")\n",
    "ax.scatter(x=hsp_significant,y = 1 / hsp_fdr, s=5, c=\"#d8031c\")\n",
    "\n",
    "\n",
    "texts = []\n",
    "sorted_df = results_df.sort_values(by=\"FDR\", ascending=True)\n",
    "already_printed = []\n",
    "for i in range(8):\n",
    "    texts.append(ax.text(sorted_df[\"meandiff\"][i], 1/sorted_df[\"FDR\"][i], sorted_df.index[i], size=4, va=\"center\"))\n",
    "    already_printed.append(sorted_df.index[i])\n",
    "\n",
    "adjust_text(texts, x=results_df[\"meandiff\"].values.tolist(), y= (1/results_df[\"FDR\"].values).tolist(), force_points=3, arrowprops=dict(arrowstyle='-', color='black', lw=0.5), ax=ax)\n",
    "\n",
    "texts = []\n",
    "sorted_df = results_df.sort_values(by=\"meandiff\", ascending=True)\n",
    "for i in range(3):\n",
    "    if sorted_df.index[i] not in already_printed:\n",
    "      texts.append(ax.text(sorted_df[\"meandiff\"][i], 1/sorted_df[\"FDR\"][i], sorted_df.index[i], size=4, va=\"center\"))\n",
    "      already_printed.append(sorted_df.index[i])\n",
    "\n",
    "sorted_df = results_df.sort_values(by=\"meandiff\", ascending=False)\n",
    "for i in range(8):\n",
    "    if sorted_df.index[i] not in already_printed:\n",
    "      texts.append(ax.text(sorted_df[\"meandiff\"][i], 1/sorted_df[\"FDR\"][i], sorted_df.index[i], size=4, va=\"center\"))\n",
    "      already_printed.append(sorted_df.index[i])\n",
    "\n",
    "sorted_df = results_df[results_df[\"meandiff\"] < 0].sort_values(by=\"FDR\", ascending=True)\n",
    "for i in range(3):\n",
    "    if sorted_df.index[i] not in already_printed:\n",
    "      texts.append(ax.text(sorted_df[\"meandiff\"][i], 1/sorted_df[\"FDR\"][i], sorted_df.index[i], size=4, va=\"center\"))\n",
    "      already_printed.append(sorted_df.index[i])\n",
    "\n",
    "adjust_text(texts, x=results_df[\"meandiff\"].values.tolist(), y=(1/results_df[\"FDR\"].values).tolist(), force_points=10, arrowprops=dict(arrowstyle='-', color='black', lw=0.5), ax=ax)\n",
    "\n",
    "\n",
    "texts = []\n",
    "hsp_df = results_df[results_df[\"HSP\"]]\n",
    "for i in range(len(hsp_df)):\n",
    "   texts.append(ax.text(hsp_df[\"meandiff\"][i], 1/hsp_df[\"FDR\"][i], hsp_df.index[i], size=4, va=\"center\"))\n",
    "\n",
    "adjust_text(texts, x=results_df[\"meandiff\"].values.tolist(), y=(1/results_df[\"FDR\"].values).tolist(), force_points=0.5, arrowprops=dict(arrowstyle='-', color='black', lw=0.5), ax=ax)\n",
    "\n",
    "\n",
    "ax.vlines(0, 1/0.05, 10e40, color=\"gray\", linestyles=\":\")\n",
    "\n",
    "ax.text(-0.01, y=10e39, s=\"{:.1f}%\".format(((all_significant < 0).sum() / len(all_significant)) * 100), ha=\"right\", va=\"top\", fontsize=8)\n",
    "ax.text(+0.01, y=10e39, s=\"{:.1f}%\".format(((all_significant > 0).sum() / len(all_significant)) * 100), ha=\"left\", va=\"top\", fontsize=8)\n",
    "\n",
    "ax.text(-0.01, y=10e36, s=\"{:.1f}%\".format(((peri_significant < 0).sum() / len(peri_significant)) * 100), ha=\"right\", va=\"top\", color=\"#8a8a8a\", fontsize=8)\n",
    "ax.text(+0.01, y=10e36, s=\"{:.1f}%\".format(((peri_significant > 0).sum() / len(peri_significant)) * 100), ha=\"left\", va=\"top\", color=\"#8a8a8a\", fontsize=8)\n",
    "\n",
    "ax.text(-0.01, y=10e33, s=\"{:.1f}%\".format(((core_significant < 0).sum() / len(core_significant)) * 100), ha=\"right\", va=\"top\", color=\"#01016f\", fontsize=8)\n",
    "ax.text(+0.01, y=10e33, s=\"{:.1f}%\".format(((core_significant > 0).sum() / len(core_significant)) * 100), ha=\"left\", va=\"top\", color=\"#01016f\", fontsize=8)\n",
    "\n",
    "ax.text(-0.01, y=10e30, s=\"{:.1f}%\".format(((hsp_significant < 0).sum() / len(hsp_significant)) * 100), ha=\"right\", va=\"top\", color=\"#d8031c\", fontsize=8)\n",
    "ax.text(+0.01, y=10e30, s=\"{:.1f}%\".format(((hsp_significant > 0).sum() / len(hsp_significant)) * 100), ha=\"left\", va=\"top\", color=\"#d8031c\", fontsize=8)\n",
    "\n",
    "legend_elements = [Patch(facecolor='black', edgecolor='black',\n",
    "                         label='Any\\nn={}'.format(len(all_significant))),\n",
    "                   Patch(facecolor='#8a8a8a', edgecolor='#8a8a8a',\n",
    "                         label='Peripheral\\nn={}'.format(len(peri_significant))),\n",
    "                   Patch(facecolor='#01016f', edgecolor='#01016f',\n",
    "                         label='Core Gene\\nn={}'.format(len(core_significant))),\n",
    "                   Patch(facecolor='#d8031c', edgecolor=\"#d8031c\",\n",
    "                         label='HSP\\nn={}'.format(len(hsp_significant)))]\n",
    "\n",
    "\n",
    "leg = ax.legend(handles=legend_elements, loc='upper left', title=\"Perturbagen\", fontsize=6.8, title_fontsize=7, ncol=2, columnspacing=0.5, handletextpad=-0.5)\n",
    "\n",
    "for patch in leg.get_patches():\n",
    "    patch.set_height(15)\n",
    "    patch.set_width(5)\n",
    "    patch.set_y(-5)\n",
    "\n",
    "\n",
    "ax.set_ylabel(r\"$-\\log(FDR)$\")\n",
    "ax.set_xlabel(\"Mean Differential Perturbation\\n(Core Gene - Peripheral)\")\n",
    "#plt.tight_layout()\n",
    "plt.savefig(\"Volcano_Overexpression_all.svg\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests for overrepresentation of HSPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "p1 = 1\n",
    "p2_1 = 0.3\n",
    "p2_2 = 0.312\n",
    "\n",
    "\n",
    "n1 = 4\n",
    "n2_1 = 2339\n",
    "n2_2 = 28\n",
    "\n",
    "n2 = n2_1 + n2_2\n",
    "p2 = ((n2_1 * p2_1) + (n2_2 * p2_2)) / n2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (p1 - p2) / np.sqrt(0.33 * ( 1- 0.33) * ((1 / n1) + (1 / n2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "proportions_ztest([n1*p1, n2*p2], [n1, n2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = 0.5\n",
    "p2_1 = 0.331\n",
    "p2_2 = 0.333\n",
    "\n",
    "\n",
    "n1 = 2\n",
    "n2_1 = 1532\n",
    "n2_2 = 183\n",
    "\n",
    "n2 = n2_1 + n2_2\n",
    "p2 = ((n2_1 * p2_1) + (n2_2 * p2_2)) / n2\n",
    "\n",
    "proportions_ztest([n1*p1, n2*p2], [n1, n2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the number of significant perturbagens across all traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for direction in [\"knockdown\", \"overexpression\"]:\n",
    "    truths = []\n",
    "    for trait in [\"uc\", \"cad\", \"scz\"]:\n",
    "        df = pd.read_csv(\"/mnt/storage/cmap/2017/differential_perturbation_{}_{}_HT29.tsv\".format(direction, trait), header=0, sep=\"\\t\")\n",
    "        truths.append(df[\"FDR\"] < 0.05)\n",
    "    truths = np.asarray(truths).reshape((-1, 3))\n",
    "    print((truths.sum(axis=1) > 0).sum()  / truths.shape[0])\n",
    "    print(truths.shape[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heretic experiment: test if conserved position is only due to shared perturbagens\n",
    "\n",
    "from speos.utils.config import Config\n",
    "from speos.preprocessing.handler import InputHandler\n",
    "import os \n",
    "os.chdir(\"..\")\n",
    "config = Config()\n",
    "config.parse_yaml(\"/home/ubuntu/speos/config_uc_only_nohetio_film_newstorage.yaml\")\n",
    "prepro = InputHandler(config).get_preprocessor()\n",
    "prepro.build_graph(adjacency=False)\n",
    "os.chdir(\"notebooks\")\n",
    "uccore, other_coregenes, hsps,  noncore = get_coregenes(\"uc\", prepro.id2hgnc.values())\n",
    "racore, _, _,  _ = get_coregenes(\"ra\", prepro.id2hgnc.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_differential_percentages(full_kd_df, uccore, hsps, noncore)[0]\n",
    "(df.transpose().FDR < 0.05).sum() / len(df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_differential_percentages(full_kd_df.loc[~full_kd_df.index.isin(uccore.intersection(racore)), :], uccore, hsps, noncore, alternative_core=uccore.difference(racore))[0]\n",
    "(df.transpose().FDR < 0.05).sum() / len(df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uccore.difference(racore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_differential_percentages(full_kd_df, uccore, hsps, noncore, alternative_core=uccore.intersection(racore))[0]\n",
    "(df.transpose().FDR < 0.05).sum() / len(df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muss zielgene rausnehmen die teil der core gene intesection intersection sind\n",
    "df = get_differential_percentages(full_kd_df, uccore, hsps, noncore, alternative_core=racore.difference(uccore))[0]\n",
    "(df.transpose().FDR < 0.05).sum() / len(df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_differential_percentages(full_kd_df.loc[~full_kd_df.index.isin(uccore), :], uccore, hsps, noncore, alternative_core=racore.difference(uccore))[0]\n",
    "(df.transpose().FDR < 0.05).sum() / len(df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_kd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_kd_df.loc[~full_kd_df.index.isin(uccore.intersection(racore)), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(racore.difference(uccore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_differential_percentages(full_kd_df, uccore, hsps, noncore, alternative_core=uccore.intersection(sczcore))[0]\n",
    "(df.transpose().FDR < 0.05).sum() / len(df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadcore, _, _,  _ = get_coregenes(\"cad\", prepro.id2hgnc.values())\n",
    "adcore, _, _,  _ = get_coregenes(\"ad\", prepro.id2hgnc.values())\n",
    "sczcore, _, _,  _ = get_coregenes(\"scz\", prepro.id2hgnc.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_differential_percentages(full_kd_df, uccore, hsps, noncore, alternative_core=adcore.difference(cadcore))[0]\n",
    "(df.transpose().FDR < 0.05).sum() / len(df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_differential_percentages(full_kd_df, uccore, hsps, noncore, alternative_core=sczcore.difference(adcore))[0]\n",
    "(df.transpose().FDR < 0.05).sum() / len(df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_differential_percentages(full_kd_df, uccore, hsps, noncore, alternative_core=sczcore)[0]\n",
    "(df.transpose().FDR < 0.05).sum() / len(df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_differential_percentages(full_kd_df, uccore, hsps, noncore, alternative_core=adcore)[0]\n",
    "(df.transpose().FDR < 0.05).sum() / len(df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_differential_percentages(full_kd_df, uccore, hsps, noncore, alternative_core=uccore.union(cadcore).union(sczcore))[0]\n",
    "(df.transpose().FDR < 0.05).sum() / len(df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uccore.intersection(sczcore))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = get_differential_percentages(full_kd_df.loc[~full_kd_df.index.isin(uccore.intersection(racore)), :], uccore, hsps, noncore, alternative_core=uccore.difference(racore))[0]\n",
    "(df.transpose().FDR < 0.05).sum() / len(df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/mnt/storage/cmap/2017/differential_perturbation_overexpression_gwas_uc_HT29.tsv\", sep=\"\\t\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.FDR[df[\"Core Gene\"]] < 0.05).sum() / df[\"Core Gene\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.FDR[df[\"Peripheral\"]] < 0.05).sum() / df[\"Peripheral\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = np.random.rand(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = labels.copy()\n",
    "\n",
    "transformed[transformed > 0.5] = 1 - transformed[transformed > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.minimum.reduce([labels, 1-labels]) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
