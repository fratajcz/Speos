{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from speos.preprocessing.handler import InputHandler\n",
    "from speos.utils.config import Config\n",
    "from speos.preprocessing.datasets import DatasetBootstrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.parse_yaml(\"config_uc_only_nohetio_film_newstorage.yaml\")\n",
    "uc_prepro = InputHandler(config).get_preprocessor()\n",
    "uc_prepro.get_data()\n",
    "G = uc_prepro.get_graph()\n",
    "\n",
    "\"\"\"\n",
    "config = Config()\n",
    "config.parse_yaml(\"config_cad_really_only_nohetio_film_newstorage.yaml\")\n",
    "cad_prepro = InputHandler(config).get_preprocessor()\n",
    "cad_prepro.get_data()\n",
    "\n",
    "config = Config()\n",
    "config.parse_yaml(\"config_scz_only_nohetio_film_newstorage.yaml\")\n",
    "scz_prepro = InputHandler(config).get_preprocessor()\n",
    "scz_prepro.get_data()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Some STatistics about the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(G.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_nodes = set()\n",
    "connected_nodes.update(set([edge[0] for edge in G.edges]))\n",
    "connected_nodes.update(set([edge[1] for edge in G.edges]))\n",
    "len(connected_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, adj = uc_prepro.get_data()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(connected_nodes) - X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " (len(connected_nodes) - X.shape[0]) / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[uc_prepro.hgnc2id[\"TNFSF15\"]]\n",
    "\n",
    "# must be 15506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = uc_prepro.get_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = DatasetBootstrapper(holdout_size=config.input.holdout_size, name=config.name, config=config).get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = {}\n",
    "for key, value in dataset.data.edge_index_dict.items():\n",
    "    num_incoming_edges = (value[1, :] == uc_prepro.hgnc2id[\"PARK7\"]).sum()\n",
    "    adjacency[key[1]] = num_incoming_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([value for value in adjacency.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list[G.edges(data=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = {}\n",
    "for key, value in adj.items():\n",
    "    num_incoming_edges = (value[1, :] == uc_prepro.hgnc2id[\"PARK7\"]).sum()\n",
    "    adjacency[key] = num_incoming_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([value for value in adjacency.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from speos.utils.nn_utils import typed_edges_to_sparse_tensor\n",
    "\n",
    "edge_index, encoder = typed_edges_to_sparse_tensor(dataset.data.x, dataset.data.edge_index_dict)\n",
    "edge_index_flat = torch.vstack((edge_index.storage.row(), edge_index.storage.col()))\n",
    "edge_index_flat_reversed = torch.vstack((edge_index.storage.col(), edge_index.storage.row()))\n",
    "#edge_index_flat = add_remaining_self_loops(edge_index_flat)[0]\n",
    "#edge_index_new = SparseTensor(row = edge_index_flat[0, :], col= edge_index_flat[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from extensions.preprocessing import preprocess_labels\n",
    "\n",
    "def get_coregenes(trait: str, background):\n",
    "    trait2name = {\"uc\": \"uc\",\n",
    "                \"cad\": \"cad_really\",\n",
    "                \"scz\": \"scz\",\n",
    "                \"ad\": \"alz\",\n",
    "                \"ra\": \"ra\"}\n",
    "\n",
    "    mendelians = preprocess_labels(\"extensions/{}_only_genes.tsv\".format(trait2name[trait]))\n",
    "\n",
    "    hsps= pd.read_csv(\"hsps/{}.txt\".format(trait), header=None, index_col=None).iloc[:, 0].tolist()\n",
    "\n",
    "    with open(\"/mnt/storage/speos/results/{}_film_nohetioouter_results.json\".format(trait2name[trait]), \"r\") as file:\n",
    "        candidate2cs = json.load(file)[0]\n",
    "\n",
    "    coregenes = [key for key, value in candidate2cs.items() if value == 11]\n",
    "\n",
    "    other_coregenes = [key for key, value in candidate2cs.items() if value != 11]\n",
    "\n",
    "    allcore = set()\n",
    "    allcore.update(set(coregenes))\n",
    "    allcore.update(set(mendelians))\n",
    "    allcore = allcore.intersection(set(background))\n",
    "\n",
    "    noncore = set(background).difference(allcore).difference(other_coregenes)\n",
    "\n",
    "    return allcore, other_coregenes, hsps,  noncore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc_core, uc_weakcore, uc_hsps,  uc_noncore = get_coregenes(\"uc\", uc_prepro.id2hgnc.values())\n",
    "\n",
    "uc_core_indices = torch.LongTensor([uc_prepro.hgnc2id[hgnc] for hgnc in uc_core])\n",
    "\n",
    "uc_core_indices_weak = torch.LongTensor([uc_prepro.hgnc2id[hgnc] for hgnc in uc_weakcore])\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data.y.long().sum()\n",
    "# must be 379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coregenes = dataset.data.y.long() \n",
    "coregenes[uc_core_indices] = 1\n",
    "coregenes.sum()\n",
    "\n",
    "coregenes_weak = torch.zeros_like(coregenes)\n",
    "coregenes_weak[uc_core_indices_weak] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.in_degree(uc_prepro.hgnc2id[\"PARK7\"])\n",
    "# must be 120, or 251?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(edge_index_flat[1, :] == uc_prepro.hgnc2id[\"PARK7\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.out_degree(uc_prepro.hgnc2id[\"PARK7\"])\n",
    "# must be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See if HSPs are \"closer\" to core genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.models import LabelPropagation\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hsp_indices = [uc_prepro.hgnc2id[hgnc] for hgnc in uc_hsps]\n",
    "hsp_y = torch.zeros_like(dataset.data.y)\n",
    "hsp_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "\n",
    "def plot_labelprop(edge_index, hsp_y, coregenes, coregenes_weak, prepro, weights=None):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "    full_width = 18\n",
    "    cm = 1/2.54\n",
    "    small_font = 6\n",
    "    medium_font = 8\n",
    "    large_font = 10\n",
    "    mpl.rc('xtick', labelsize=small_font)\n",
    "    mpl.rc('ytick', labelsize=small_font)\n",
    "    mpl.rcParams['axes.linewidth'] = 0.4\n",
    "    mpl.rcParams['ytick.major.size'] = 3\n",
    "    mpl.rcParams['ytick.major.width'] = 0.5\n",
    "    mpl.rcParams['ytick.minor.size'] = 2\n",
    "    mpl.rcParams['ytick.minor.width'] = 0.3\n",
    "    mpl.rcParams['xtick.major.size'] = 2\n",
    "    mpl.rcParams['xtick.major.width'] = 0.3\n",
    "    mpl.rcParams['xtick.minor.size'] = 1\n",
    "    mpl.rcParams['xtick.minor.width'] = 0.1\n",
    "\n",
    "    reverse_edge_index = torch.vstack((edge_index[1, :], edge_index[0, :]))\n",
    "\n",
    "    #weights = torch.ones_like(edge_index[0, :]) if weights is None else weights\n",
    "\n",
    "    fig, axes = plt.subplots(1, 6, figsize=(full_width*cm,5*cm), sharey=False)\n",
    "    pvals = []\n",
    "    stats = []\n",
    "    ys = []\n",
    "\n",
    "    for i, (num_layers, edges, ax) in enumerate(zip((1,3,5,1,3,5), [edge_index, edge_index, edge_index, reverse_edge_index, reverse_edge_index, reverse_edge_index], axes)):\n",
    "                                \n",
    "        model = LabelPropagation(num_layers=num_layers, alpha=0.9)\n",
    "        out = model(hsp_y.long(), edges, edge_weight=weights)\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df[\"HGNC\"] = list(prepro.id2hgnc.values())\n",
    "        df[\"coregenes\"] = coregenes\n",
    "        df[\"weak_coregenes\"] = coregenes_weak\n",
    "        df[\"total_coregenes\"] = coregenes_weak + coregenes\n",
    "        df[\"hsp\"] = hsp_y\n",
    "        df[\"propagated\"] = out[:, 1]\n",
    "\n",
    "        new_df = df[df[\"hsp\"] == 0]\n",
    "        new_df = new_df[new_df[\"weak_coregenes\"] == 0]\n",
    "        new_df = new_df[new_df[\"propagated\"] > 0]\n",
    "                                \n",
    "        ax = sns.boxplot(new_df,x =\"coregenes\", y=\"propagated\", fliersize=0.3, ax=ax, order=[1, 0], palette={0: \"darkgray\", 1: \"#01016f\"}, linewidth=1)\n",
    "        if i != 0:\n",
    "            ax.set_ylabel(\"\")\n",
    "        else:\n",
    "            ax.set_ylabel(\"Propagated z'\")\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_xticklabels([\"Core\\n(n={})\".format((new_df[\"coregenes\"] == 1).sum()), \"Peripheral\\n(n={})\".format((new_df[\"coregenes\"] == 0).sum())])\n",
    "        topval = np.quantile(new_df[\"propagated\"], 0.99)\n",
    "        ax.set_ylim((0, topval))\n",
    "\n",
    "        from scipy.stats import mannwhitneyu\n",
    "\n",
    "        result = mannwhitneyu(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], new_df[\"propagated\"][new_df[\"coregenes\"] == 0])\n",
    "        pvals.append(result[1])\n",
    "        stats.append(result[0])\n",
    "\n",
    "        ax.tick_params(axis='x', labelrotation=90)\n",
    "        ys.append(max(np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], 0.75), np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 0], 0.75) ))\n",
    "\n",
    "    pvals = fdrcorrection(pvals)[1]\n",
    "    for ax, pval, y in zip(axes, pvals, ys):\n",
    "\n",
    "        if pval < 0.001:\n",
    "            s = \"***\"\n",
    "        elif pval < 0.01:\n",
    "            s = \"**\"\n",
    "        elif pval < 0.05:\n",
    "            s = \"*\"\n",
    "        else:\n",
    "            s = \"n.s.\"\n",
    "\n",
    "        ax.text(0.5, y=y * 1.2,\n",
    "                    s=s, fontsize=small_font, ha=\"center\")\n",
    "\n",
    "    return fig, df, pvals, stats\n",
    "\n",
    "fig, df, pvals, stats = plot_labelprop(edge_index_flat, hsp_y, coregenes, coregenes_weak, prepro=uc_prepro)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_propagation_pyg.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsp_y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Connection Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import degree\n",
    "from collections import Counter\n",
    "from speos.visualization.settings import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "out_degrees = degree(edge_index_flat[0, :], dataset.data.x.shape[0])\n",
    "in_degrees = degree(edge_index_flat[1, :], dataset.data.x.shape[0])\n",
    "total_degrees = in_degrees + out_degrees\n",
    "\n",
    "\n",
    "\n",
    "out_degree_core = out_degrees[coregenes.nonzero()]\n",
    "out_degree_hsp = out_degrees[hsp_y.nonzero()]\n",
    "out_degree_peripheral = out_degrees[(1 - (coregenes + coregenes_weak + hsp_y)).nonzero()]\n",
    "\n",
    "in_degree_core = in_degrees[coregenes.nonzero()]\n",
    "in_degree_hsp = in_degrees[hsp_y.nonzero()]\n",
    "in_degree_peripheral = in_degrees[(1 - (coregenes + coregenes_weak + hsp_y)).nonzero()]\n",
    "\n",
    "total_degree_core = total_degrees[coregenes.nonzero()]\n",
    "total_degree_hsp = total_degrees[hsp_y.nonzero()]\n",
    "total_degree_peripheral = total_degrees[(1 - (coregenes + coregenes_weak + hsp_y)).nonzero()]\n",
    "\n",
    "\n",
    "out_core_counter = Counter(out_degree_core.squeeze().tolist())\n",
    "out_hsp_counter = Counter(out_degree_hsp.squeeze().tolist())\n",
    "out_peripheral_counter = Counter(out_degree_peripheral.squeeze().tolist())\n",
    "\n",
    "in_core_counter = Counter(in_degree_core.squeeze().tolist())\n",
    "in_hsp_counter = Counter(in_degree_hsp.squeeze().tolist())\n",
    "in_peripheral_counter = Counter(in_degree_peripheral.squeeze().tolist())\n",
    "\n",
    "total_core_counter = Counter(total_degree_core.squeeze().tolist())\n",
    "total_hsp_counter = Counter(total_degree_hsp.squeeze().tolist())\n",
    "total_peripheral_counter = Counter(total_degree_peripheral.squeeze().tolist())\n",
    "\n",
    "out_counter = [out_peripheral_counter, out_core_counter, out_hsp_counter]\n",
    "in_counter = [in_peripheral_counter, in_core_counter, in_hsp_counter]\n",
    "total_counter = [total_peripheral_counter, total_hsp_counter, total_hsp_counter]\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(full_width*cm*1.3,5*cm*1.3), sharey=True, width_ratios=(3,3,3,1.2))\n",
    "\n",
    "for counters, ax, title, xval in zip((out_counter, in_counter, total_counter, None), axes, (\"Out-Degree\", \"In-Degree\", \"Total Degree\", None), (1e5, 1e3 *1.3, 1e4 *6.2, None)):\n",
    "    if title is None:\n",
    "        legend_elements = [Patch(facecolor='#5a5a5a', edgecolor='#5a5a5a',\n",
    "                                label='Peripheral\\nn={}'.format((1 - (coregenes + coregenes_weak)).sum())),\n",
    "                            Patch(facecolor='#01016f', edgecolor='#01016f',\n",
    "                                    label='Core Gene\\nn={}'.format(coregenes.sum())),\n",
    "                            Patch(facecolor='#d8031c', edgecolor='#d8031c',\n",
    "                                    label='HSP\\nn={}'.format(hsp_y.sum().long()))]\n",
    "\n",
    "        leg = ax.legend(handles=legend_elements, loc='center', title=\"Node Class\", fontsize=6.8, title_fontsize=8, ncol=1, columnspacing=1.7, handletextpad=-0.5, labelspacing=1.7)\n",
    "\n",
    "        for patch in leg.get_patches():\n",
    "            patch.set_height(15)\n",
    "            patch.set_width(5)\n",
    "            patch.set_y(-5)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    else:\n",
    "\n",
    "        ax.text(xval, 1e3 * 2, \"Degree 0:\", color=\"black\", fontsize=8, ha=\"right\")\n",
    "        for counter, color, yval, totalnum in zip(counters, (\"#5a5a5a\", \"#01016f\", \"#d8031c\"), (1e3, 1e3 * 0.5, 1e3 * 0.25), ((1 - (coregenes + coregenes_weak)).sum(), coregenes.sum(),hsp_y.sum())):\n",
    "            x, y = zip(*counter.items())           \n",
    "            ax.scatter(x, y, marker='.', color=color, alpha=0.1)   \n",
    "            ax.text(xval, yval, \"{} ({:.1f}%)\".format(counter[0], (counter[0] / totalnum)*100), color=color, fontsize=8, ha=\"right\")  \n",
    "                                            \n",
    "\n",
    "                                                                                                                                                                                                                                                                \n",
    "        # prep axes                                                                                                                      \n",
    "        ax.set_xlabel(title)                                                                                        \n",
    "        ax.set_xscale('log')                                                                                                                \n",
    "        #ax.set_xlim(0.9, max(x) + 0.1 * max(x))  \n",
    "        if title == \"Out-Degree\":                                                                                                        \n",
    "            ax.set_ylabel('Frequency')                                                                                                          \n",
    "        ax.set_yscale('log')                                                                                                                \n",
    "        #ax.set_ylim(0.9, max(y) + 0.1 *max(y))       \n",
    "\n",
    "plt.savefig(\"degree_distributions.svg\", bbox_inches=\"tight\")                                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(full_width*cm*0.1, 0.2*cm))\n",
    "col_map = plt.get_cmap('Reds')\n",
    "cbar = mpl.colorbar.ColorbarBase(ax, cmap=col_map, orientation = 'horizontal', ticks=[0,  0.5,  1])\n",
    "cbar.ax.tick_params(labelsize=5)\n",
    "cbar.set_label(label=\"Propagated $Z'$\",size=6,weight='bold')\n",
    "# As for a more fancy example, you can also give an axes by hand:\n",
    "c_map_ax = fig.add_axes([0.2, 0.8, 0.6, 0.02])\n",
    "c_map_ax.axes.get_xaxis().set_visible(False)\n",
    "c_map_ax.axes.get_yaxis().set_visible(False)\n",
    "plt.tight_layout()\n",
    "# and create another colorbar with:\n",
    "#mpl.colorbar.ColorbarBase(c_map_ax, cmap=col_map, orientation = 'horizontal', )\n",
    "plt.savefig(\"colorbar.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_and_isolated = ((out_degrees == 0 )[coregenes.nonzero()]).sum()\n",
    "hsp_and_isolated = ((out_degrees == 0 )[hsp_y.nonzero()]).sum()\n",
    "core_not_isolated = ((out_degrees > 0 )[coregenes.nonzero()]).sum()\n",
    "hsp_not_isolated = ((out_degrees > 0 )[hsp_y.nonzero()]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "\n",
    "array = np.asarray([[hsp_and_isolated, hsp_not_isolated],\n",
    "                    [core_and_isolated, core_not_isolated]])\n",
    "\n",
    "fisher_exact(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "out_degree_core = out_degrees[coregenes.nonzero()]\n",
    "out_degree_hsp = out_degrees[hsp_y.nonzero()]\n",
    "\n",
    "mannwhitneyu(out_degree_core, out_degree_hsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "out_degree_core = out_degrees[coregenes.nonzero()]\n",
    "out_degree_hsp = out_degrees[hsp_y.nonzero()]\n",
    "\n",
    "mannwhitneyu(out_degree_core[out_degree_core > 0], out_degree_hsp[out_degree_hsp > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degree_counts = Counter(out_degree.tolist())       \n",
    "in_degree_counts = Counter(in_degree.tolist())         \n",
    "\n",
    "fig, axes = plt.subplots(2,1, figsize=(3,6))\n",
    "\n",
    "for counter, ax, title, color in zip((out_degree_counts, in_degree_counts), axes, (\"Out-Degree\", \"In-Degree\"), (\"#03CAF7\", \"#59D52F\")):\n",
    "    x, y = zip(*counter.items())                                                      \n",
    "\n",
    "                                                                                                                                                                                                                                                            \n",
    "    # prep axes                                                                                                                      \n",
    "    ax.set_xlabel('degree')                                                                                        \n",
    "    ax.set_xscale('log')                                                                                                                \n",
    "    ax.set_xlim(0.9, max(x) + 0.1 * max(x))  \n",
    "                                                                                                                \n",
    "    ax.set_ylabel('frequency')                                                                                                          \n",
    "    ax.set_yscale('log')                                                                                                                \n",
    "    ax.set_ylim(0.9, max(y) + 0.1 *max(y))                                                                                                             \n",
    "                                                                                                                                            # do plot                                                                                                                        \n",
    "    ax.scatter(x, y, marker='.', color=color)\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSPs from other Phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsps = pd.read_csv(\"hsps/uc.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [uc_prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0]]\n",
    "hsp_y = torch.zeros_like(dataset.data.y)\n",
    "hsp_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "fig, df, pvals, stats = plot_labelprop(edge_index_flat, hsp_y, coregenes, coregenes_weak, prepro=uc_prepro)\n",
    "\n",
    "#test_df_list.append(pvals)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_propagation_pyg_uc.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "edge_weights = torch.load(\"edge_attributions_tensor_UC.pt\")\n",
    "\n",
    "fig, df, pvals, stats = plot_labelprop(edge_index_flat, hsp_y, coregenes, coregenes_weak, weights=edge_weights, prepro=uc_prepro)\n",
    "\n",
    "#test_df_list.append(pvals)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_propagation_pyg_uc_weighted.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsps = pd.read_csv(\"hsps/cad.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [uc_prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0]]\n",
    "hsp_y = torch.zeros_like(dataset.data.y)\n",
    "hsp_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "fig, df, pvals, stats = plot_labelprop(edge_index_flat, hsp_y, coregenes, coregenes_weak, prepro=uc_prepro)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_propagation_pyg_cad.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hsps = pd.read_csv(\"hsps/scz.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [uc_prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0] if hgnc in uc_prepro.hgnc2id.keys()]\n",
    "hsp_y = torch.zeros_like(dataset.data.y)\n",
    "hsp_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "fig, df, pvals, stats = plot_labelprop(edge_index_flat, hsp_y, coregenes, coregenes_weak, prepro=uc_prepro)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"label_propagation_pyg_scz.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other trait's Coregenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.parse_yaml(\"config_cad_really_only_nohetio_film_newstorage.yaml\")\n",
    "prepro = InputHandler(config).get_preprocessor()\n",
    "prepro.build_graph(adjacency=False)\n",
    "\n",
    "dataset = DatasetBootstrapper(holdout_size=config.input.holdout_size, name=config.name, config=config).get_dataset()\n",
    "   \n",
    "\n",
    "edge_index, encoder = typed_edges_to_sparse_tensor(dataset._data.x, dataset._data.edge_index_dict)\n",
    "edge_index_flat = torch.vstack((edge_index.storage.row(), edge_index.storage.col()))\n",
    "\n",
    "core, weakcore, _,  _ = get_coregenes(\"cad\", prepro.id2hgnc.values())\n",
    "\n",
    "core_indices = torch.LongTensor([prepro.hgnc2id[hgnc] for hgnc in core])\n",
    "core_indices_weak = torch.LongTensor([prepro.hgnc2id[hgnc] for hgnc in weakcore])\n",
    "\n",
    "coregenes = dataset._data.y.long() \n",
    "coregenes[core_indices] = 1\n",
    "print(\"CAD: {} core genes\".format(coregenes.sum()))\n",
    "\n",
    "coregenes_weak = torch.zeros_like(coregenes)\n",
    "coregenes_weak[core_indices_weak] = 1\n",
    "\n",
    "\n",
    "hsps = pd.read_csv(\"hsps/cad.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0]]\n",
    "hsp_y = torch.zeros_like(dataset.data.y)\n",
    "hsp_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "fig, df, pvals, stats = plot_labelprop(edge_index_flat, hsp_y, coregenes, coregenes_weak, prepro=prepro)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_propagation_pyg_target_cad.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.parse_yaml(\"config_scz_only_nohetio_film_newstorage.yaml\")\n",
    "prepro = InputHandler(config).get_preprocessor()\n",
    "prepro.build_graph(adjacency=False)\n",
    "\n",
    "dataset = DatasetBootstrapper(holdout_size=config.input.holdout_size, name=config.name, config=config).get_dataset()\n",
    "   \n",
    "\n",
    "edge_index, encoder = typed_edges_to_sparse_tensor(dataset._data.x, dataset._data.edge_index_dict)\n",
    "edge_index_flat = torch.vstack((edge_index.storage.row(), edge_index.storage.col()))\n",
    "\n",
    "core, weakcore, _,  _ = get_coregenes(\"scz\", prepro.id2hgnc.values())\n",
    "\n",
    "core_indices = torch.LongTensor([prepro.hgnc2id[hgnc] for hgnc in core])\n",
    "core_indices_weak = torch.LongTensor([prepro.hgnc2id[hgnc] for hgnc in weakcore])\n",
    "\n",
    "coregenes = dataset._data.y.long() \n",
    "coregenes[core_indices] = 1\n",
    "print(\"SCZ: {} core genes\".format(coregenes.sum()))\n",
    "\n",
    "coregenes_weak = torch.zeros_like(coregenes)\n",
    "coregenes_weak[core_indices_weak] = 1\n",
    "\n",
    "\n",
    "hsps = pd.read_csv(\"hsps/scz.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0] if  hgnc in prepro.hgnc2id.keys()]\n",
    "hsp_y = torch.zeros_like(dataset.data.y)\n",
    "hsp_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "fig, df, pvals, stats = plot_labelprop(edge_index_flat, hsp_y, coregenes, coregenes_weak, prepro=prepro)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_propagation_pyg_target_scz.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Background Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pvals(_hsp_y, _edge_index, _coregenes, _coregenes_weak, weights=None):\n",
    "    from scipy.stats import mannwhitneyu\n",
    "\n",
    "    edge_index_reversed = torch.vstack((_edge_index[1, :], _edge_index[0, :]))\n",
    "    pvals = []\n",
    "    for i, (num_layers, edges) in enumerate(zip((1,3,5,1,3,5), [_edge_index, _edge_index, _edge_index, edge_index_reversed, edge_index_reversed, edge_index_reversed])):\n",
    "        model = LabelPropagation(num_layers=num_layers, alpha=0.9)\n",
    "        out = model(_hsp_y.long(), edges, edge_weight=weights)\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df[\"coregenes\"] = _coregenes\n",
    "        df[\"weak_coregenes\"] = _coregenes_weak\n",
    "        df[\"total_coregenes\"] = _coregenes_weak + _coregenes\n",
    "        df[\"hsp\"] = _hsp_y\n",
    "        df[\"propagated\"] = out[:, 1]\n",
    "\n",
    "        new_df = df[df[\"hsp\"] == 0]\n",
    "        new_df = new_df[new_df[\"weak_coregenes\"] == 0]\n",
    "        new_df = new_df[new_df[\"propagated\"] > 0]\n",
    "\n",
    "        pvals.append(mannwhitneyu(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], new_df[\"propagated\"][new_df[\"coregenes\"] == 0])[1])\n",
    "\n",
    "    return pvals\n",
    "\n",
    "def get_random_background(trait, weights=False, nrandom = 100, use_seed=1):\n",
    "    import torch\n",
    "    from random import choice, seed\n",
    "    from speos.utils.nn_utils import typed_edges_to_sparse_tensor\n",
    "\n",
    "    config = Config()\n",
    "    config.parse_yaml(\"config_{}_only_nohetio_film_newstorage.yaml\".format(trait if trait != \"cad\" else trait + \"_really\"))\n",
    "    prepro = InputHandler(config).get_preprocessor()\n",
    "    prepro.build_graph(adjacency=False)\n",
    "\n",
    "    dataset = DatasetBootstrapper(holdout_size=config.input.holdout_size, name=config.name, config=config).get_dataset()\n",
    "   \n",
    "\n",
    "    edge_index, encoder = typed_edges_to_sparse_tensor(dataset._data.x, dataset._data.edge_index_dict)\n",
    "    edge_index_flat = torch.vstack((edge_index.storage.row(), edge_index.storage.col()))\n",
    "\n",
    "    core, weakcore, hsps,  _ = get_coregenes(trait, prepro.id2hgnc.values())\n",
    "    core_indices = torch.LongTensor([prepro.hgnc2id[hgnc] for hgnc in core])\n",
    "    core_indices_weak = torch.LongTensor([prepro.hgnc2id[hgnc] for hgnc in weakcore])\n",
    "\n",
    "    coregenes = dataset._data.y.long() \n",
    "    coregenes[core_indices] = 1\n",
    "    print(\"{}: {} core genes\".format(trait, coregenes.sum()))\n",
    "\n",
    "    coregenes_weak = torch.zeros_like(coregenes)\n",
    "    coregenes_weak[core_indices_weak] = 1\n",
    "\n",
    "    if weights:\n",
    "\n",
    "        genes = []\n",
    "        edge_attributions = []\n",
    "\n",
    "        for gene in [prepro.id2hgnc[idx.item()] for idx in coregenes.nonzero()]:\n",
    "            try:\n",
    "                edge_attributions.append(torch.load(\"/mnt/storage/speos/explanations/{}_film_nohetio_ig_attr_edge_total_{}.pt\".format(trait if trait != \"cad\" else trait + \"_really\", gene)).detach().float().cpu().numpy())\n",
    "                genes.append(gene)\n",
    "            except (FileNotFoundError, RuntimeError):\n",
    "                continue\n",
    "\n",
    "        edge_weights = torch.Tensor(np.asarray(edge_attributions).max(axis=0))\n",
    "    else:\n",
    "        edge_weights = None\n",
    "        \n",
    "\n",
    "    seed(use_seed)\n",
    "    test_df_list = []\n",
    "\n",
    "    for anothertrait in [\"uc\", \"cad\", \"scz\"]:\n",
    "        hsps = pd.read_csv(\"hsps/{}.txt\".format(anothertrait), header=None, index_col=None, sep=\"\\t\").iloc[:, 0].tolist()\n",
    "        hsp_indices = [prepro.hgnc2id[hsp] for hsp in hsps if hsp in prepro.hgnc2id.keys()]\n",
    "        hsp_y = torch.zeros_like(dataset._data.y)\n",
    "        hsp_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "        test_df_list.append(get_pvals(hsp_y, edge_index_flat, coregenes, coregenes_weak, edge_weights))\n",
    "\n",
    "    hsps = pd.read_csv(\"hsps/{}.txt\".format(trait), header=None, index_col=None, sep=\"\\t\").iloc[:, 0].tolist()\n",
    "    runs = 0\n",
    "    while runs < nrandom:\n",
    "        try:\n",
    "            hsp_indices = [choice(list(prepro.hgnc2id.values())) for _ in range(len(hsps))]\n",
    "            hsp_y = torch.zeros_like(dataset._data.y)\n",
    "            hsp_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "            pvals = get_pvals(hsp_y, edge_index_flat, coregenes, coregenes_weak, edge_weights)\n",
    "            \n",
    "            test_df_list.append(pvals)\n",
    "            runs += 1\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    test_df_list = np.asarray(test_df_list)\n",
    "    old_shape = test_df_list.shape\n",
    "\n",
    "    adjusted = fdrcorrection(test_df_list.flatten())[1].reshape(old_shape)\n",
    "    test_df = pd.DataFrame(adjusted, index=[\"UC\", \"CAD\", \"SCZ\"] + [\"Random{}\".format(i) for i in range(nrandom)], columns=[\"1\",\"3\",\"5\",\"1_rev\", \"3_rev\", \"5_rev\"])\n",
    "    test_df.to_csv(\"random_labelprop_target_{}_{}.tsv\".format(trait, \"weighted\" if edge_weights is not None else \"unweighted\"), sep=\"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_random_background(\"uc\", nrandom=1000, weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_random_background(\"uc\", nrandom=1000, weights=True)\n",
    "get_random_background(\"cad\", nrandom=1000, weights=False)\n",
    "get_random_background(\"cad\", nrandom=1000, weights=True)\n",
    "get_random_background(\"scz\", nrandom=1000, weights=False)\n",
    "get_random_background(\"scz\", nrandom=1000, weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "traits = [\"uc\", \"cad\", \"scz\"]\n",
    "\n",
    "combinations = []\n",
    "\n",
    "for trait in traits:\n",
    "    combinations.append((trait, False))\n",
    "    combinations.append((trait, True))\n",
    "\n",
    "\n",
    "Parallel(n_jobs=6)(delayed(get_random_background)(trait, nrandom=1000, weights=weights) for (trait, weights) in combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice, seed\n",
    "from scipy.stats import mannwhitneyu\n",
    "from speos.visualization.settings import *\n",
    "\n",
    "test_df_list = []\n",
    "\n",
    "seed(1)\n",
    "for _ in range(500):\n",
    "    hsps = pd.read_csv(\"hsps/uc.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "    hsp_indices = [choice(list(prepro.hgnc2id.values())) for _ in range(len(hsps))]\n",
    "    new_y = torch.zeros_like(new_y)\n",
    "    new_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "    pvals = []\n",
    "    for i, (num_layers, edges) in enumerate(zip((1,3,5,1,3,5), [edge_index_flat, edge_index_flat, edge_index_flat, edge_index_flat_reversed, edge_index_flat_reversed, edge_index_flat_reversed])):\n",
    "                                \n",
    "        model = LabelPropagation(num_layers=num_layers, alpha=0.9)\n",
    "        out = model(new_y.long(), edges, edge_weight=edge_weights)\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df[\"HGNC\"] = list(prepro.id2hgnc.values())\n",
    "        df[\"coregenes\"] = coregenes\n",
    "        df[\"weak_coregenes\"] = coregenes_weak\n",
    "        df[\"total_coregenes\"] = coregenes_weak + coregenes\n",
    "        df[\"hsp\"] = new_y\n",
    "        df[\"propagated\"] = out[:, 1]\n",
    "\n",
    "        new_df = df[df[\"hsp\"] == 0]\n",
    "        new_df = new_df[new_df[\"weak_coregenes\"] == 0]\n",
    "        new_df = new_df[new_df[\"propagated\"] > 0]\n",
    "\n",
    "        from scipy.stats import mannwhitneyu\n",
    "\n",
    "        pval =  mannwhitneyu(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], new_df[\"propagated\"][new_df[\"coregenes\"] == 0])[1]\n",
    "        pvals.append(pval)\n",
    "    test_df_list.append(pvals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_list = np.asarray(test_df_list)\n",
    "old_shape = test_df_list.shape\n",
    "\n",
    "adjusted = fdrcorrection(test_df_list.flatten())[1].reshape(old_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df_list < 0.05).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(adjusted < 0.05).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(adjusted, index=[\"UC\"] + [\"Random{}\".format(i) for i in range(500)], columns=[\"1\",\"3\",\"5\",\"1_rev\", \"3_rev\", \"5_rev\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df.sort_values(\"1\").index == \"UC\").nonzero()[0] / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df.sort_values(\"3\").index == \"UC\").nonzero()[0] / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df.sort_values(\"5\").index == \"UC\").nonzero()[0] / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df.sort_values(\"1_rev\").index == \"UC\").nonzero()[0] / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df.sort_values(\"3_rev\").index == \"UC\").nonzero()[0] / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df.sort_values(\"5_rev\").index == \"UC\").nonzero()[0] / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc_test_df_list = cad_test_df_list.tolist()\n",
    "uc_test_df_list[0] = uc_pvals\n",
    "uc_test_df_list = np.asarray(uc_test_df_list)\n",
    "old_shape = uc_test_df_list.shape\n",
    "\n",
    "adjusted = fdrcorrection(uc_test_df_list.flatten())[1].reshape(old_shape)\n",
    "test_df = pd.DataFrame(adjusted, index=[\"CAD\"] + [\"Random{}\".format(i) for i in range(500)], columns=[\"1\",\"3\",\"5\",\"1_rev\", \"3_rev\", \"5_rev\"])\n",
    "\n",
    "print((test_df.sort_values(\"1\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"3\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"5\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"1_rev\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"3_rev\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"5_rev\").index == \"CAD\").nonzero()[0] / len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For CAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_test_df_list = test_df_list[:]\n",
    "cad_test_df_list[0] = cad_pvals\n",
    "cad_test_df_list = np.asarray(cad_test_df_list)\n",
    "old_shape = cad_test_df_list.shape\n",
    "\n",
    "adjusted = fdrcorrection(cad_test_df_list.flatten())[1].reshape(old_shape)\n",
    "test_df = pd.DataFrame(adjusted, index=[\"CAD\"] + [\"Random{}\".format(i) for i in range(500)], columns=[\"1\",\"3\",\"5\",\"1_rev\", \"3_rev\", \"5_rev\"])\n",
    "\n",
    "print((test_df.sort_values(\"1\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"3\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"5\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"1_rev\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"3_rev\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"5_rev\").index == \"CAD\").nonzero()[0] / len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scz_test_df_list = test_df_list[:]\n",
    "scz_test_df_list[0] = scz_pvals\n",
    "scz_test_df_list = np.asarray(cad_test_df_list)\n",
    "old_shape = scz_test_df_list.shape\n",
    "\n",
    "adjusted = fdrcorrection(scz_test_df_list.flatten())[1].reshape(old_shape)\n",
    "test_df = pd.DataFrame(adjusted, index=[\"SCZ\"] + [\"Random{}\".format(i) for i in range(500)], columns=[\"1\",\"3\",\"5\",\"1_rev\", \"3_rev\", \"5_rev\"])\n",
    "\n",
    "print((test_df.sort_values(\"1\").index == \"SCZ\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"3\").index == \"SCZ\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"5\").index == \"SCZ\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"1_rev\").index == \"SCZ\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"3_rev\").index == \"SCZ\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"5_rev\").index == \"SCZ\").nonzero()[0] / len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "from scipy.stats import rankdata\n",
    "import matplotlib.ticker as tck\n",
    "import seaborn as sns\n",
    "from speos.visualization.settings import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"random_labelprop_target_uc_unweighted.tsv\", index_col=0, header=0, sep=\"\\t\")\n",
    "\n",
    "def plot_random_prop(df, target=\"UC\", others=\"CAD/SCZ\"):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=7, figsize=(full_width*cm, 5*cm))\n",
    "    for ax, str_ind, ind in zip(axes.tolist(), df.columns.tolist() + [\"None\"], range(7)):\n",
    "        if ind < 6:\n",
    "            ax = sns.kdeplot(y = np.log10(df[str_ind]) * -1, cut=0, fill=\"lightblue\", ax=ax)\n",
    "            value = np.quantile(np.log10(df[str_ind]) * -1, 0.95)\n",
    "            pval = (rankdata(df[str_ind])[df[str_ind] == df.loc[target, str_ind]] / len(df))[0]\n",
    "            #if ind > 2:\n",
    "            #    value = np.quantile(np.log10(df[str_ind]) * -1, 0.95)\n",
    "            #    pval = rankdata(df[str_ind])[df[str_ind] == df.loc[\"UC\", str_ind]] / len(df)\n",
    "            #else:\n",
    "            #    value = np.quantile(np.log10(df[str_ind]) * -1, 0.05)\n",
    "            #    pval = 1 - (rankdata(df[str_ind])[df[str_ind] == df.loc[\"UC\", str_ind]] / len(df))\n",
    "            \n",
    "            text = \"p={:.3f}\".format(pval.item())\n",
    "            ax.hlines(value, 0, 0.05, color=\"#5a5a5a\", zorder=2)\n",
    "            ax.hlines(np.log10(df.loc[target, str_ind]) * -1, 0, 0.1, color=\"#d8031c\", zorder=1)\n",
    "            ax.hlines(np.log10(df.loc[others.split(\"/\")[0], str_ind]) * -1, 0, 0.1, color=\"green\", zorder=1)\n",
    "            ax.hlines(np.log10(df.loc[others.split(\"/\")[1], str_ind]) * -1, 0, 0.1, color=\"green\", zorder=1)\n",
    "            ax.set_ylabel(\"\")\n",
    "            #ax.set_title(str_ind)\n",
    "            # Create a Rectangle patch\n",
    "            xlim = ax.get_xlim()\n",
    "            ylim= ax.get_ylim()\n",
    "            ax.hlines(value, 0, xlim[1]*0.4, color=\"#5a5a5a\", zorder=2)\n",
    "            ax.hlines(np.log10(df.loc[target, str_ind]) * -1, 0, xlim[1]*0.8, color=\"#d8031c\", zorder=1)\n",
    "            ax.hlines(np.log10(df.loc[others.split(\"/\")[0], str_ind]) * -1, 0, xlim[1]*0.8, color=\"green\", zorder=1)\n",
    "            ax.hlines(np.log10(df.loc[others.split(\"/\")[1], str_ind]) * -1, 0, xlim[1]*0.8, color=\"green\", zorder=1)\n",
    "            #rect = patches.Rectangle((0, value*0.99 if ind >2 else value*1.01), 0.3, -200 if ind > 2 else 200,  linewidth=0, facecolor='white', alpha=0.7, zorder=5)\n",
    "            ax.text(x=np.mean(xlim), y=ylim[1] * 0.9, s=text, fontsize=5, zorder=7, ha=\"center\")\n",
    "\n",
    "            # Add the patch to the Axes\n",
    "            #ax.add_patch(rect)\n",
    "            ax.set_xlim(xlim)\n",
    "            ax.set_ylim((-0.05, ylim[1]))\n",
    "            #nticks = int(ylim[1] / 8)\n",
    "            #ax.yaxis.set_major_locator(tck.MultipleLocator(nticks))\n",
    "            if ind == 0:\n",
    "                ax.set_ylabel(\"-log(p)\")\n",
    "        else:\n",
    "            legend_elements = [patches.Patch(facecolor='#d8031c', edgecolor='#d8031c',\n",
    "                                    label='{} HSPs'.format(target)),\n",
    "                                patches.Patch(facecolor='green', edgecolor='green',\n",
    "                                        label='{} HSPs'.format(others)),\n",
    "                                patches.Patch(facecolor='#5a5a5a', edgecolor='#5a5a5a',\n",
    "                                        label='95th Percentile')]\n",
    "\n",
    "            leg = ax.legend(handles=legend_elements, loc='center', title=\"p-Values\", fontsize=8, title_fontsize=8, ncol=1, columnspacing=1.7, handletextpad=-0.2, labelspacing=1.7)\n",
    "\n",
    "            for patch in leg.get_patches():\n",
    "                patch.set_height(10)\n",
    "                patch.set_width(10)\n",
    "                patch.set_y(-2.5)\n",
    "            ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.4)\n",
    "        \n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = plot_random_prop(df)\n",
    "\n",
    "plt.savefig(\"pvals_labelprop_uc_new.svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"random_labelprop_target_uc_weighted.tsv\", index_col=0, header=0, sep=\"\\t\")\n",
    "fig, ax = plot_random_prop(df, target=\"UC\", others=\"CAD/SCZ\")\n",
    "\n",
    "plt.savefig(\"pvals_labelprop_uc_weighted.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"random_labelprop_target_cad_unweighted.tsv\", index_col=0, header=0, sep=\"\\t\")\n",
    "fig, ax = plot_random_prop(df,target=\"CAD\", others=\"UC/SCZ\")\n",
    "\n",
    "plt.savefig(\"pvals_labelprop_cad_unweighted.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"random_labelprop_target_cad_weighted.tsv\", index_col=0, header=0, sep=\"\\t\")\n",
    "fig, ax = plot_random_prop(df)\n",
    "\n",
    "plt.savefig(\"pvals_labelprop_cad_weighted.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"random_labelprop_target_scz_unweighted.tsv\", index_col=0, header=0, sep=\"\\t\")\n",
    "\n",
    "fig, ax = plot_random_prop(df, target=\"SCZ\", others=\"UC/CAD\")\n",
    "\n",
    "plt.savefig(\"pvals_labelprop_scz_unweighted.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"random_labelprop_target_scz_weighted.tsv\", index_col=0, header=0, sep=\"\\t\")\n",
    "\n",
    "fig, ax = plot_random_prop(df, target=\"SCZ\", others=\"UC/CAD\")\n",
    "\n",
    "plt.savefig(\"pvals_labelprop_scz_weighted.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Centrality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.parse_yaml(\"config_uc_only_nohetio_film_newstorage.yaml\")\n",
    "uc_prepro = InputHandler(config).get_preprocessor()\n",
    "#G = uc_prepro.get_graph()\n",
    "uc_prepro.build_graph(adjacency=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = uc_prepro.G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "pagerank = nx.pagerank(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centrality = nx.degree_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness = nx.betweenness_centrality(G, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = {i: G.degree([i])[i] for i in range(len(uc_prepro.id2hgnc))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcore, other_coregenes, hsps, noncore = get_coregenes(\"uc\", background=uc_prepro.id2hgnc.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "core_values = [betweenness[uc_prepro.hgnc2id[hgnc]] for hgnc in allcore]\n",
    "peri_values = [betweenness[uc_prepro.hgnc2id[hgnc]] for hgnc in list(noncore) + hsps]\n",
    "sns.boxplot(y = core_values + peri_values, x=[\"Core\"] * len(core_values) + [\"Peripheral\"] * len(peri_values), showfliers=False)\n",
    "mannwhitneyu(core_values, peri_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "core_values = [degree[uc_prepro.hgnc2id[hgnc]] for hgnc in allcore]\n",
    "peri_values = [degree[uc_prepro.hgnc2id[hgnc]] for hgnc in list(noncore) + hsps]\n",
    "sns.boxplot(y = np.log10(np.asarray(core_values + peri_values) +1), x=[\"Core\"] * len(core_values) + [\"Peripheral\"] * len(peri_values), showfliers=False)\n",
    "mannwhitneyu(core_values, peri_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_values = [degree_centrality[uc_prepro.hgnc2id[hgnc]] for hgnc in allcore]\n",
    "peri_values = [degree_centrality[uc_prepro.hgnc2id[hgnc]] for hgnc in list(noncore) + hsps]\n",
    "sns.boxplot(y = np.log10(np.asarray(core_values + peri_values) +1), x=[\"Core\"] * len(core_values) + [\"Peripheral\"] * len(peri_values), showfliers=False)\n",
    "mannwhitneyu(core_values, peri_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "core_values = [pagerank[uc_prepro.hgnc2id[hgnc]] for hgnc in allcore]\n",
    "peri_values = [pagerank[uc_prepro.hgnc2id[hgnc]] for hgnc in list(noncore) + hsps]\n",
    "sns.boxplot(y = core_values + peri_values, x=[\"Core\"] * len(core_values) + [\"Peripheral\"] * len(peri_values), showfliers=False)\n",
    "mannwhitneyu(core_values, peri_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(peri_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc_prepro.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
