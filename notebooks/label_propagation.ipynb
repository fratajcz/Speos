{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from speos.preprocessing.handler import InputHandler\n",
    "from speos.utils.config import Config\n",
    "from speos.preprocessing.datasets import DatasetBootstrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.parse_yaml(\"config_uc_only_nohetio_film_newstorage.yaml\")\n",
    "prepro = InputHandler(config).get_preprocessor()\n",
    "G = prepro.get_graph()\n",
    "prepro.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[prepro.hgnc2id[\"TNFSF15\"]]\n",
    "\n",
    "# must be 15506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepro.get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = DatasetBootstrapper(holdout_size=config.input.holdout_size, name=config.name, config=config).get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.models import LabelPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speos.utils.nn_utils import typed_edges_to_sparse_tensor\n",
    "from torch_geometric.utils import add_remaining_self_loops, to_undirected \n",
    "\n",
    "edge_index, encoder = typed_edges_to_sparse_tensor(dataset.data.x, dataset.data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_sparse import SparseTensor\n",
    "edge_index_flat = torch.vstack((edge_index.storage.row(), edge_index.storage.col()))\n",
    "edge_index_flat_reversed = torch.vstack((edge_index.storage.col(), edge_index.storage.row()))\n",
    "#edge_index_flat = add_remaining_self_loops(edge_index_flat)[0]\n",
    "edge_index_new = SparseTensor(row = edge_index_flat[0, :], col= edge_index_flat[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional\n",
    "\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.typing import Adj, OptTensor, SparseTensor\n",
    "from torch_geometric.utils import one_hot\n",
    "\n",
    "class PULabelPropagation(LabelPropagation):\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        y: Tensor,\n",
    "        edge_index: Adj,\n",
    "        mask: OptTensor = None,\n",
    "        edge_weight: OptTensor = None,\n",
    "        post_step: Optional[Callable[[Tensor], Tensor]] = None,\n",
    "    ) -> Tensor:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            y (torch.Tensor): The ground-truth label information\n",
    "                :math:`\\mathbf{Y}`.\n",
    "            edge_index (torch.Tensor or SparseTensor): The edge connectivity.\n",
    "            mask (torch.Tensor, optional): A mask or index tensor denoting\n",
    "                which nodes are used for label propagation.\n",
    "                (default: :obj:`None`)\n",
    "            edge_weight (torch.Tensor, optional): The edge weights.\n",
    "                (default: :obj:`None`)\n",
    "            post_step (callable, optional): A post step function specified\n",
    "                to apply after label propagation. If no post step function\n",
    "                is specified, the output will be clamped between 0 and 1.\n",
    "                (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        pos_mask = y.clone().bool()\n",
    "\n",
    "        if y.dtype == torch.long and y.size(0) == y.numel():\n",
    "            y = one_hot(y.view(-1))\n",
    "\n",
    "        initial_y = y.clone()\n",
    "\n",
    "        out = y\n",
    "        if mask is not None:\n",
    "            out = torch.zeros_like(y)\n",
    "            out[mask] = y[mask]\n",
    "\n",
    "        if isinstance(edge_index, SparseTensor) and not edge_index.has_value():\n",
    "            edge_index = gcn_norm(edge_index, add_self_loops=False)\n",
    "        elif isinstance(edge_index, Tensor) and edge_weight is None:\n",
    "            edge_index, edge_weight = gcn_norm(edge_index, num_nodes=y.size(0),\n",
    "                                               add_self_loops=False)\n",
    "\n",
    "        res = (1 - self.alpha) * out\n",
    "        for _ in range(self.num_layers):\n",
    "            # propagate_type: (y: Tensor, edge_weight: OptTensor)\n",
    "            out = self.propagate(edge_index, x=out, edge_weight=edge_weight,\n",
    "                                 size=None)\n",
    "            out.mul_(self.alpha).add_(res)\n",
    "\n",
    "            out = torch.nn.functional.normalize(out, p=1, dim=1)\n",
    "\n",
    "            out[pos_mask, 1] = 1\n",
    "            \n",
    "            \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/mnt/storage/speos/results/uc_film_nohetioouter_results.json\", \"r\") as file:\n",
    "    results =  [key for key, value in json.load(file)[0].items() if value >= 11]\n",
    "\n",
    "indices = torch.LongTensor([prepro.hgnc2id[hgnc] for hgnc in results])\n",
    "\n",
    "with open(\"/mnt/storage/speos/results/uc_film_nohetioouter_results.json\", \"r\") as file:\n",
    "    results =  [key for key, value in json.load(file)[0].items() if value >= 1 and value < 11]\n",
    "\n",
    "indices_weak = torch.LongTensor([prepro.hgnc2id[hgnc] for hgnc in results])\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data.y.long().sum()\n",
    "# must be 379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coregenes = dataset.data.y.long() \n",
    "coregenes[indices] = 1\n",
    "coregenes.sum()\n",
    "\n",
    "coregenes_weak = torch.zeros_like(coregenes)\n",
    "coregenes_weak[indices_weak] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coregenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.in_degree(prepro.hgnc2id[\"PARK7\"])\n",
    "# must be 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.out_degree(prepro.hgnc2id[\"PARK7\"])\n",
    "# must be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See if HSPs are \"closer\" to core genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsps = pd.read_csv(\"hsps/uc.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0]]\n",
    "new_y = torch.zeros_like(dataset.data.y)\n",
    "new_y[np.asarray(hsp_indices)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsps = pd.read_csv(\"hsps/uc.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0]]\n",
    "new_y = torch.zeros_like(dataset.data.y)\n",
    "new_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "import seaborn as sns\n",
    "from speos.visualization.settings import *\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 6, figsize=(full_width*cm,5*cm), sharey=False)\n",
    "\n",
    "for i, (num_layers, edges, ax) in enumerate(zip((1,3,5,1,3,5), [edge_index_flat, edge_index_flat, edge_index_flat, edge_index_flat_reversed, edge_index_flat_reversed, edge_index_flat_reversed], axes)):\n",
    "                             \n",
    "    model = LabelPropagation(num_layers=num_layers, alpha=0.9)\n",
    "    out = model(new_y.long(), edges)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"HGNC\"] = list(prepro.id2hgnc.values())\n",
    "    df[\"coregenes\"] = coregenes\n",
    "    df[\"weak_coregenes\"] = coregenes_weak\n",
    "    df[\"total_coregenes\"] = coregenes_weak + coregenes\n",
    "    df[\"hsp\"] = new_y\n",
    "    df[\"propagated\"] = out[:, 1]\n",
    "\n",
    "    new_df = df[df[\"hsp\"] == 0]\n",
    "    new_df = new_df[new_df[\"weak_coregenes\"] == 0]\n",
    "    new_df = new_df[new_df[\"propagated\"] > 0]\n",
    "                             \n",
    "    ax = sns.boxplot(new_df,x =\"coregenes\", y=\"propagated\", fliersize=0.3, ax=ax, order=[1, 0], palette={0: \"#04964d\", 1: \"darkgray\"}, linewidth=1)\n",
    "    if i != 0:\n",
    "        ax.set_ylabel(\"\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"Propagated z'\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticklabels([\"Core\\n(n={})\".format((new_df[\"coregenes\"] == 1).sum()), \"Peripheral\\n(n={})\".format((new_df[\"coregenes\"] == 0).sum())])\n",
    "    topval = np.quantile(new_df[\"propagated\"], 0.99)\n",
    "    ax.set_ylim((0, topval))\n",
    "\n",
    "    from scipy.stats import mannwhitneyu\n",
    "\n",
    "    pval =  mannwhitneyu(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], new_df[\"propagated\"][new_df[\"coregenes\"] == 0])[1] * 6\n",
    "    \n",
    "    if pval < 0.001:\n",
    "        s = \"***\"\n",
    "    elif pval < 0.01:\n",
    "        s = \"**\"\n",
    "    elif pval < 0.05:\n",
    "        s = \"*\"\n",
    "    else:\n",
    "        s = \"n.s.\"\n",
    "\n",
    "    ax.text(0.5, y=max(np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], 0.75), np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 0], 0.75) ) * 1.2,\n",
    "            s=s, fontsize=small_font, ha=\"center\")\n",
    "\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_propagation_pyg.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "hsps = pd.read_csv(\"hsps/uc.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0]]\n",
    "new_y = torch.zeros_like(dataset.data.y)\n",
    "new_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "import seaborn as sns\n",
    "from speos.visualization.settings import *\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 6, figsize=(full_width*cm,5*cm), sharey=False)\n",
    "\n",
    "for i, (num_layers, edges, ax) in enumerate(zip((1,3,5,1,3,5), [edge_index_flat, edge_index_flat, edge_index_flat, edge_index_flat_reversed, edge_index_flat_reversed, edge_index_flat_reversed], axes)):\n",
    "                             \n",
    "    model = LabelPropagation(num_layers=num_layers, alpha=0.9)\n",
    "    out = model(new_y.long(), to_undirected(edges))\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"HGNC\"] = list(prepro.id2hgnc.values())\n",
    "    df[\"coregenes\"] = coregenes\n",
    "    df[\"weak_coregenes\"] = coregenes_weak\n",
    "    df[\"total_coregenes\"] = coregenes_weak + coregenes\n",
    "    df[\"hsp\"] = new_y\n",
    "    df[\"propagated\"] = out[:, 1]\n",
    "\n",
    "    new_df = df[df[\"hsp\"] == 0]\n",
    "    new_df = new_df[new_df[\"weak_coregenes\"] == 0]\n",
    "    new_df = new_df[new_df[\"propagated\"] > 0]\n",
    "                             \n",
    "    ax = sns.boxplot(new_df,x =\"coregenes\", y=\"propagated\", fliersize=0.3, ax=ax, order=[1, 0], palette={0: \"#04964d\", 1: \"darkgray\"}, linewidth=1)\n",
    "    if i != 0:\n",
    "        ax.set_ylabel(\"\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"Propagated z'\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticklabels([\"Core\\n(n={})\".format((new_df[\"coregenes\"] == 1).sum()), \"Peripheral\\n(n={})\".format((new_df[\"coregenes\"] == 0).sum())])\n",
    "    topval = np.quantile(new_df[\"propagated\"], 0.99)\n",
    "    ax.set_ylim((0, topval))\n",
    "\n",
    "    from scipy.stats import mannwhitneyu\n",
    "\n",
    "    pval =  mannwhitneyu(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], new_df[\"propagated\"][new_df[\"coregenes\"] == 0])[1] * 6\n",
    "    \n",
    "    if pval < 0.001:\n",
    "        s = \"***\"\n",
    "    elif pval < 0.01:\n",
    "        s = \"**\"\n",
    "    elif pval < 0.05:\n",
    "        s = \"*\"\n",
    "    else:\n",
    "        s = \"n.s.\"\n",
    "\n",
    "    ax.text(0.5, y=max(np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], 0.75), np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 0], 0.75) ) * 1.2,\n",
    "            s=s, fontsize=small_font, ha=\"center\")\n",
    "\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_propagation_pyg_undirected.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Connection Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import degree\n",
    "from collections import Counter\n",
    "from speos.visualization.settings import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "out_degrees = degree(edge_index_flat[0, :], dataset.data.x.shape[0])\n",
    "in_degrees = degree(edge_index_flat[1, :], dataset.data.x.shape[0])\n",
    "total_degrees = in_degrees + out_degrees\n",
    "\n",
    "\n",
    "\n",
    "out_degree_core = out_degrees[coregenes.nonzero()]\n",
    "out_degree_hsp = out_degrees[new_y.nonzero()]\n",
    "out_degree_peripheral = out_degrees[(1 - (coregenes + coregenes_weak + new_y)).nonzero()]\n",
    "\n",
    "in_degree_core = in_degrees[coregenes.nonzero()]\n",
    "in_degree_hsp = in_degrees[new_y.nonzero()]\n",
    "in_degree_peripheral = in_degrees[(1 - (coregenes + coregenes_weak + new_y)).nonzero()]\n",
    "\n",
    "total_degree_core = total_degrees[coregenes.nonzero()]\n",
    "total_degree_hsp = total_degrees[new_y.nonzero()]\n",
    "total_degree_peripheral = total_degrees[(1 - (coregenes + coregenes_weak + new_y)).nonzero()]\n",
    "\n",
    "\n",
    "out_core_counter = Counter(out_degree_core.squeeze().tolist())\n",
    "out_hsp_counter = Counter(out_degree_hsp.squeeze().tolist())\n",
    "out_peripheral_counter = Counter(out_degree_peripheral.squeeze().tolist())\n",
    "\n",
    "in_core_counter = Counter(in_degree_core.squeeze().tolist())\n",
    "in_hsp_counter = Counter(in_degree_hsp.squeeze().tolist())\n",
    "in_peripheral_counter = Counter(in_degree_peripheral.squeeze().tolist())\n",
    "\n",
    "total_core_counter = Counter(total_degree_core.squeeze().tolist())\n",
    "total_hsp_counter = Counter(total_degree_hsp.squeeze().tolist())\n",
    "total_peripheral_counter = Counter(total_degree_peripheral.squeeze().tolist())\n",
    "\n",
    "out_counter = [out_peripheral_counter, out_core_counter, out_hsp_counter]\n",
    "in_counter = [in_peripheral_counter, in_core_counter, in_hsp_counter]\n",
    "total_counter = [total_peripheral_counter, total_hsp_counter, total_hsp_counter]\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(full_width*cm*1.3,5*cm*1.3), sharey=True, width_ratios=(3,3,3, 1.2))\n",
    "\n",
    "for counters, ax, title, xval in zip((out_counter, in_counter, total_counter, None), axes, (\"Out-Degree\", \"In-Degree\", \"Total Degree\", None), (1e5, 1e3 *1.3, 1e4 *6.2, None)):\n",
    "    if title is None:\n",
    "        legend_elements = [Patch(facecolor='#5a5a5a', edgecolor='#5a5a5a',\n",
    "                                label='Peripheral\\nn={}'.format((1 - (coregenes + coregenes_weak)).sum())),\n",
    "                            Patch(facecolor='#01016f', edgecolor='#01016f',\n",
    "                                    label='Core Gene\\nn={}'.format(coregenes.sum())),\n",
    "                            Patch(facecolor='#d8031c', edgecolor='#d8031c',\n",
    "                                    label='HSP\\nn={}'.format(new_y.sum().long()))]\n",
    "\n",
    "        leg = ax.legend(handles=legend_elements, loc='center', title=\"Node Class\", fontsize=6.8, title_fontsize=8, ncol=1, columnspacing=1.7, handletextpad=-0.5, labelspacing=1.7)\n",
    "\n",
    "        for patch in leg.get_patches():\n",
    "            patch.set_height(15)\n",
    "            patch.set_width(5)\n",
    "            patch.set_y(-5)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    else:\n",
    "\n",
    "        ax.text(xval, 1e3 * 2, \"Degree 0:\", color=\"black\", fontsize=8, ha=\"right\")\n",
    "        for counter, color, yval, totalnum in zip(counters, (\"#5a5a5a\", \"#01016f\", \"#d8031c\"), (1e3, 1e3 * 0.5, 1e3 * 0.25), ((1 - (coregenes + coregenes_weak)).sum(), coregenes.sum(),new_y.sum())):\n",
    "            x, y = zip(*counter.items())           \n",
    "            ax.scatter(x, y, marker='.', color=color, alpha=0.1)   \n",
    "            ax.text(xval, yval, \"{} ({:.1f}%)\".format(counter[0], (counter[0] / totalnum)*100), color=color, fontsize=8, ha=\"right\")  \n",
    "                                            \n",
    "\n",
    "                                                                                                                                                                                                                                                                \n",
    "        # prep axes                                                                                                                      \n",
    "        ax.set_xlabel(title)                                                                                        \n",
    "        ax.set_xscale('log')                                                                                                                \n",
    "        #ax.set_xlim(0.9, max(x) + 0.1 * max(x))  \n",
    "        if title == \"Out-Degree\":                                                                                                        \n",
    "            ax.set_ylabel('Frequency')                                                                                                          \n",
    "        ax.set_yscale('log')                                                                                                                \n",
    "        #ax.set_ylim(0.9, max(y) + 0.1 *max(y))       \n",
    "\n",
    "plt.savefig(\"degree_distributions.svg\", bbox_inches=\"tight\")                                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(full_width*cm*0.1, 0.2*cm))\n",
    "col_map = plt.get_cmap('Reds')\n",
    "cbar = mpl.colorbar.ColorbarBase(ax, cmap=col_map, orientation = 'horizontal', ticks=[0,  0.5,  1])\n",
    "cbar.ax.tick_params(labelsize=5)\n",
    "cbar.set_label(label=\"Propagated $Z'$\",size=6,weight='bold')\n",
    "# As for a more fancy example, you can also give an axes by hand:\n",
    "c_map_ax = fig.add_axes([0.2, 0.8, 0.6, 0.02])\n",
    "c_map_ax.axes.get_xaxis().set_visible(False)\n",
    "c_map_ax.axes.get_yaxis().set_visible(False)\n",
    "plt.tight_layout()\n",
    "# and create another colorbar with:\n",
    "#mpl.colorbar.ColorbarBase(c_map_ax, cmap=col_map, orientation = 'horizontal', )\n",
    "plt.savefig(\"colorbar.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_and_isolated = ((out_degrees == 0 )[coregenes.nonzero()]).sum()\n",
    "hsp_and_isolated = ((out_degrees == 0 )[new_y.nonzero()]).sum()\n",
    "core_not_isolated = ((out_degrees > 0 )[coregenes.nonzero()]).sum()\n",
    "hsp_not_isolated = ((out_degrees > 0 )[new_y.nonzero()]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "\n",
    "array = np.asarray([[hsp_and_isolated, hsp_not_isolated],\n",
    "                    [core_and_isolated, core_not_isolated]])\n",
    "\n",
    "fisher_exact(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "out_degree_core = out_degrees[coregenes.nonzero()]\n",
    "out_degree_hsp = out_degrees[new_y.nonzero()]\n",
    "\n",
    "mannwhitneyu(out_degree_core, out_degree_hsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "out_degree_core = out_degrees[coregenes.nonzero()]\n",
    "out_degree_hsp = out_degrees[new_y.nonzero()]\n",
    "\n",
    "mannwhitneyu(out_degree_core[out_degree_core > 0], out_degree_hsp[out_degree_hsp > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degree_counts = Counter(out_degree.tolist())       \n",
    "in_degree_counts = Counter(in_degree.tolist())         \n",
    "\n",
    "fig, axes = plt.subplots(2,1, figsize=(3,6))\n",
    "\n",
    "for counter, ax, title, color in zip((out_degree_counts, in_degree_counts), axes, (\"Out-Degree\", \"In-Degree\"), (\"#03CAF7\", \"#59D52F\")):\n",
    "    x, y = zip(*counter.items())                                                      \n",
    "\n",
    "                                                                                                                                                                                                                                                            \n",
    "    # prep axes                                                                                                                      \n",
    "    ax.set_xlabel('degree')                                                                                        \n",
    "    ax.set_xscale('log')                                                                                                                \n",
    "    ax.set_xlim(0.9, max(x) + 0.1 * max(x))  \n",
    "                                                                                                                \n",
    "    ax.set_ylabel('frequency')                                                                                                          \n",
    "    ax.set_yscale('log')                                                                                                                \n",
    "    ax.set_ylim(0.9, max(y) + 0.1 *max(y))                                                                                                             \n",
    "                                                                                                                                            # do plot                                                                                                                        \n",
    "    ax.scatter(x, y, marker='.', color=color)\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSPs from other Phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsps = pd.read_csv(\"hsps/uc.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0]]\n",
    "new_y = torch.zeros_like(dataset.data.y)\n",
    "new_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "import seaborn as sns\n",
    "from speos.visualization.settings import *\n",
    "\n",
    "#test_df_list = []\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 6, figsize=(full_width*cm,5*cm), sharey=False)\n",
    "uc_pvals = []\n",
    "for i, (num_layers, edges, ax) in enumerate(zip((1,3,5,1,3,5), [edge_index_flat, edge_index_flat, edge_index_flat, edge_index_flat_reversed, edge_index_flat_reversed, edge_index_flat_reversed], axes)):\n",
    "                             \n",
    "    model = LabelPropagation(num_layers=num_layers, alpha=0.9)\n",
    "    out = model(new_y.long(), edges)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"HGNC\"] = list(prepro.id2hgnc.values())\n",
    "    df[\"coregenes\"] = coregenes\n",
    "    df[\"weak_coregenes\"] = coregenes_weak\n",
    "    df[\"total_coregenes\"] = coregenes_weak + coregenes\n",
    "    df[\"hsp\"] = new_y\n",
    "    df[\"propagated\"] = out[:, 1]\n",
    "\n",
    "    new_df = df[df[\"hsp\"] == 0]\n",
    "    new_df = new_df[new_df[\"weak_coregenes\"] == 0]\n",
    "    new_df = new_df[new_df[\"propagated\"] > 0]\n",
    "                             \n",
    "    ax = sns.boxplot(new_df,x =\"coregenes\", y=\"propagated\", fliersize=0.3, ax=ax, order=[1, 0], palette={0: \"#5a5a5a\", 1: \"#01016f\"}, linewidth=1)\n",
    "    if i != 0:\n",
    "        ax.set_ylabel(\"\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"Propagated z'\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticklabels([\"Core\\n(n={})\".format((new_df[\"coregenes\"] == 1).sum()), \"Peripheral\\n(n={})\".format((new_df[\"coregenes\"] == 0).sum())])\n",
    "    topval = np.quantile(new_df[\"propagated\"], 0.99)\n",
    "    ax.set_ylim((0, topval))\n",
    "\n",
    "    from scipy.stats import mannwhitneyu\n",
    "\n",
    "    pval =  mannwhitneyu(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], new_df[\"propagated\"][new_df[\"coregenes\"] == 0])[1]\n",
    "    uc_pvals.append(pval)\n",
    "    \n",
    "    if pval * 6 < 0.001:\n",
    "        s = \"***\"\n",
    "    elif pval * 6 < 0.01:\n",
    "        s = \"**\"\n",
    "    elif pval * 6 < 0.05:\n",
    "        s = \"*\"\n",
    "    else:\n",
    "        s = \"n.s.\"\n",
    "\n",
    "    ax.text(0.5, y=max(np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], 0.75), np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 0], 0.75) ) * 1.2,\n",
    "            s=s, fontsize=small_font, ha=\"center\")\n",
    "\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "#test_df_list.append(pvals)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_propagation_pyg_uc.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsps = pd.read_csv(\"hsps/uc.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0]]\n",
    "new_y = torch.zeros_like(dataset.data.y)\n",
    "new_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "edge_weights = torch.load(\"edge_attributions_tensor_UC.pt\")\n",
    "\n",
    "import seaborn as sns\n",
    "from speos.visualization.settings import *\n",
    "\n",
    "#test_df_list = []\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 6, figsize=(full_width*cm,5*cm), sharey=False)\n",
    "uc_pvals = []\n",
    "for i, (num_layers, edges, ax) in enumerate(zip((1,3,5,1,3,5), [edge_index_flat, edge_index_flat, edge_index_flat, edge_index_flat_reversed, edge_index_flat_reversed, edge_index_flat_reversed], axes)):\n",
    "                             \n",
    "    model = LabelPropagation(num_layers=num_layers, alpha=0.9)\n",
    "    out = model(new_y.long(), edges, edge_weight=edge_weights)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"HGNC\"] = list(prepro.id2hgnc.values())\n",
    "    df[\"coregenes\"] = coregenes\n",
    "    df[\"weak_coregenes\"] = coregenes_weak\n",
    "    df[\"total_coregenes\"] = coregenes_weak + coregenes\n",
    "    df[\"hsp\"] = new_y\n",
    "    df[\"propagated\"] = out[:, 1]\n",
    "\n",
    "    new_df = df[df[\"hsp\"] == 0]\n",
    "    new_df = new_df[new_df[\"weak_coregenes\"] == 0]\n",
    "    new_df = new_df[new_df[\"propagated\"] > 0]\n",
    "                             \n",
    "    ax = sns.boxplot(new_df,x =\"coregenes\", y=\"propagated\", fliersize=0.3, ax=ax, order=[1, 0], palette={0: \"#5a5a5a\", 1: \"#01016f\"}, linewidth=1)\n",
    "    if i != 0:\n",
    "        ax.set_ylabel(\"\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"Propagated z'\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticklabels([\"Core\\n(n={})\".format((new_df[\"coregenes\"] == 1).sum()), \"Peripheral\\n(n={})\".format((new_df[\"coregenes\"] == 0).sum())])\n",
    "    topval = np.quantile(new_df[\"propagated\"], 0.99)\n",
    "    #ax.set_ylim((0, topval))\n",
    "\n",
    "    from scipy.stats import mannwhitneyu\n",
    "\n",
    "    pval =  mannwhitneyu(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], new_df[\"propagated\"][new_df[\"coregenes\"] == 0])[1]\n",
    "    uc_pvals.append(pval)\n",
    "    \n",
    "    if pval * 6 < 0.001:\n",
    "        s = \"***\"\n",
    "    elif pval * 6 < 0.01:\n",
    "        s = \"**\"\n",
    "    elif pval * 6 < 0.05:\n",
    "        s = \"*\"\n",
    "    else:\n",
    "        s = \"n.s.\"\n",
    "\n",
    "    ax.text(0.5, y=max(np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], 0.75), np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 0], 0.75) ) * 1.2,\n",
    "            s=s, fontsize=small_font, ha=\"center\")\n",
    "\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "#test_df_list.append(pvals)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_propagation_pyg_uc_weighted.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsps = pd.read_csv(\"hsps/cad.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0]]\n",
    "new_y = torch.zeros_like(dataset.data.y)\n",
    "new_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "import seaborn as sns\n",
    "from speos.visualization.settings import *\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 6, figsize=(full_width*cm,5*cm), sharey=False)\n",
    "\n",
    "cad_pvals = []\n",
    "for i, (num_layers, edges, ax) in enumerate(zip((1,3,5,1,3,5), [edge_index_flat, edge_index_flat, edge_index_flat, edge_index_flat_reversed, edge_index_flat_reversed, edge_index_flat_reversed], axes)):\n",
    "                             \n",
    "    model = LabelPropagation(num_layers=num_layers, alpha=0.9)\n",
    "    out = model(new_y.long(), edges)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"HGNC\"] = list(prepro.id2hgnc.values())\n",
    "    df[\"coregenes\"] = coregenes\n",
    "    df[\"weak_coregenes\"] = coregenes_weak\n",
    "    df[\"total_coregenes\"] = coregenes_weak + coregenes\n",
    "    df[\"hsp\"] = new_y\n",
    "    df[\"propagated\"] = out[:, 1]\n",
    "\n",
    "    new_df = df[df[\"hsp\"] == 0]\n",
    "    new_df = new_df[new_df[\"weak_coregenes\"] == 0]\n",
    "    new_df = new_df[new_df[\"propagated\"] > 0]\n",
    "                             \n",
    "    ax = sns.boxplot(new_df,x =\"coregenes\", y=\"propagated\", fliersize=0.3, ax=ax, order=[1, 0], palette={0: \"#5a5a5a\", 1: \"#01016f\"}, linewidth=1)\n",
    "    if i != 0:\n",
    "        ax.set_ylabel(\"\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"Propagated z'\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticklabels([\"Core\\n(n={})\".format((new_df[\"coregenes\"] == 1).sum()), \"Peripheral\\n(n={})\".format((new_df[\"coregenes\"] == 0).sum())])\n",
    "    topval = np.quantile(new_df[\"propagated\"], 0.99)\n",
    "    ax.set_ylim((0, topval))\n",
    "\n",
    "    from scipy.stats import mannwhitneyu\n",
    "\n",
    "    pval =  mannwhitneyu(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], new_df[\"propagated\"][new_df[\"coregenes\"] == 0])[1]\n",
    "    cad_pvals.append(pval)\n",
    "    if pval * 6 < 0.001:\n",
    "        s = \"***\"\n",
    "    elif pval * 6 < 0.01:\n",
    "        s = \"**\"\n",
    "    elif pval * 6 < 0.05:\n",
    "        s = \"*\"\n",
    "    else:\n",
    "        s = \"n.s.\"\n",
    "\n",
    "    ax.text(0.5, y=max(np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], 0.75), np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 0], 0.75) ) * 1.2,\n",
    "            s=s, fontsize=small_font, ha=\"center\")\n",
    "\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_propagation_pyg_cad.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsps = pd.read_csv(\"hsps/cad.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0]]\n",
    "new_y = torch.zeros_like(dataset.data.y)\n",
    "new_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "import seaborn as sns\n",
    "from speos.visualization.settings import *\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 6, figsize=(full_width*cm,5*cm), sharey=False)\n",
    "\n",
    "cad_pvals = []\n",
    "for i, (num_layers, edges, ax) in enumerate(zip((1,3,5,1,3,5), [edge_index_flat, edge_index_flat, edge_index_flat, edge_index_flat_reversed, edge_index_flat_reversed, edge_index_flat_reversed], axes)):\n",
    "                             \n",
    "    model = LabelPropagation(num_layers=num_layers, alpha=0.9)\n",
    "    out = model(new_y.long(), edges, edge_weight=edge_weights)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"HGNC\"] = list(prepro.id2hgnc.values())\n",
    "    df[\"coregenes\"] = coregenes\n",
    "    df[\"weak_coregenes\"] = coregenes_weak\n",
    "    df[\"total_coregenes\"] = coregenes_weak + coregenes\n",
    "    df[\"hsp\"] = new_y\n",
    "    df[\"propagated\"] = out[:, 1]\n",
    "\n",
    "    new_df = df[df[\"hsp\"] == 0]\n",
    "    new_df = new_df[new_df[\"weak_coregenes\"] == 0]\n",
    "    new_df = new_df[new_df[\"propagated\"] > 0]\n",
    "                             \n",
    "    ax = sns.boxplot(new_df,x =\"coregenes\", y=\"propagated\", fliersize=0.3, ax=ax, order=[1, 0], palette={0: \"#5a5a5a\", 1: \"#01016f\"}, linewidth=1)\n",
    "    if i != 0:\n",
    "        ax.set_ylabel(\"\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"Propagated z'\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticklabels([\"Core\\n(n={})\".format((new_df[\"coregenes\"] == 1).sum()), \"Peripheral\\n(n={})\".format((new_df[\"coregenes\"] == 0).sum())])\n",
    "    topval = np.quantile(new_df[\"propagated\"], 0.99)\n",
    "    #ax.set_ylim((0, topval))\n",
    "\n",
    "    from scipy.stats import mannwhitneyu\n",
    "\n",
    "    pval =  mannwhitneyu(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], new_df[\"propagated\"][new_df[\"coregenes\"] == 0])[1]\n",
    "    cad_pvals.append(pval)\n",
    "    if pval * 6 < 0.001:\n",
    "        s = \"***\"\n",
    "    elif pval * 6 < 0.01:\n",
    "        s = \"**\"\n",
    "    elif pval * 6 < 0.05:\n",
    "        s = \"*\"\n",
    "    else:\n",
    "        s = \"n.s.\"\n",
    "\n",
    "    ax.text(0.5, y=max(np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], 0.75), np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 0], 0.75) ) * 1.2,\n",
    "            s=s, fontsize=small_font, ha=\"center\")\n",
    "\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_propagation_pyg_cad_weighted.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "from speos.visualization.settings import *\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "hsps = pd.read_csv(\"hsps/scz.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0] if hgnc in prepro.hgnc2id.keys()]\n",
    "new_y = torch.zeros_like(dataset.data.y)\n",
    "new_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "fig, axes = plt.subplots(1, 6, figsize=(full_width*cm,5*cm), sharey=False)\n",
    "scz_pvals = []\n",
    "for i, (num_layers, edges, ax) in enumerate(zip((1,3,5,1,3,5), [edge_index_flat, edge_index_flat, edge_index_flat, edge_index_flat_reversed, edge_index_flat_reversed, edge_index_flat_reversed], axes)):\n",
    "                             \n",
    "    model = LabelPropagation(num_layers=num_layers, alpha=0.9)\n",
    "    out = model(new_y.long(), edges)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"HGNC\"] = list(prepro.id2hgnc.values())\n",
    "    df[\"coregenes\"] = coregenes\n",
    "    df[\"weak_coregenes\"] = coregenes_weak\n",
    "    df[\"total_coregenes\"] = coregenes_weak + coregenes\n",
    "    df[\"hsp\"] = new_y\n",
    "    df[\"propagated\"] = out[:, 1]\n",
    "\n",
    "    new_df = df[df[\"hsp\"] == 0]\n",
    "    new_df = new_df[new_df[\"weak_coregenes\"] == 0]\n",
    "    new_df = new_df[new_df[\"propagated\"] > 0]\n",
    "                             \n",
    "    ax = sns.boxplot(new_df,x =\"coregenes\", y=\"propagated\", fliersize=0.3, ax=ax, order=[1, 0], palette={0: \"#5a5a5a\", 1: \"#01016f\"}, linewidth=1)\n",
    "    if i != 0:\n",
    "        ax.set_ylabel(\"\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"Propagated z'\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticklabels([\"Core\\n(n={})\".format((new_df[\"coregenes\"] == 1).sum()), \"Peripheral\\n(n={})\".format((new_df[\"coregenes\"] == 0).sum())])\n",
    "    topval = np.quantile(new_df[\"propagated\"], 0.99)\n",
    "    ax.set_ylim((0, topval))\n",
    "\n",
    "    from scipy.stats import mannwhitneyu\n",
    "\n",
    "    pval =  mannwhitneyu(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], new_df[\"propagated\"][new_df[\"coregenes\"] == 0])[1]\n",
    "    scz_pvals.append(pval)\n",
    "    if pval * 6 < 0.001:\n",
    "        s = \"***\"\n",
    "    elif pval * 6 < 0.01:\n",
    "        s = \"**\"\n",
    "    elif pval * 6 < 0.05:\n",
    "        s = \"*\"\n",
    "    else:\n",
    "        s = \"n.s.\"\n",
    "    \n",
    "    ax.text(0.5, y=max(np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], 0.75), np.quantile(new_df[\"propagated\"][new_df[\"coregenes\"] == 0], 0.75) ) * 1.2,\n",
    "            s=s, fontsize=small_font, ha=\"center\")\n",
    "\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"label_propagation_pyg_scz.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice, seed\n",
    "from scipy.stats import mannwhitneyu\n",
    "from speos.visualization.settings import *\n",
    "\n",
    "seed(1)\n",
    "for _ in range(500):\n",
    "    hsps = pd.read_csv(\"hsps/uc.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "    hsp_indices = [choice(list(prepro.hgnc2id.values())) for _ in range(len(hsps))]\n",
    "    new_y = torch.zeros_like(new_y)\n",
    "    new_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "    pvals = []\n",
    "    for i, (num_layers, edges) in enumerate(zip((1,3,5,1,3,5), [edge_index_flat, edge_index_flat, edge_index_flat, edge_index_flat_reversed, edge_index_flat_reversed, edge_index_flat_reversed])):\n",
    "                                \n",
    "        model = LabelPropagation(num_layers=num_layers, alpha=0.9)\n",
    "        out = model(new_y.long(), edges)\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df[\"HGNC\"] = list(prepro.id2hgnc.values())\n",
    "        df[\"coregenes\"] = coregenes\n",
    "        df[\"weak_coregenes\"] = coregenes_weak\n",
    "        df[\"total_coregenes\"] = coregenes_weak + coregenes\n",
    "        df[\"hsp\"] = new_y\n",
    "        df[\"propagated\"] = out[:, 1]\n",
    "\n",
    "        new_df = df[df[\"hsp\"] == 0]\n",
    "        new_df = new_df[new_df[\"weak_coregenes\"] == 0]\n",
    "        new_df = new_df[new_df[\"propagated\"] > 0]\n",
    "\n",
    "        from scipy.stats import mannwhitneyu\n",
    "\n",
    "        pval =  mannwhitneyu(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], new_df[\"propagated\"][new_df[\"coregenes\"] == 0])[1]\n",
    "        pvals.append(pval)\n",
    "    test_df_list.append(pvals)\n",
    "#plt.tight_layout()\n",
    "\n",
    "#plt.savefig(\"label_propagation_pyg_scz.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice, seed\n",
    "from scipy.stats import mannwhitneyu\n",
    "from speos.visualization.settings import *\n",
    "\n",
    "test_df_list = []\n",
    "\n",
    "seed(1)\n",
    "for _ in range(500):\n",
    "    hsps = pd.read_csv(\"hsps/uc.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "    hsp_indices = [choice(list(prepro.hgnc2id.values())) for _ in range(len(hsps))]\n",
    "    new_y = torch.zeros_like(new_y)\n",
    "    new_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "    pvals = []\n",
    "    for i, (num_layers, edges) in enumerate(zip((1,3,5,1,3,5), [edge_index_flat, edge_index_flat, edge_index_flat, edge_index_flat_reversed, edge_index_flat_reversed, edge_index_flat_reversed])):\n",
    "                                \n",
    "        model = LabelPropagation(num_layers=num_layers, alpha=0.9)\n",
    "        out = model(new_y.long(), edges, edge_weight=edge_weights)\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df[\"HGNC\"] = list(prepro.id2hgnc.values())\n",
    "        df[\"coregenes\"] = coregenes\n",
    "        df[\"weak_coregenes\"] = coregenes_weak\n",
    "        df[\"total_coregenes\"] = coregenes_weak + coregenes\n",
    "        df[\"hsp\"] = new_y\n",
    "        df[\"propagated\"] = out[:, 1]\n",
    "\n",
    "        new_df = df[df[\"hsp\"] == 0]\n",
    "        new_df = new_df[new_df[\"weak_coregenes\"] == 0]\n",
    "        new_df = new_df[new_df[\"propagated\"] > 0]\n",
    "\n",
    "        from scipy.stats import mannwhitneyu\n",
    "\n",
    "        pval =  mannwhitneyu(new_df[\"propagated\"][new_df[\"coregenes\"] == 1], new_df[\"propagated\"][new_df[\"coregenes\"] == 0])[1]\n",
    "        pvals.append(pval)\n",
    "    test_df_list.append(pvals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_list = np.asarray(test_df_list)\n",
    "old_shape = test_df_list.shape\n",
    "\n",
    "adjusted = fdrcorrection(test_df_list.flatten())[1].reshape(old_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df_list < 0.05).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(adjusted < 0.05).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(adjusted, index=[\"UC\"] + [\"Random{}\".format(i) for i in range(500)], columns=[\"1\",\"3\",\"5\",\"1_rev\", \"3_rev\", \"5_rev\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df.sort_values(\"1\").index == \"UC\").nonzero()[0] / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df.sort_values(\"3\").index == \"UC\").nonzero()[0] / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df.sort_values(\"5\").index == \"UC\").nonzero()[0] / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df.sort_values(\"1_rev\").index == \"UC\").nonzero()[0] / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df.sort_values(\"3_rev\").index == \"UC\").nonzero()[0] / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_df.sort_values(\"5_rev\").index == \"UC\").nonzero()[0] / len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc_test_df_list = cad_test_df_list.tolist()\n",
    "uc_test_df_list[0] = uc_pvals\n",
    "uc_test_df_list = np.asarray(uc_test_df_list)\n",
    "old_shape = uc_test_df_list.shape\n",
    "\n",
    "adjusted = fdrcorrection(uc_test_df_list.flatten())[1].reshape(old_shape)\n",
    "test_df = pd.DataFrame(adjusted, index=[\"CAD\"] + [\"Random{}\".format(i) for i in range(500)], columns=[\"1\",\"3\",\"5\",\"1_rev\", \"3_rev\", \"5_rev\"])\n",
    "\n",
    "print((test_df.sort_values(\"1\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"3\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"5\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"1_rev\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"3_rev\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"5_rev\").index == \"CAD\").nonzero()[0] / len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For CAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_test_df_list = test_df_list[:]\n",
    "cad_test_df_list[0] = cad_pvals\n",
    "cad_test_df_list = np.asarray(cad_test_df_list)\n",
    "old_shape = cad_test_df_list.shape\n",
    "\n",
    "adjusted = fdrcorrection(cad_test_df_list.flatten())[1].reshape(old_shape)\n",
    "test_df = pd.DataFrame(adjusted, index=[\"CAD\"] + [\"Random{}\".format(i) for i in range(500)], columns=[\"1\",\"3\",\"5\",\"1_rev\", \"3_rev\", \"5_rev\"])\n",
    "\n",
    "print((test_df.sort_values(\"1\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"3\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"5\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"1_rev\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"3_rev\").index == \"CAD\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"5_rev\").index == \"CAD\").nonzero()[0] / len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scz_test_df_list = test_df_list[:]\n",
    "scz_test_df_list[0] = scz_pvals\n",
    "scz_test_df_list = np.asarray(cad_test_df_list)\n",
    "old_shape = scz_test_df_list.shape\n",
    "\n",
    "adjusted = fdrcorrection(scz_test_df_list.flatten())[1].reshape(old_shape)\n",
    "test_df = pd.DataFrame(adjusted, index=[\"SCZ\"] + [\"Random{}\".format(i) for i in range(500)], columns=[\"1\",\"3\",\"5\",\"1_rev\", \"3_rev\", \"5_rev\"])\n",
    "\n",
    "print((test_df.sort_values(\"1\").index == \"SCZ\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"3\").index == \"SCZ\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"5\").index == \"SCZ\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"1_rev\").index == \"SCZ\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"3_rev\").index == \"SCZ\").nonzero()[0] / len(test_df))\n",
    "print((test_df.sort_values(\"5_rev\").index == \"SCZ\").nonzero()[0] / len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=7, figsize=(full_width*cm, 5*cm))\n",
    "\n",
    "for ax, str_ind, ind in zip(axes.tolist(), test_df.columns.tolist() + [\"None\"], range(7)):\n",
    "    if ind < 6:\n",
    "        ax = sns.kdeplot(y = np.log10(test_df[str_ind][]) * -1, cut=0, fill=\"lightblue\", ax=ax)\n",
    "        if ind > 2:\n",
    "            value = np.quantile(np.log10(test_df[str_ind]) * -1, 0.95)\n",
    "        else:\n",
    "            value = np.quantile(np.log10(test_df[str_ind]) * -1, 0.05)\n",
    "\n",
    "        ax.hlines(value, 0, 0.05, color=\"gray\", zorder=2)\n",
    "        ax.hlines(np.log10(uc_pvals[ind]) * -1, 0, 0.1, color=\"red\", zorder=1)\n",
    "        ax.hlines(np.log10(cad_pvals[ind]) * -1, 0, 0.1, color=\"blue\", zorder=1)\n",
    "        ax.hlines(np.log10(scz_pvals[ind]) * -1, 0, 0.1, color=\"blue\", zorder=1)\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_title(str_ind)\n",
    "        # Create a Rectangle patch\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim= ax.get_ylim()\n",
    "        rect = patches.Rectangle((0, value*0.99 if ind >2 else value*1.01), 0.3, -200 if ind > 2 else 200,  linewidth=0, facecolor='white', alpha=0.7, zorder=5)\n",
    "\n",
    "\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "        if ind ==0:\n",
    "            ax.set_ylabel(\"-log(p)\")\n",
    "    else:\n",
    "        legend_elements = [Patch(facecolor='red', edgecolor='red',\n",
    "                                label='Traits Match'),\n",
    "                            Patch(facecolor='blue', edgecolor='blue',\n",
    "                                    label='Trait Mismatch'),\n",
    "                            Patch(facecolor='gray', edgecolor='gray',\n",
    "                                    label='95th Percentile')]\n",
    "\n",
    "        leg = ax.legend(handles=legend_elements, loc='center', title=\"p-Values\", fontsize=8, title_fontsize=8, ncol=1, columnspacing=1.7, handletextpad=-0.5, labelspacing=1.7)\n",
    "\n",
    "        for patch in leg.get_patches():\n",
    "            patch.set_height(10)\n",
    "            patch.set_width(10)\n",
    "            patch.set_y(-2.5)\n",
    "        ax.set_axis_off()\n",
    "        \n",
    "    #ax.set_xscale(\"log\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "from scipy.stats import rankdata\n",
    "import matplotlib.ticker as tck\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=7, figsize=(full_width*cm, 5*cm))\n",
    "df = pd.read_csv(\"random_labelprop_target_uc_film_nohetio.tsv\", index_col=0, header=0, sep=\"\\t\")\n",
    "\n",
    "for ax, str_ind, ind in zip(axes.tolist(), df.columns.tolist() + [\"None\"], range(7)):\n",
    "    if ind < 6:\n",
    "        ax = sns.kdeplot(y = np.log10(df[str_ind]) * -1, cut=0, fill=\"lightblue\", ax=ax)\n",
    "        if ind > 2:\n",
    "            value = np.quantile(np.log10(df[str_ind]) * -1, 0.95)\n",
    "            pval = rankdata(df[str_ind])[df[str_ind] == df.loc[\"UC\", str_ind]] / len(df)\n",
    "        else:\n",
    "            value = np.quantile(np.log10(df[str_ind]) * -1, 0.05)\n",
    "            pval = 1 - (rankdata(df[str_ind])[df[str_ind] == df.loc[\"UC\", str_ind]] / len(df))\n",
    "        \n",
    "        text = \"p={:.3f}\".format(pval.item())\n",
    "        ax.hlines(value, 0, 0.05, color=\"#5a5a5a\", zorder=2)\n",
    "        ax.hlines(np.log10(df.loc[\"UC\", str_ind]) * -1, 0, 0.1, color=\"#d8031c\", zorder=1)\n",
    "        ax.hlines(np.log10(df.loc[\"CAD\", str_ind]) * -1, 0, 0.1, color=\"#2b5d34\", zorder=1)\n",
    "        ax.hlines(np.log10(df.loc[\"SCZ\", str_ind]) * -1, 0, 0.1, color=\"#2b5d34\", zorder=1)\n",
    "        ax.set_ylabel(\"\")\n",
    "        #ax.set_title(str_ind)\n",
    "        # Create a Rectangle patch\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim= ax.get_ylim()\n",
    "        ax.hlines(value, 0, xlim[1]*0.4, color=\"#5a5a5a\", zorder=2)\n",
    "        ax.hlines(np.log10(df.loc[\"UC\", str_ind]) * -1, 0, xlim[1]*0.8, color=\"#d8031c\", zorder=1)\n",
    "        ax.hlines(np.log10(df.loc[\"CAD\", str_ind]) * -1, 0, xlim[1]*0.8, color=\"#2b5d34\", zorder=1)\n",
    "        ax.hlines(np.log10(df.loc[\"SCZ\", str_ind]) * -1, 0, xlim[1]*0.8, color=\"#2b5d34\", zorder=1)\n",
    "        rect = patches.Rectangle((0, value*0.99 if ind >2 else value*1.01), 0.3, -200 if ind > 2 else 200,  linewidth=0, facecolor='white', alpha=0.7, zorder=5)\n",
    "        ax.text(x=np.mean(xlim), y=ylim[1] * 0.9, s=text, fontsize=5, zorder=7, ha=\"center\")\n",
    "\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim((-0.05, ylim[1]))\n",
    "        nticks = int(ylim[1] / 8)\n",
    "        ax.yaxis.set_major_locator(tck.MultipleLocator(nticks))\n",
    "        if ind ==0:\n",
    "            ax.set_ylabel(\"-log(p)\")\n",
    "    else:\n",
    "        legend_elements = [Patch(facecolor='#d8031c', edgecolor='#d8031c',\n",
    "                                label='UC HSPs'),\n",
    "                            Patch(facecolor='#2b5d34', edgecolor='#2b5d34',\n",
    "                                    label='CAD/SCZ HSPs'),\n",
    "                            Patch(facecolor='#5a5a5a', edgecolor='#5a5a5a',\n",
    "                                    label='5th/95th Percentile')]\n",
    "\n",
    "        leg = ax.legend(handles=legend_elements, loc='center', title=\"p-Values\", fontsize=8, title_fontsize=8, ncol=1, columnspacing=1.7, handletextpad=-0.2, labelspacing=1.7)\n",
    "\n",
    "        for patch in leg.get_patches():\n",
    "            patch.set_height(10)\n",
    "            patch.set_width(10)\n",
    "            patch.set_y(-2.5)\n",
    "        ax.set_axis_off()\n",
    "        \n",
    "    #ax.set_xscale(\"log\")\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "plt.savefig(\"pvals_labelprop_uc.svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=7, figsize=(full_width*cm, 5*cm))\n",
    "df = pd.read_csv(\"random_labelprop_target_cad_really_film_nohetio.tsv\", index_col=0, header=0, sep=\"\\t\")\n",
    "\n",
    "for ax, str_ind, ind in zip(axes.tolist(), df.columns.tolist() + [\"None\"], range(7)):\n",
    "    if ind < 6:\n",
    "        ax = sns.kdeplot(y = np.log10(df[str_ind]) * -1, cut=0, fill=\"lightblue\", ax=ax)\n",
    "        if ind > 2:\n",
    "            value = np.quantile(np.log10(df[str_ind]) * -1, 0.95)\n",
    "            pval = rankdata(df[str_ind])[df[str_ind] == df.loc[\"CAD\", str_ind]] / len(df)\n",
    "        else:\n",
    "            value = np.quantile(np.log10(df[str_ind]) * -1, 0.05)\n",
    "            pval = 1 - (rankdata(df[str_ind])[df[str_ind] == df.loc[\"CAD\", str_ind]] / len(df))\n",
    "        \n",
    "        text = \"p={:.3f}\".format(pval.item())\n",
    "        ax.hlines(value, 0, 0.05, color=\"gray\", zorder=2)\n",
    "        ax.hlines(value, 0, 0.05, color=\"gray\", zorder=2)\n",
    "        ax.hlines(np.log10(df.loc[\"CAD\", str_ind]) * -1, 0, 0.1, color=\"red\", zorder=1)\n",
    "        ax.hlines(np.log10(df.loc[\"UC\", str_ind]) * -1, 0, 0.1, color=\"blue\", zorder=1)\n",
    "        ax.hlines(np.log10(df.loc[\"SCZ\", str_ind]) * -1, 0, 0.1, color=\"blue\", zorder=1)\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_title(str_ind)\n",
    "        # Create a Rectangle patch\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim= ax.get_ylim()\n",
    "        rect = patches.Rectangle((0, value*0.99 if ind >2 else value*1.01), 1.5, -200 if ind > 2 else 200,  linewidth=0, facecolor='white', alpha=0.7, zorder=5)\n",
    "\n",
    "        ax.text(x=np.mean(xlim), y=ylim[1] * 0.9, s=text, fontsize=5, zorder=7, ha=\"center\")\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "        if ind ==0:\n",
    "            ax.set_ylabel(\"-log(p)\")\n",
    "    else:\n",
    "        legend_elements = [Patch(facecolor='red', edgecolor='red',\n",
    "                                label='Traits Match'),\n",
    "                            Patch(facecolor='blue', edgecolor='blue',\n",
    "                                    label='Trait Mismatch'),\n",
    "                            Patch(facecolor='gray', edgecolor='gray',\n",
    "                                    label='5th/95th\\nPercentile')]\n",
    "\n",
    "        leg = ax.legend(handles=legend_elements, loc='center', title=\"p-Values\", fontsize=8, title_fontsize=8, ncol=1, columnspacing=1.7, handletextpad=-0.5, labelspacing=1.7)\n",
    "\n",
    "        for patch in leg.get_patches():\n",
    "            patch.set_height(10)\n",
    "            patch.set_width(10)\n",
    "            patch.set_y(-2.5)\n",
    "        ax.set_axis_off()\n",
    "        \n",
    "    #ax.set_xscale(\"log\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=7, figsize=(full_width*cm, 5*cm))\n",
    "df = pd.read_csv(\"random_labelprop_target_scz_film_nohetio.tsv\", index_col=0, header=0, sep=\"\\t\")\n",
    "\n",
    "for ax, str_ind, ind in zip(axes.tolist(), df.columns.tolist() + [\"None\"], range(7)):\n",
    "    if ind < 6:\n",
    "        ax = sns.kdeplot(y = np.log10(df[str_ind]) * -1, cut=0, fill=\"lightblue\", ax=ax)\n",
    "        if ind > 2:\n",
    "            value = np.quantile(np.log10(df[str_ind]) * -1, 0.95)\n",
    "            pval = rankdata(df[str_ind])[df[str_ind] == df.loc[\"CAD\", str_ind]] / len(df)\n",
    "        else:\n",
    "            value = np.quantile(np.log10(df[str_ind]) * -1, 0.05)\n",
    "            pval = 1 - (rankdata(df[str_ind])[df[str_ind] == df.loc[\"CAD\", str_ind]] / len(df))\n",
    "        \n",
    "        text = \"p={:.3f}\".format(pval.item())\n",
    "        ax.hlines(value, 0, 0.05, color=\"gray\", zorder=2)\n",
    "        ax.hlines(value, 0, 0.05, color=\"gray\", zorder=2)\n",
    "        ax.hlines(np.log10(df.loc[\"CAD\", str_ind]) * -1, 0, 0.1, color=\"red\", zorder=1)\n",
    "        ax.hlines(np.log10(df.loc[\"UC\", str_ind]) * -1, 0, 0.1, color=\"blue\", zorder=1)\n",
    "        ax.hlines(np.log10(df.loc[\"SCZ\", str_ind]) * -1, 0, 0.1, color=\"blue\", zorder=1)\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_title(str_ind)\n",
    "        # Create a Rectangle patch\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim= ax.get_ylim()\n",
    "        rect = patches.Rectangle((0, value*0.99 if ind >2 else value*1.01), 1.5, -200 if ind > 2 else 200,  linewidth=0, facecolor='white', alpha=0.7, zorder=5)\n",
    "\n",
    "        ax.text(x=np.mean(xlim), y=ylim[1] * 0.9, s=text, fontsize=5, zorder=7, ha=\"center\")\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "        if ind ==0:\n",
    "            ax.set_ylabel(\"-log(p)\")\n",
    "    else:\n",
    "        legend_elements = [Patch(facecolor='red', edgecolor='red',\n",
    "                                label='Traits Match'),\n",
    "                            Patch(facecolor='blue', edgecolor='blue',\n",
    "                                    label='Trait Mismatch'),\n",
    "                            Patch(facecolor='gray', edgecolor='gray',\n",
    "                                    label='5th/95th\\nPercentile')]\n",
    "\n",
    "        leg = ax.legend(handles=legend_elements, loc='center', title=\"p-Values\", fontsize=8, title_fontsize=8, ncol=1, columnspacing=1.7, handletextpad=-0.5, labelspacing=1.7)\n",
    "\n",
    "        for patch in leg.get_patches():\n",
    "            patch.set_height(10)\n",
    "            patch.set_width(10)\n",
    "            patch.set_y(-2.5)\n",
    "        ax.set_axis_off()\n",
    "        \n",
    "    #ax.set_xscale(\"log\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Edgetypes and connectivities of Core Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "hsps = pd.read_csv(\"hsps/uc.txt\", header=None, index_col=None, sep=\"\\t\")\n",
    "hsp_indices = [prepro.hgnc2id[hgnc] for hgnc in hsps.iloc[:, 0]]\n",
    "new_y = torch.zeros_like(dataset.data.y)\n",
    "new_y[np.asarray(hsp_indices)] = 1\n",
    "\n",
    "\n",
    "\n",
    "centrality = nx.degree_centrality(G)\n",
    "core_centrality = [centrality[idx.item()] for idx in coregenes.nonzero() if idx.item() in centrality.keys()]\n",
    "hsp_centrality = [centrality[idx] for idx in hsp_indices if idx in centrality.keys()]\n",
    "peripheral_centrality = [centrality[idx.item()] for idx in (torch.ones_like(new_y) - coregenes - new_y - coregenes_weak).nonzero() if idx.item() in centrality.keys()]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.boxplot([core_centrality, hsp_centrality, peripheral_centrality], positions=[0,1,2])\n",
    "\n",
    "mannwhitneyu(core_centrality, peripheral_centrality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = nx.out_degree_centrality(G)\n",
    "core_centrality = [centrality[idx.item()] for idx in coregenes.nonzero() if idx.item() in centrality.keys()]\n",
    "hsp_centrality = [centrality[idx] for idx in hsp_indices if idx in centrality.keys()]\n",
    "peripheral_centrality = [centrality[idx.item()] for idx in (torch.ones_like(new_y) - coregenes - new_y - coregenes_weak).nonzero() if idx.item() in centrality.keys()]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.boxplot([core_centrality, hsp_centrality, peripheral_centrality], positions=[0,1,2])\n",
    "\n",
    "mannwhitneyu(core_centrality, peripheral_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = nx.in_degree_centrality(G)\n",
    "core_centrality = [centrality[idx.item()] for idx in coregenes.nonzero() if idx.item() in centrality.keys()]\n",
    "hsp_centrality = [centrality[idx] for idx in hsp_indices if idx in centrality.keys()]\n",
    "peripheral_centrality = [centrality[idx.item()] for idx in (torch.ones_like(new_y) - coregenes - new_y - coregenes_weak).nonzero() if idx.item() in centrality.keys()]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.boxplot([core_centrality, hsp_centrality, peripheral_centrality], positions=[0,1,2])\n",
    "\n",
    "mannwhitneyu(core_centrality, peripheral_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = nx.pagerank(G)\n",
    "core_centrality = [centrality[idx.item()] for idx in coregenes.nonzero() if idx.item() in centrality.keys()]\n",
    "hsp_centrality = [centrality[idx] for idx in hsp_indices if idx in centrality.keys()]\n",
    "peripheral_centrality = [centrality[idx.item()] for idx in (torch.ones_like(new_y) - coregenes - new_y - coregenes_weak).nonzero() if idx.item() in centrality.keys()]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.boxplot([core_centrality, hsp_centrality, peripheral_centrality], positions=[0,1,2])\n",
    "\n",
    "mannwhitneyu(core_centrality, peripheral_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = nx.betweenness_centrality(G, 20)\n",
    "core_centrality = [centrality[idx.item()] for idx in coregenes.nonzero() if idx.item() in centrality.keys()]\n",
    "hsp_centrality = [centrality[idx] for idx in hsp_indices if idx in centrality.keys()]\n",
    "peripheral_centrality = [centrality[idx.item()] for idx in (torch.ones_like(new_y) - coregenes - new_y - coregenes_weak).nonzero() if idx.item() in centrality.keys()]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.boxplot([core_centrality, hsp_centrality, peripheral_centrality], positions=[0,1,2])\n",
    "\n",
    "print(mannwhitneyu(core_centrality, peripheral_centrality))\n",
    "print(mannwhitneyu(core_centrality, hsp_centrality))\n",
    "print(mannwhitneyu(peripheral_centrality, hsp_centrality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = nx.load_centrality(G)\n",
    "core_centrality = [centrality[idx.item()] for idx in coregenes.nonzero() if idx.item() in centrality.keys()]\n",
    "hsp_centrality = [centrality[idx] for idx in hsp_indices if idx in centrality.keys()]\n",
    "peripheral_centrality = [centrality[idx.item()] for idx in (torch.ones_like(new_y) - coregenes - new_y - coregenes_weak).nonzero() if idx.item() in centrality.keys()]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.boxplot([core_centrality, hsp_centrality, peripheral_centrality], positions=[0,1,2])\n",
    "\n",
    "mannwhitneyu(core_centrality, peripheral_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "outgoing = {}\n",
    "for key, edge_index in tqdm(dataset.data.edge_index_dict.items()):\n",
    "    key = key[1]\n",
    "    outgoing[key] = {}\n",
    "    for index in coregenes.nonzero():\n",
    "        values = edge_index[1, :][edge_index[0, :] == index].tolist()\n",
    "        if len(values) > 0:\n",
    "            outgoing[key][prepro.id2hgnc[index.item()]] = [prepro.id2hgnc[value] for value in values]\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "outgoing_background = {}\n",
    "for key, edge_index in tqdm(dataset.data.edge_index_dict.items()):\n",
    "    key = key[1]\n",
    "    outgoing_background[key] = len(edge_index[0, :].unique().tolist())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in outgoing.items():\n",
    "    print(\"{}: {}\".format(key, len(value.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outgoing_background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "adj_fisher = {}\n",
    "for key in dataset.data.edge_index_dict.keys():\n",
    "    total_n_core = coregenes.sum().item()\n",
    "    total_n_genes = coregenes.shape[0]\n",
    "    tf_and_core = len(outgoing[key[1]].keys())\n",
    "    total_tf = outgoing_background[key[1]]\n",
    "\n",
    "    #               TF\n",
    "    #            Yes    No\n",
    "    # Core  Yes\n",
    "    #       No\n",
    "\n",
    "    array = np.asarray([[tf_and_core, total_n_core - tf_and_core],\n",
    "            [total_tf- tf_and_core, total_n_genes - total_tf - total_n_core + tf_and_core]])\n",
    "    \n",
    "    result = fisher_exact(array)\n",
    "    adj_fisher[key[1]] = [array[0,0], array[0,1], array[1,0], array[1,1], result[0], result[1]]\n",
    "\n",
    "tf_df = pd.DataFrame.from_dict(adj_fisher, orient=\"index\", columns=[\"Core_and_Out\", \"Core_not_Out\", \"not_Core_and_Out\", \"not_Core_not_Out\", \"OR\", \"pval\"])\n",
    "tf_df[\"FDR\"] = fdrcorrection(tf_df[\"pval\"])[1]\n",
    "tf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(full_width*cm*0.5, 3))\n",
    "\n",
    "tf_df[\"log_OR\"] = np.log10(tf_df[\"OR\"])\n",
    "ax.bar(range(len(tf_df[\"log_OR\"])), tf_df[\"log_OR\"], color=\"#01016f\", zorder=3, width=1, edgecolor=\"white\")\n",
    "for i, label in enumerate(tf_df.index):\n",
    "    ax.text(i+0.2, +0.02, pretty_names[label], va=\"bottom\", ha=\"center\", rotation=90, fontsize=5, color=\"white\", zorder=5)\n",
    "ax.set_yscale(\"symlog\")\n",
    "ax.set_yticks(np.log10([0.01, 0.1, 0.5, 1, 2, 4]))\n",
    "ax.set_yticklabels([0.01, 0.1, 0.5, 1, 2, 4])\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", color=\"lightgray\", zorder=-5)\n",
    "ax.set_ylabel(\"Odds Ratio\")\n",
    "ax.set_xticks([])\n",
    "ax.hlines(0, -0.75, len(tf_df)-0.25, color=\"black\", linewidth=0.5)\n",
    "ax.set_xlim((-0.75, len(tf_df)-0.25))\n",
    "#ax.set_yticks(ax.get_yticks())\n",
    "#ax.set_yticklabels(ticklabels)\n",
    "plt.savefig(\"edge_frequency.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df.to_csv(\"edge_frequency_df.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with edge frequency instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "outgoing_background_frequency = {}\n",
    "for key, edge_index in tqdm(dataset.data.edge_index_dict.items()):\n",
    "    key = key[1]\n",
    "    outgoing_background_frequency[key] = len(edge_index[0, :].tolist())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_fisher = {}\n",
    "for key in dataset.data.edge_index_dict.keys():\n",
    "    total_edges_core = np.sum(list(chain(*[[len(value) for value in values.values()] for values in outgoing.values()])))\n",
    "    total_edges = edge_index_flat.shape[1]\n",
    "    tf_and_core = np.sum([len(value) for value in outgoing[key[1]].values()])\n",
    "    total_tf = outgoing_background_frequency[key[1]]\n",
    "    #               edges\n",
    "    #               Yes  No\n",
    "    #   Core    Yes\n",
    "    #           No\n",
    "\n",
    "    array = np.asarray([[tf_and_core, total_edges_core - tf_and_core],\n",
    "            [total_tf- tf_and_core, total_edges - total_tf - total_edges_core + tf_and_core]])\n",
    "    \n",
    "    result = fisher_exact(array)\n",
    "    adj_fisher[key[1]] = array.flatten().tolist() + [result[0], result[1]]\n",
    "\n",
    "tf_df = pd.DataFrame.from_dict(adj_fisher, orient=\"index\", columns=[\"Core_and_Out\", \"Core_not_Out\", \"not_Core_and_Out\", \"not_Core_not_Out\", \"OR\", \"pval\"])\n",
    "tf_df[\"FDR\"] = fdrcorrection(tf_df[\"pval\"])[1]\n",
    "tf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro.hgnc2id[\"FCGR2A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df[\"log_OR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = []\n",
    "for key, value in outgoing.items():\n",
    "    if key.startswith(\"GRNDB\"):\n",
    "        tfs.extend(list(value.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(tfs)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "countcounter = Counter(counter.values())\n",
    "countcounter\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(full_width*cm*0.5, 6*cm))\n",
    "\n",
    "labels = []\n",
    "for i, (key, value) in enumerate(sorted(countcounter.items())[::-1]):\n",
    "    ax.bar(i, height=value)\n",
    "    labels.append(key)\n",
    "\n",
    "ax.set_xticks(range(20))\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel(\"Number of Core Gene TFS\")\n",
    "ax.set_xlabel(\"TF in # Tissues (out of 27)\")\n",
    "plt.savefig(\"tfs_per_tissue.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_withedges = {}\n",
    "for key, value in outgoing.items():\n",
    "    if key.startswith(\"GRNDB\"):\n",
    "        for tf, targets in value.items():\n",
    "            try:\n",
    "                tfs_withedges[tf].append(len(targets))\n",
    "            except KeyError:\n",
    "                tfs_withedges[tf] = [len(targets)]\n",
    "\n",
    "\n",
    "#edgecounter = Counter(tfs)\n",
    "#edgecounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_withedges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_aggregated = {}\n",
    "for tf, value in counter.items():\n",
    "    tfs_aggregated[tf] = np.sum(tfs_withedges[tf])\n",
    "tfs_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_aggregated_by_num_adjacencies = {value: 0 for value in counter.values()}\n",
    "for tf, value in counter.items():\n",
    "    tfs_aggregated_by_num_adjacencies[value] += tfs_aggregated[tf]\n",
    "tfs_aggregated_by_num_adjacencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(full_width*cm*0.5, 6*cm))\n",
    "\n",
    "labels = []\n",
    "cumsum = [0]\n",
    "for i, (key, value) in enumerate(sorted(tfs_aggregated_by_num_adjacencies.items())[::-1]):\n",
    "    ax.bar(i, height=value)\n",
    "    labels.append(key)\n",
    "    cumsum.append(cumsum[i] + value)\n",
    "\n",
    "ax.set_xticks(range(20))\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel(\"Number of Edges outgoing\\nfrom Core Gene TF\")\n",
    "ax.set_xlabel(\"TF in # Tissues (out of 27)\")\n",
    "print(np.asarray(cumsum) / cumsum[-1])\n",
    "plt.savefig(\"tf_edges_per_tissue.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unspecific_TFS = set([key for key, value in counter.items() if value >24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unspecific_TFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "adj_fisher = {}\n",
    "for key in dataset.data.edge_index_dict.keys():\n",
    "    total_n_core = coregenes.sum().item()\n",
    "    total_n_genes = coregenes.shape[0]\n",
    "    if key[1].startswith(\"GRNDB\"):\n",
    "        tf_and_core = len(set(outgoing[key[1]].keys()).difference(unspecific_TFS))\n",
    "    else:\n",
    "        tf_and_core = len(outgoing[key[1]].keys())\n",
    "    total_tf = outgoing_background[key[1]]\n",
    "\n",
    "    #               TF\n",
    "    #            Yes    No\n",
    "    # Core  Yes\n",
    "    #       No\n",
    "\n",
    "    array = np.asarray([[tf_and_core, total_n_core - tf_and_core],\n",
    "            [total_tf- tf_and_core, total_n_genes - total_tf - total_n_core + tf_and_core]])\n",
    "    \n",
    "    result = fisher_exact(array)\n",
    "    adj_fisher[key[1]] = [array[0,0], array[0,1], array[1,0], array[1,1], result[0], result[1]]\n",
    "\n",
    "tf_df_corrected = pd.DataFrame.from_dict(adj_fisher, orient=\"index\", columns=[\"Core_and_Out\", \"Core_not_Out\", \"not_Core_and_Out\", \"not_Core_not_Out\", \"OR\", \"pval\"])\n",
    "tf_df_corrected[\"FDR\"] = fdrcorrection(tf_df_corrected[\"pval\"])[1]\n",
    "tf_df_corrected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(full_width*cm*0.5, 6*cm))\n",
    "\n",
    "tf_df[\"log_OR\"] = np.log10(tf_df[\"OR\"])\n",
    "for i, (log_or, fdr) in enumerate(zip(tf_df[\"log_OR\"], tf_df[\"FDR\"])):\n",
    "    ax.bar(i, log_or, color=\"#01016f\" if fdr <0.05 else \"gray\", zorder=3, width=1, edgecolor=\"white\")\n",
    "for i, (label, log_or) in enumerate(zip(tf_df.index, tf_df[\"OR\"])):\n",
    "    ax.text(i+0.18,np.log10(log_or) + 0.02 if label.startswith(\"GRNDB\") and log_or > 1 else 0.02, label, va=\"bottom\", ha=\"center\", rotation=90, fontsize=6, color=\"black\" if label.startswith(\"GRNDB\") else \"white\" , zorder=5)\n",
    "ax.set_yscale(\"symlog\")\n",
    "ax.set_yticks(np.log10([0.01, 0.1, 0.5, 1, 2, 4]))\n",
    "ax.set_yticklabels([0.01, 0.1, 0.5, 1, 2, 4])\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", color=\"lightgray\", zorder=-5)\n",
    "ax.set_ylabel(\"Odds Ratio\")\n",
    "ax.set_xticks([])\n",
    "\n",
    "ax.hlines(0, -0.75, len(tf_df)-0.25, color=\"black\", linewidth=0.5)\n",
    "ax.set_xlim((-0.75, len(tf_df)-0.25))\n",
    "#ax.set_yticks(ax.get_yticks())\n",
    "#ax.set_yticklabels(ticklabels)\n",
    "plt.savefig(\"edge_frequency_minus_unspec_dfs.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(full_width*cm, 6*cm), sharey=True)\n",
    "\n",
    "tf_df[\"log_OR\"] = np.log10(tf_df[\"OR\"])\n",
    "ax1.bar(range(len(tf_df[\"log_OR\"])), tf_df[\"log_OR\"], color=\"#01016f\", zorder=3, width=1, edgecolor=\"white\", linewidth=0.5)\n",
    "for i, label in enumerate(tf_df.index):\n",
    "    ax1.text(i+0.115, +0.01, pretty_names[label], va=\"bottom\", ha=\"center\", rotation=90, fontsize=6, color=\"white\", zorder=5)\n",
    "ax1.set_yscale(\"symlog\")\n",
    "ax1.set_yticks(np.log10([0.01, 0.1, 0.5, 1, 2, 4, 6]))\n",
    "ax1.set_yticklabels([0.01, 0.1, 0.5, 1, 2, 4, 6])\n",
    "ax1.grid(axis=\"y\", linestyle=\"--\", color=\"lightgray\", zorder=-5)\n",
    "ax1.set_ylabel(r\"Odds Ratio of $d_{out} > 0$\")\n",
    "ax1.set_xticks([])\n",
    "ax1.hlines(0, -0.75, len(tf_df)-0.25, color=\"black\", linewidth=0.5)\n",
    "ax1.set_xlim((-0.75, len(tf_df)-0.25))\n",
    "ax1.set_xlabel(\"Subnetworks\")\n",
    "\n",
    "tf_df_corrected[\"log_OR\"] = np.log10(tf_df_corrected[\"OR\"])\n",
    "for i, (log_or, fdr) in enumerate(zip(tf_df_corrected[\"log_OR\"], tf_df_corrected[\"FDR\"])):\n",
    "    ax2.bar(i, log_or, color=\"#01016f\" if fdr <0.05 else \"gray\", zorder=3, width=1, edgecolor=\"white\", linewidth=0.5)\n",
    "for i, (label, log_or) in enumerate(zip(tf_df_corrected.index, tf_df_corrected[\"OR\"])):\n",
    "    ax2.text(i+0.115,np.log10(log_or) + 0.01 if label.startswith(\"GRNDB\") and log_or > 1 else 0.02, pretty_names[label], va=\"bottom\", ha=\"center\", rotation=90, fontsize=6, color=\"black\" if label.startswith(\"GRNDB\") else \"white\" , zorder=5)\n",
    "ax2.set_yscale(\"symlog\")\n",
    "ax2.set_yticks(np.log10([0.01, 0.1, 0.5, 1, 2, 4, 6]))\n",
    "ax2.set_yticklabels([0.01, 0.1, 0.5, 1, 2, 4, 6])\n",
    "ax2.grid(axis=\"y\", linestyle=\"--\", color=\"lightgray\", zorder=-5)\n",
    "ax2.set_xticks([])\n",
    "\n",
    "ax2.hlines(0, -0.75, len(tf_df)-0.25, color=\"black\", linewidth=0.5)\n",
    "ax2.set_xlim((-0.75, len(tf_df)-0.25))\n",
    "ax2.set_xlabel(\"Subnetworks\")\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['bottom'].set_visible(False)\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "\n",
    "plt.savefig(\"edge_frequency_both.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from itertools import chain\n",
    "firsthop_outgoing = {}\n",
    "new_start_nodes = set()\n",
    "key = list(outgoing.keys())[0]\n",
    "new_start_nodes.update(set(chain(*list(outgoing[key].values()))))\n",
    "\n",
    "for key, edge_index in tqdm(dataset.data.edge_index_dict.items()):\n",
    "    key = key[1]\n",
    "    firsthop_outgoing[key] = {}\n",
    "    for index in tqdm(new_start_nodes):\n",
    "        values = edge_index[1, :][edge_index[0, :] == prepro.hgnc2id[index]].tolist()\n",
    "        if len(values) > 0:\n",
    "            firsthop_outgoing[key][index] = [prepro.id2hgnc[value] for value in values]\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/mnt/storage/speos/firsthop_bioplexhct_outgoing.json\", \"w\") as outfile: \n",
    "    json.dump(firsthop_outgoing, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from itertools import chain\n",
    "\n",
    "with open(\"/mnt/storage/speos/firsthop_bioplexhct_outgoing.json\", \"r\") as outfile: \n",
    "    firsthop_outgoing = json.load(outfile)\n",
    "\n",
    "new_start_nodes = set()\n",
    "key = list(outgoing.keys())[0]\n",
    "new_start_nodes.update(set(chain(*list(outgoing[key].values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(chain(*list(outgoing[key].values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_fisher = {}\n",
    "\n",
    "for key in dataset.data.edge_index_dict.keys():\n",
    "    total_firsthop = len(new_start_nodes)\n",
    "    total_n_genes = coregenes.shape[0]\n",
    "    tf_and_firsthop = len(set(firsthop_outgoing[key[1]].keys()))\n",
    "    total_tf = outgoing_background[key[1]]\n",
    "\n",
    "    #           Transcrtiption Factor\n",
    "    #          Yes  No\n",
    "    #   FH  Yes\n",
    "    #       No\n",
    "\n",
    "    array = np.asarray([[tf_and_firsthop           , total_firsthop - tf_and_firsthop],\n",
    "                        [total_tf - tf_and_firsthop, total_n_genes - total_tf - total_firsthop + tf_and_firsthop]])\n",
    "\n",
    "    assert array[0, :].sum() == total_firsthop\n",
    "    assert array[1, :].sum() == total_n_genes - total_firsthop\n",
    "    assert array[:, 0].sum() == total_tf\n",
    "    assert array[:, 1].sum() == total_n_genes - total_tf\n",
    "    \n",
    "    result = fisher_exact(array)\n",
    "    adj_fisher[key[1]] = array.flatten().tolist() + [result[0], result[1]]\n",
    "\n",
    "firsthop_tf_df = pd.DataFrame.from_dict(adj_fisher, orient=\"index\", columns=[\"1Hop_and_Out\", \"1Hop_not_Out\", \"not_1Hop_and_Out\", \"not_1Hop_not_Out\", \"OR\", \"pval\"])\n",
    "firsthop_tf_df[\"FDR\"] = fdrcorrection(firsthop_tf_df[\"pval\"])[1]\n",
    "firsthop_tf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(full_width*cm, 3))\n",
    "\n",
    "firsthop_tf_df[\"log_OR\"] = np.log10(firsthop_tf_df[\"OR\"])\n",
    "firsthop_tf_df.iloc[0, -1] = np.log10(30)\n",
    "print(firsthop_tf_df[\"log_OR\"])\n",
    "for i, (log_or, fdr) in enumerate(zip(firsthop_tf_df[\"log_OR\"], firsthop_tf_df[\"FDR\"])):\n",
    "    ax.bar(i, log_or, color=\"#01016f\" if fdr <0.05 else \"gray\", zorder=3)\n",
    "for i, (label, log_or) in enumerate(zip(firsthop_tf_df.index, firsthop_tf_df[\"OR\"])):\n",
    "    ax.text(i+0.05,np.log10(log_or) + 0.02 if label.startswith(\"GRNDB\") and log_or > 1 else 0.02, label, va=\"bottom\", ha=\"center\", rotation=90, fontsize=6, color=\"black\" if label.startswith(\"GRNDB\") else \"white\" , zorder=5)\n",
    "ax.set_ylim(top = np.log10(25))\n",
    "ax.set_ylim(bottom = 1)\n",
    "ax.set_yscale(\"symlog\")\n",
    "ax.set_yticks(np.log10([ 0.5, 1, 2, 4, 10, 20, ]))\n",
    "ax.set_yticklabels([ 0.5, 1, 2, 4,  10, 20, ])\n",
    "\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", color=\"lightgray\", zorder=-5)\n",
    "ax.set_ylabel(\"Odds Ratio\")\n",
    "ax.set_xticks([])\n",
    "ax.hlines(0, -0.75, len(tf_df)-0.25, color=\"black\", linewidth=0.5)\n",
    "ax.set_xlim((-0.75, len(tf_df)-0.25))\n",
    "#ax.set_yticks(ax.get_yticks())\n",
    "#ax.set_yticklabels(ticklabels)\n",
    "plt.savefig(\"edge_frequency_onehop.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_fisher = {}\n",
    "\n",
    "for key in dataset.data.edge_index_dict.keys():\n",
    "    total_firsthop = len(new_start_nodes)\n",
    "    total_n_genes = coregenes.shape[0]\n",
    "    tf_and_firsthop = len(set(firsthop_outgoing[key[1]].keys()))\n",
    "    total_tf = outgoing_background[key[1]]\n",
    "\n",
    "    #           Transcrtiption Factor\n",
    "    #          Yes  No\n",
    "    #   FH  Yes\n",
    "    #       No\n",
    "\n",
    "    array = np.asarray([[tf_and_firsthop           , total_firsthop - tf_and_firsthop],\n",
    "                        [total_tf - tf_and_firsthop, total_n_genes - total_tf - total_firsthop + tf_and_firsthop]])\n",
    "\n",
    "    assert array[0, :].sum() == total_firsthop\n",
    "    assert array[1, :].sum() == total_n_genes - total_firsthop\n",
    "    assert array[:, 0].sum() == total_tf\n",
    "    assert array[:, 1].sum() == total_n_genes - total_tf\n",
    "    \n",
    "    result = fisher_exact(array)\n",
    "    adj_fisher[key[1]] = array.flatten().tolist() + [result[0], result[1]]\n",
    "\n",
    "firsthop_tf_df = pd.DataFrame.from_dict(adj_fisher, orient=\"index\", columns=[\"1Hop_and_Out\", \"1Hop_not_Out\", \"not_1Hop_and_Out\", \"not_1Hop_not_Out\", \"OR\", \"pval\"])\n",
    "firsthop_tf_df[\"FDR\"] = fdrcorrection(firsthop_tf_df[\"pval\"])[1]\n",
    "firsthop_tf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for newkey, edge_index in tqdm(dataset.data.edge_index_dict.items()):\n",
    "    if newkey == key:\n",
    "        print(len(edge_index[0,:].unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_n_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_firsthop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_and_firsthop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_n_genes - total_tf - total_firsthop + tf_and_firsthop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(edge_index_flat[0, :] == 10612).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro.hgnc2id[\"PARK7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data.y.nonzero().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Edge Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "genes = []\n",
    "edge_attributions = []\n",
    "\n",
    "for gene in [prepro.id2hgnc[idx.item()] for idx in coregenes.nonzero()]:\n",
    "    try:\n",
    "        edge_attributions.append(torch.load(\"/mnt/storage/speos/explanations/uc_film_nohetio_ig_attr_edge_total_{}.pt\".format(gene)).detach().float().cpu().numpy())\n",
    "        genes.append(gene)\n",
    "    except (FileNotFoundError, RuntimeError):\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edge_attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "edge_df = pd.DataFrame({\"from\": edge_index.storage.row().tolist(),\n",
    "                        \"to\": edge_index.storage.col().tolist(),\n",
    "                        \"type\":  encoder.inverse_transform(edge_index.storage.value().long().tolist()).tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attributions = np.asarray(edge_attributions)\n",
    "edge_attributions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attributions_tensor = torch.Tensor(edge_attributions.max(axis=0))\n",
    "torch.save(edge_attributions_tensor, \"edge_attributions_tensor_UC.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(edge_attributions > 0.01).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "edge_df[\"avg_attr\"] = edge_attributions.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df[\"avg_attr\"].sort_values(ascending=False)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_edges = {}\n",
    "\n",
    "for i, gene in enumerate(genes):\n",
    "    important_indices = (edge_attributions[i, :] > 0.9).nonzero()[0]\n",
    "    important_edges[gene] = important_indices, edge_attributions[i, :][important_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"disease_network_09.txt\", \"w\") as file:\n",
    "    for gene, (indices, values) in important_edges.items():\n",
    "        file.writelines(\"{}\\t{}\\t{}\\t{}\\n\".format(prepro.id2hgnc[sender], prepro.id2hgnc[receiver], edgetype, value) for sender, receiver, edgetype, value in zip(edge_df[\"from\"][indices], edge_df[\"to\"][indices], edge_df[\"type\"][indices], values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "count_dfs = []\n",
    "total_counts = []\n",
    "num_genes = []\n",
    "\n",
    "for level in [\"75\", \"5\", \"25\", \"1\", \"01\"]:\n",
    "    disease_edges = pd.read_csv(\"disease_network_0{}.txt\".format(level), sep=\"\\t\", index_col=False, header=None, names=[\"from\", \"to\", \"type\", \"weight\"])\n",
    "    disease_edges = disease_edges.groupby([\"from\", \"to\", \"type\"]).agg(\"max\").reset_index()\n",
    "    counter = Counter(disease_edges[\"type\"])\n",
    "    count_df = pd.DataFrame.from_dict(counter, orient=\"index\", columns=[level])\n",
    "    count_df[level] /= count_df[level].sum()\n",
    "    count_dfs.append(count_df)\n",
    "    total_counts.append(len(disease_edges))\n",
    "\n",
    "    num_genes.append(len(set(disease_edges[\"to\"].tolist()).union(set(disease_edges[\"from\"].tolist()))))\n",
    "\n",
    "count_dfs = pd.concat(count_dfs, axis=1, join=\"outer\").fillna(0).sort_values(by=\"75\", ascending=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dfs[\"0\"] = [dataset.data.edge_index_dict[(\"gene\", adj, \"gene\")].shape[1] for adj in count_dfs.index]\n",
    "total_counts.append(count_dfs[\"0\"].sum())\n",
    "count_dfs[\"0\"] /= count_dfs[\"0\"].sum()\n",
    "\n",
    "num_genes.append(edge_index_flat.flatten().unique().shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dfs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_names = {\n",
    "    \"BioPlex30293T\": \"BioPlex 3.0 HEK293T\",\n",
    "    \"BioPlex30HCT116\": \"BioPlex 3.0 HCT116\",\n",
    "    \"HuRI\": \"HuRI\",\n",
    "    'GRNDBadrenalgland': 'GRNDB Adrenal Gland',\n",
    "    'GRNDBbloodvessel': \"GRNDB Blood Vessel\",\n",
    "    'Recon3DDirected': \"Recon 3D\",\n",
    "    'GRNDBsalivarygland': \"GRNDB Salivary Gland\", \n",
    "    'GRNDBsmallintestine': \"GRNDB Small Intestine\", \n",
    "    'GRNDButerus': \"GRNDB Uterus\",\n",
    "    'GRNDBadiposetissue': 'GRNDB Adipose Tissue', \n",
    "    'GRNDBthyroid': 'GRNDB Thyroid', \n",
    "    'GRNDBstomach': \"GRNDB Stomach\", \n",
    "    'GRNDBcolon': \"GRNDB Colon\",\n",
    "    'GRNDBovary': \"GRNDB Ovary\", \n",
    "    'GRNDBpituitary': \"GRNDB Pituitary\", \n",
    "    'GRNDBesophagus': \"GRNDB Esophagus\", \n",
    "    'GRNDBbrain': \"GRNDB Brain\",\n",
    "    'GRNDBliver': \"GRNDB Liver\", \n",
    "    'GRNDBprostate': 'GRNDB Prostate', \n",
    "    'GRNDBheart': 'GRNDB Heart', \n",
    "    'GRNDBmuscle': 'GRNDB Muscle',\n",
    "    'GRNDBkidney': \"GRNDB Kidney\",\n",
    "    'GRNDBnerve': 'GRNDB Nerve', \n",
    "    'GRNDBbreast': \"GRNDB Breast\", \n",
    "    'GRNDBpancreas': \"GRNDB Pancreas\",\n",
    "    'GRNDBtestis': \"GRNDB Testis\", \n",
    "    'GRNDBspleen': \"GRNDB Spleen\", \n",
    "    'GRNDBlung': \"GRNDB Lung\", \n",
    "    'GRNDBbloodx': \"GRNDB Blood\", \n",
    "    'GRNDBskin': \"GRNDB Skin\",\n",
    "    'GRNDBvagina': \"GRNDB Vagina\"\n",
    "}\n",
    "\n",
    "class ColorCycler:\n",
    "    def __init__(self, colors):\n",
    "        self.state = 0\n",
    "        self.colors = colors\n",
    "\n",
    "    def next(self):\n",
    "        color = self.colors[self.state]\n",
    "        if self.state == len(self.colors) - 1:\n",
    "            self.state = 0\n",
    "        else:\n",
    "            self.state += 1\n",
    "        return color\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speos.visualization.settings import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#cycler = ColorCycler([\"#01016f\", \"#89006b\", \"#d00053\", \"#f85732\", \"#ffa600\"])\n",
    "\n",
    "cycler = ColorCycler([\"#000066\", \"#640069\", \"#9e0061\", \"#cc0052\", \"#eb3a3e\", \"#fc7225\", \"#ffa600\"])\n",
    "\n",
    "fig, (ax0, ax) = plt.subplots(nrows=2, figsize=(full_width*cm*0.5, 10*cm), sharex=True, gridspec_kw={'height_ratios': [1, 3]})\n",
    "\n",
    "running = np.zeros((len(count_dfs.columns),))\n",
    "\n",
    "ax0.plot(range(len(running)), num_genes, color=\"gray\")\n",
    "ax0.fill_between(range(len(running)), running, running+np.asarray(num_genes), color=\"gray\", alpha=1)\n",
    "ax0.set_ylabel(\"Genes\")\n",
    "ax0.set_ylim(bottom=0)\n",
    "ax1 = ax0.twinx()\n",
    "ax1.set_ylabel(\"% of Total\\nNetwork\")\n",
    "ax1.set_ylim((0,1))\n",
    "ax1.set_yticks((0, 0.2, 0.4, 0.6, 0.8, 1))\n",
    "ax1.set_yticklabels((0, 20, 40, 60, 80, 100))\n",
    "ax1.grid(axis=\"y\", zorder=-5, linestyle=\":\")\n",
    "\n",
    "\n",
    "for i, (idx, row) in enumerate(count_dfs.iterrows()):\n",
    "    color = cycler.next()\n",
    "    #line = ax.plot(range(len(running)), running+row.values, linewidth=1, color=color)\n",
    "    ax.fill_between(range(len(running)), running, running+row.values, color=color, alpha=1)\n",
    "    running += row.values\n",
    "    ax.text(x=5.05, ha=\"left\", y=i/len(count_dfs.index), s=pretty_names[idx], color=color, fontsize=5)\n",
    "\n",
    "ax.set_xticks((0,1,2,3,4, 5))\n",
    "ax.set_xticklabels([\"{}\\n(n={})\".format(importance, num_edges) for importance, num_edges in  zip((\".75\", \".5\", \".25\", \".1\", \".01\", \"0\"), total_counts)])\n",
    "ax.set_xlim((0,5))\n",
    "ax.set_ylim((0,1))\n",
    "ax.set_yticks((0, 0.2, 0.4, 0.6, 0.8, 1))\n",
    "ax.set_yticklabels((0, 20, 40, 60, 80, 100))\n",
    "ax.set_xlabel(\"Attributed Importance (>=)\\n(Number of Edges)\")\n",
    "ax.set_ylabel(\"Percentage of Subnetwork\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0.05)\n",
    "plt.savefig(\"edge_importance_cycler2.svg\", dpi=450, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_edges_grouped = disease_edges.groupby([\"from\", \"to\", \"type\"]).agg(\"max\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_edges_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(disease_edges_grouped[\"from\"].tolist() + disease_edges_grouped[\"to\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "disease_network = nx.MultiDiGraph()\n",
    "\n",
    "for i, edge in disease_edges_grouped.iterrows():\n",
    "    disease_network.add_edges_from(((edge[0], edge[1], edge[2]),), weight=[edge[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_network[\"IRF3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(nx.connected_components(nx.MultiGraph(disease_network))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(disease_edges_grouped[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_edges = pd.read_csv(\"disease_network_075.txt\", sep=\"\\t\", index_col=False, header=None, names=[\"from\", \"to\", \"type\", \"weight\"])\n",
    "disease_edges = disease_edges.groupby([\"from\", \"to\", \"type\"]).agg(\"max\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_edges.sort_values(\"weight\")[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro.hgnc2id[\"LEMD3\"] in coregenes.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
