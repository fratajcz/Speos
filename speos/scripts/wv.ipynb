{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wv = KeyedVectors.load(\"~/ppi-core-genes/data/walking.output\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.74105393],\n",
       "       [0.74105393, 1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(wv[\"NDUFA1\"].T, wv[\"NDUFA2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.3051454],\n",
       "       [0.3051454, 1.       ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(wv[\"NDUFA1\"].T, wv[\"MTOR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv[wv.index_to_key[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist = pd.read_csv(\"~/ppi-core-genes/data/ppi/bioplex_hgnc_only.tsv\",sep=\"\\t\",names=[\"source\",\"target\"])\n",
    "graph = nx.from_pandas_edgelist(edgelist,create_using=nx.Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Graph with 13957 nodes and 118162 edges'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import Mapper, Preprocessor\n",
    "from src.utils.config import Config\n",
    "from src.utils.metrics import *\n",
    "from src.utils.rank_metrics import *\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, RandomForestRegressor,BaggingRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = Mapper(config.input.gene_sets,config.input.gwas).get_mappings(config.input.tag, field = config.input.field)\n",
    "preprocessor = Preprocessor(mappings)\n",
    "X, y, _ = preprocessor.get_data(use_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noemb = X[:,:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricHelper = MetricsHelper(y,masks={},pred_cutoff=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'class_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/icb/florin.ratajczak/ppi-core-genes/src/scripts/wv.ipynb Cell 15'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvicb-submit-01.scidom.de/home/icb/florin.ratajczak/ppi-core-genes/src/scripts/wv.ipynb#ch0000014vscode-remote?line=2'>3</a>\u001b[0m tests \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvicb-submit-01.scidom.de/home/icb/florin.ratajczak/ppi-core-genes/src/scripts/wv.ipynb#ch0000014vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (train, test) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(skf\u001b[39m.\u001b[39msplit(X, y)):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvicb-submit-01.scidom.de/home/icb/florin.ratajczak/ppi-core-genes/src/scripts/wv.ipynb#ch0000014vscode-remote?line=4'>5</a>\u001b[0m     clf \u001b[39m=\u001b[39m RandomForestRegressor(max_depth\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, oob_score\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, class_weight\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbalanced\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mfit(X[train], y[train])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvicb-submit-01.scidom.de/home/icb/florin.ratajczak/ppi-core-genes/src/scripts/wv.ipynb#ch0000014vscode-remote?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(clf\u001b[39m.\u001b[39moob_score_)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvicb-submit-01.scidom.de/home/icb/florin.ratajczak/ppi-core-genes/src/scripts/wv.ipynb#ch0000014vscode-remote?line=6'>7</a>\u001b[0m     mask_key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i)\n",
      "File \u001b[0;32m~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sklearn/utils/validation.py?line=60'>61</a>\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sklearn/utils/validation.py?line=61'>62</a>\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sklearn/utils/validation.py?line=62'>63</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sklearn/utils/validation.py?line=64'>65</a>\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sklearn/utils/validation.py?line=65'>66</a>\u001b[0m args_msg \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sklearn/utils/validation.py?line=66'>67</a>\u001b[0m             \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sklearn/utils/validation.py?line=67'>68</a>\u001b[0m                                  args[\u001b[39m-\u001b[39mextra_args:])]\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'class_weight'"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=4)\n",
    "predicted_probas = []\n",
    "tests = []\n",
    "for i, (train, test) in enumerate(skf.split(X, y)):\n",
    "    clf = RandomForestClassifier(max_depth=100, random_state=0, oob_score=True, class_weight=\"balanced\").fit(X[train], y[train])\n",
    "    print(clf.oob_score_)\n",
    "    mask_key = \"split{}\".format(i)\n",
    "    metricHelper.masks.update({mask_key: test})\n",
    "    predicted_proba = np.log(clf.predict_proba(X[test])+1e-32)[:,1]\n",
    "    predicted_probas.extend(predicted_proba.tolist())\n",
    "    tests.extend(test.tolist())\n",
    "    metricHelper.update(predicted_proba, mask_key)\n",
    "    probability, prediction, accuracy, recall, precision,auroc, auprc, f1, mrr = metricHelper.get_metrics(\"probability\", \"prediction\", \"accuracy\", \"recall\", \"precision\", \"auroc\", \"auprc\", \"f1\", \"mrr\")\n",
    "    print(\"Accuracy: {}, Recall: {}, Precision: {}, AUROC: {}, AUPRC: {}, F1: {}, MRR: {}, Target: {}\".format(accuracy, recall, precision, auroc, auprc, f1, mrr, mask_key))\n",
    "\n",
    "sorted_indices, sorted_probas = zip(*sorted(zip(tests,predicted_probas)))\n",
    "metricHelper.update(np.asarray(sorted_probas), \"all\")\n",
    "probability, prediction, accuracy, recall, precision,auroc, auprc, f1, mrr = metricHelper.get_metrics(\"probability\", \"prediction\", \"accuracy\", \"recall\", \"precision\", \"auroc\", \"auprc\", \"f1\", \"mrr\")\n",
    "print(\"Accuracy: {}, Recall: {}, Precision: {}, AUROC: {}, AUPRC: {}, F1: {}, MRR: {}, Target: {}\".format(accuracy, recall, precision, auroc, auprc, f1, mrr, \"all\"))\n",
    "ranking = np.argsort(sorted_probas)[::-1]\n",
    "ordered_truth_val = np.take_along_axis(y, ranking, axis=0)\n",
    "get_metrics([ordered_truth_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0024651262563888388\n",
      "Accuracy: 0.9678753954733512, Recall: 0.0, Precision: 0.0, AUROC: 0.691199777508553, AUPRC: 0.08119632681880311, F1: 0.0, MRR: 0.010949548395070226, Target: split0\n",
      "0.003385120324312596\n",
      "Accuracy: 0.9681110029211295, Recall: 0.0, Precision: 0.0, AUROC: 0.6423154512492634, AUPRC: 0.07094565670256417, F1: 0.0, MRR: 0.005925695586192437, Target: split1\n",
      "0.003624660558230852\n",
      "Accuracy: 0.9681110029211295, Recall: 0.0, Precision: 0.0, AUROC: 0.6112628530078486, AUPRC: 0.05752360455864895, F1: 0.0, MRR: 0.003867986755502078, Target: split2\n",
      "0.00365368148398848\n",
      "Accuracy: 0.9681110029211295, Recall: 0.0, Precision: 0.0, AUROC: 0.6414804975939898, AUPRC: 0.06675947085948448, F1: 0.0, MRR: 0.005360598945629266, Target: split3\n",
      "Accuracy: 0.9680520903060914, Recall: 0.0, Precision: 0.0, AUROC: 0.6332571811726954, AUPRC: 0.06527769671736518, F1: 0.0, MRR: 0.0018437209702388976, Target: all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15892/1716292592.py:53: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  total_after = np.sum(np.sum(r) for r in rs_filtered)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0018437209702388976,\n",
       " 0.0019765702400485873,\n",
       " 6104.346666666666,\n",
       " 5842.346666666666,\n",
       " 0.0019047619047619048,\n",
       " 0.0019047619047619048,\n",
       " 0.0019047619047619048,\n",
       " 0.0019047619047619048,\n",
       " 0.005714285714285714,\n",
       " 0.005714285714285714,\n",
       " 0.011428571428571429,\n",
       " 0.10857142857142857)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=4)\n",
    "predicted_probas = []\n",
    "tests = []\n",
    "for i, (train, test) in enumerate(skf.split(X, y)):\n",
    "    clf = RandomForestRegressor(max_depth=10, random_state=0, oob_score=True,n_estimators=100).fit(X[train], y[train])\n",
    "    print(clf.oob_score_)\n",
    "    mask_key = \"split{}\".format(i)\n",
    "    metricHelper.masks.update({mask_key: test})\n",
    "    predicted_proba = np.log(clf.predict(X[test])+1e-32)\n",
    "    predicted_probas.extend(predicted_proba.tolist())\n",
    "    tests.extend(test.tolist())\n",
    "    metricHelper.update(predicted_proba, mask_key)\n",
    "    probability, prediction, accuracy, recall, precision,auroc, auprc, f1, mrr = metricHelper.get_metrics(\"probability\", \"prediction\", \"accuracy\", \"recall\", \"precision\", \"auroc\", \"auprc\", \"f1\", \"mrr\")\n",
    "    print(\"Accuracy: {}, Recall: {}, Precision: {}, AUROC: {}, AUPRC: {}, F1: {}, MRR: {}, Target: {}\".format(accuracy, recall, precision, auroc, auprc, f1, mrr, mask_key))\n",
    "\n",
    "sorted_indices, sorted_probas = zip(*sorted(zip(tests,predicted_probas)))\n",
    "metricHelper.update(np.asarray(sorted_probas), \"all\")\n",
    "probability, prediction, accuracy, recall, precision,auroc, auprc, f1, mrr = metricHelper.get_metrics(\"probability\", \"prediction\", \"accuracy\", \"recall\", \"precision\", \"auroc\", \"auprc\", \"f1\", \"mrr\")\n",
    "print(\"Accuracy: {}, Recall: {}, Precision: {}, AUROC: {}, AUPRC: {}, F1: {}, MRR: {}, Target: {}\".format(accuracy, recall, precision, auroc, auprc, f1, mrr, \"all\"))\n",
    "ranking = np.argsort(sorted_probas)[::-1]\n",
    "ordered_truth_val = np.take_along_axis(y, ranking, axis=0)\n",
    "get_metrics([ordered_truth_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9678753954733512, Recall: 0.0, Precision: 0.0, AUROC: 0.5997020748089393, AUPRC: 0.06817807410334853, F1: 0.0, MRR: 0.012231965429480999, Target: split0\n",
      "Accuracy: 0.9681110029211295, Recall: 0.0, Precision: 0.0, AUROC: 0.5767648712923739, AUPRC: 0.05394504848933844, F1: 0.0, MRR: 0.005632910586311973, Target: split1\n",
      "Accuracy: 0.9681110029211295, Recall: 0.0, Precision: 0.0, AUROC: 0.555011929280385, AUPRC: 0.05001954201187257, F1: 0.0, MRR: 0.002818419867800991, Target: split2\n",
      "Accuracy: 0.9681110029211295, Recall: 0.0, Precision: 0.0, AUROC: 0.6015082909938252, AUPRC: 0.06362872728424708, F1: 0.0, MRR: 0.0038770293652761927, Target: split3\n",
      "Accuracy: 0.9680520903060914, Recall: 0.0, Precision: 0.0, AUROC: 0.583235149729995, AUPRC: 0.05424950329094309, F1: 0.0, MRR: 0.0016032998754804244, Target: all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15892/1716292592.py:53: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  total_after = np.sum(np.sum(r) for r in rs_filtered)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0016032998754804244,\n",
       " 0.001686632868121468,\n",
       " 6892.897142857143,\n",
       " 6630.897142857143,\n",
       " 0.0019047619047619048,\n",
       " 0.0019047619047619048,\n",
       " 0.0019047619047619048,\n",
       " 0.0019047619047619048,\n",
       " 0.0038095238095238095,\n",
       " 0.0038095238095238095,\n",
       " 0.009523809523809525,\n",
       " 0.10857142857142857)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "skf = StratifiedKFold(n_splits=4)\n",
    "predicted_probas = []\n",
    "tests = []\n",
    "for i, (train, test) in enumerate(skf.split(X, y)):\n",
    "    clf = BaggingRegressor(base_estimator=SVR(), n_estimators=100, random_state=0).fit(X[train], y[train])\n",
    "    mask_key = \"split{}\".format(i)\n",
    "    metricHelper.masks.update({mask_key: test})\n",
    "    predicted_proba = np.log(clf.predict(X[test])+1e-32)\n",
    "    predicted_probas.extend(predicted_proba.tolist())\n",
    "    tests.extend(test.tolist())\n",
    "    metricHelper.update(predicted_proba, mask_key)\n",
    "    probability, prediction, accuracy, recall, precision,auroc, auprc, f1, mrr = metricHelper.get_metrics(\"probability\", \"prediction\", \"accuracy\", \"recall\", \"precision\", \"auroc\", \"auprc\", \"f1\", \"mrr\")\n",
    "    print(\"Accuracy: {}, Recall: {}, Precision: {}, AUROC: {}, AUPRC: {}, F1: {}, MRR: {}, Target: {}\".format(accuracy, recall, precision, auroc, auprc, f1, mrr, mask_key))\n",
    "\n",
    "sorted_indices, sorted_probas = zip(*sorted(zip(tests,predicted_probas)))\n",
    "metricHelper.update(np.asarray(sorted_probas), \"all\")\n",
    "probability, prediction, accuracy, recall, precision,auroc, auprc, f1, mrr = metricHelper.get_metrics(\"probability\", \"prediction\", \"accuracy\", \"recall\", \"precision\", \"auroc\", \"auprc\", \"f1\", \"mrr\")\n",
    "print(\"Accuracy: {}, Recall: {}, Precision: {}, AUROC: {}, AUPRC: {}, F1: {}, MRR: {}, Target: {}\".format(accuracy, recall, precision, auroc, auprc, f1, mrr, \"all\"))\n",
    "ranking = np.argsort(sorted_probas)[::-1]\n",
    "ordered_truth_val = np.take_along_axis(y, ranking, axis=0)\n",
    "get_metrics([ordered_truth_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9678753954733512, Recall: 0.0, Precision: 0.0, AUROC: 0.553662727348923, AUPRC: 0.059093107251652496, F1: 0.0, MRR: 0.011727061472681401, Target: split0\n",
      "Accuracy: 0.9681110029211295, Recall: 0.0, Precision: 0.0, AUROC: 0.5459809937675988, AUPRC: 0.048356044359869045, F1: 0.0, MRR: 0.005329050186394648, Target: split1\n",
      "Accuracy: 0.9681110029211295, Recall: 0.0, Precision: 0.0, AUROC: 0.5317944593627095, AUPRC: 0.04314212378183076, F1: 0.0, MRR: 0.0024338278293824047, Target: split2\n",
      "Accuracy: 0.9681110029211295, Recall: 0.0, Precision: 0.0, AUROC: 0.5836364439035907, AUPRC: 0.058350027136052876, F1: 0.0, MRR: 0.0036665974626101674, Target: split3\n",
      "Accuracy: 0.9680520903060914, Recall: 0.0, Precision: 0.0, AUROC: 0.5525737275045799, AUPRC: 0.0481245251012677, F1: 0.0, MRR: 0.001540585457331143, Target: all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15892/1716292592.py:53: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  total_after = np.sum(np.sum(r) for r in rs_filtered)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.001540585457331143,\n",
       " 0.0016139647051052607,\n",
       " 7380.657142857143,\n",
       " 7118.657142857143,\n",
       " 0.0019047619047619048,\n",
       " 0.0019047619047619048,\n",
       " 0.0019047619047619048,\n",
       " 0.0019047619047619048,\n",
       " 0.0038095238095238095,\n",
       " 0.0038095238095238095,\n",
       " 0.011428571428571429,\n",
       " 0.0838095238095238)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "skf = StratifiedKFold(n_splits=4)\n",
    "predicted_probas = []\n",
    "tests = []\n",
    "for i, (train, test) in enumerate(skf.split(X_noemb, y)):\n",
    "    clf = BaggingRegressor(base_estimator=SVR(), n_estimators=100, random_state=0).fit(X_noemb[train], y[train])\n",
    "    mask_key = \"split{}\".format(i)\n",
    "    metricHelper.masks.update({mask_key: test})\n",
    "    predicted_proba = np.log(clf.predict(X_noemb[test])+1e-32)\n",
    "    predicted_probas.extend(predicted_proba.tolist())\n",
    "    tests.extend(test.tolist())\n",
    "    metricHelper.update(predicted_proba, mask_key)\n",
    "    probability, prediction, accuracy, recall, precision,auroc, auprc, f1, mrr = metricHelper.get_metrics(\"probability\", \"prediction\", \"accuracy\", \"recall\", \"precision\", \"auroc\", \"auprc\", \"f1\", \"mrr\")\n",
    "    print(\"Accuracy: {}, Recall: {}, Precision: {}, AUROC: {}, AUPRC: {}, F1: {}, MRR: {}, Target: {}\".format(accuracy, recall, precision, auroc, auprc, f1, mrr, mask_key))\n",
    "\n",
    "sorted_indices, sorted_probas = zip(*sorted(zip(tests,predicted_probas)))\n",
    "metricHelper.update(np.asarray(sorted_probas), \"all\")\n",
    "probability, prediction, accuracy, recall, precision,auroc, auprc, f1, mrr = metricHelper.get_metrics(\"probability\", \"prediction\", \"accuracy\", \"recall\", \"precision\", \"auroc\", \"auprc\", \"f1\", \"mrr\")\n",
    "print(\"Accuracy: {}, Recall: {}, Precision: {}, AUROC: {}, AUPRC: {}, F1: {}, MRR: {}, Target: {}\".format(accuracy, recall, precision, auroc, auprc, f1, mrr, \"all\"))\n",
    "ranking = np.argsort(sorted_probas)[::-1]\n",
    "ordered_truth_val = np.take_along_axis(y, ranking, axis=0)\n",
    "get_metrics([ordered_truth_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del TreeRankForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sandbox.ranking.TreeRankForest import TreeRankForest\n",
    "from sandbox.ranking.leafrank.DecisionTree import DecisionTree\n",
    "\n",
    "rf = TreeRankForest(DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree: 0 (0.000)"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'Orange' has no attribute 'Preprocessor_addClassWeight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/icb/florin.ratajczak/ppi-core-genes/src/scripts/wv.ipynb Cell 21'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvicb-submit-01.scidom.de/home/icb/florin.ratajczak/ppi-core-genes/src/scripts/wv.ipynb#ch0000025vscode-remote?line=4'>5</a>\u001b[0m y_ranking[y_ranking \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvicb-submit-01.scidom.de/home/icb/florin.ratajczak/ppi-core-genes/src/scripts/wv.ipynb#ch0000025vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (train, test) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(skf\u001b[39m.\u001b[39msplit(X_noemb, y)):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvicb-submit-01.scidom.de/home/icb/florin.ratajczak/ppi-core-genes/src/scripts/wv.ipynb#ch0000025vscode-remote?line=6'>7</a>\u001b[0m     rf \u001b[39m=\u001b[39m TreeRankForest(DecisionTree())\u001b[39m.\u001b[39;49mlearnModel(X_noemb[train], y[train])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvicb-submit-01.scidom.de/home/icb/florin.ratajczak/ppi-core-genes/src/scripts/wv.ipynb#ch0000025vscode-remote?line=7'>8</a>\u001b[0m     \u001b[39mprint\u001b[39m(clf\u001b[39m.\u001b[39moob_score_)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvicb-submit-01.scidom.de/home/icb/florin.ratajczak/ppi-core-genes/src/scripts/wv.ipynb#ch0000025vscode-remote?line=8'>9</a>\u001b[0m     mask_key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i)\n",
      "File \u001b[0;32m~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRankForest.py:93\u001b[0m, in \u001b[0;36mTreeRankForest.learnModel\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRankForest.py?line=90'>91</a>\u001b[0m treeRank\u001b[39m.\u001b[39msetFeatureSize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatureSize)\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRankForest.py?line=91'>92</a>\u001b[0m treeRank\u001b[39m.\u001b[39msetBestResponse(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbestResponse)\n\u001b[0;32m---> <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRankForest.py?line=92'>93</a>\u001b[0m treeRank\u001b[39m.\u001b[39;49mlearnModel(X[inds, :], y[inds])\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRankForest.py?line=93'>94</a>\u001b[0m forestList\u001b[39m.\u001b[39mappend(treeRank)\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRankForest.py?line=94'>95</a>\u001b[0m indList\u001b[39m.\u001b[39mappend(inds)\n",
      "File \u001b[0;32m~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRank.py:147\u001b[0m, in \u001b[0;36mTreeRank.learnModel\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRank.py?line=143'>144</a>\u001b[0m             node \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39mgetVertex((d, k))\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRank.py?line=145'>146</a>\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m node\u001b[39m.\u001b[39misPure() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m node\u001b[39m.\u001b[39misLeafNode():\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRank.py?line=146'>147</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplitNode(tree, X, Y, d, k)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRank.py?line=148'>149</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree \u001b[39m=\u001b[39m tree\n",
      "File \u001b[0;32m~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRank.py:76\u001b[0m, in \u001b[0;36mTreeRank.splitNode\u001b[0;34m(self, tree, X, Y, d, k)\u001b[0m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRank.py?line=73'>74</a>\u001b[0m \u001b[39mif\u001b[39;00m Util\u001b[39m.\u001b[39mhistogram(Y[inds])[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmin() \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mminLabelCount:\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRank.py?line=74'>75</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleafRanklearner\u001b[39m.\u001b[39msetWeight(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39malpha)\n\u001b[0;32m---> <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRank.py?line=75'>76</a>\u001b[0m     leafRank \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleafRanklearner\u001b[39m.\u001b[39;49mgenerateLearner(X, Y)\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRank.py?line=76'>77</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/TreeRank.py?line=77'>78</a>\u001b[0m     leafRank \u001b[39m=\u001b[39m MajorityPredictor()\n",
      "File \u001b[0;32m~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py:132\u001b[0m, in \u001b[0;36mDecisionTree.generateLearner\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py?line=129'>130</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampleSize \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m: \n\u001b[1;32m    <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py?line=130'>131</a>\u001b[0m     idx \u001b[39m=\u001b[39m Sampling\u001b[39m.\u001b[39mcrossValidation(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfolds, X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py?line=131'>132</a>\u001b[0m     learner, meanErrors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallelModelSelect(X, y, idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparamDict)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py?line=132'>133</a>\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[1;32m    <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py?line=133'>134</a>\u001b[0m     idx \u001b[39m=\u001b[39m Sampling\u001b[39m.\u001b[39mcrossValidation(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfolds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampleSize)\n",
      "File \u001b[0;32m~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py:367\u001b[0m, in \u001b[0;36mAbstractPredictor.parallelModelSelect\u001b[0;34m(self, X, y, idx, paramDict)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py?line=364'>365</a>\u001b[0m     indexIter \u001b[39m=\u001b[39m itertools\u001b[39m.\u001b[39mproduct(\u001b[39m*\u001b[39mgridInds)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py?line=365'>366</a>\u001b[0m     \u001b[39mfor\u001b[39;00m inds \u001b[39min\u001b[39;00m indexIter: \n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py?line=366'>367</a>\u001b[0m         error \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(resultsIterator)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py?line=367'>368</a>\u001b[0m         meanErrors[inds] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m error\u001b[39m/\u001b[39m\u001b[39mfloat\u001b[39m(folds)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py?line=369'>370</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocesses \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py:26\u001b[0m, in \u001b[0;36mcomputeTestError\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py?line=20'>21</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py?line=21'>22</a>\u001b[0m \u001b[39mUsed in conjunction with the parallel model selection. Trains and then tests\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py?line=22'>23</a>\u001b[0m \u001b[39mon a seperate test set. \u001b[39;00m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py?line=23'>24</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py?line=24'>25</a>\u001b[0m (trainX, trainY, testX, testY, learner) \u001b[39m=\u001b[39m args\n\u001b[0;32m---> <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py?line=25'>26</a>\u001b[0m learner\u001b[39m.\u001b[39;49mlearnModel(trainX, trainY)\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py?line=26'>27</a>\u001b[0m predY \u001b[39m=\u001b[39m learner\u001b[39m.\u001b[39mpredict(testX)\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/predictors/AbstractPredictor.py?line=28'>29</a>\u001b[0m \u001b[39mreturn\u001b[39;00m learner\u001b[39m.\u001b[39mgetMetricMethod()(testY, predY)\n",
      "File \u001b[0;32m~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py:70\u001b[0m, in \u001b[0;36mDecisionTree.learnModel\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py?line=64'>65</a>\u001b[0m eTable \u001b[39m=\u001b[39m Table\u001b[39m.\u001b[39mfrom_numpy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdomain, XY)\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py?line=66'>67</a>\u001b[0m \u001b[39m#Weight examples and equalise\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py?line=67'>68</a>\u001b[0m \u001b[39m#Equalizing computes such weights that the weighted number of examples\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py?line=68'>69</a>\u001b[0m \u001b[39m#in each class is equivalent.\u001b[39;00m\n\u001b[0;32m---> <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py?line=69'>70</a>\u001b[0m preprocessor \u001b[39m=\u001b[39m orange\u001b[39m.\u001b[39;49mPreprocessor_addClassWeight(equalize\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py?line=70'>71</a>\u001b[0m preprocessor\u001b[39m.\u001b[39mclassWeights \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight]\n\u001b[1;32m     <a href='file:///~/anaconda3/envs/pygeo/lib/python3.8/site-packages/sandbox-0.1-py3.8-linux-x86_64.egg/sandbox/ranking/leafrank/DecisionTree.py?line=71'>72</a>\u001b[0m eTable, weightID \u001b[39m=\u001b[39m preprocessor(eTable)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'Orange' has no attribute 'Preprocessor_addClassWeight'"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=4)\n",
    "predicted_probas = []\n",
    "tests = []\n",
    "y_ranking = y[:]\n",
    "y_ranking[y_ranking == 0] = -1\n",
    "for i, (train, test) in enumerate(skf.split(X_noemb, y)):\n",
    "    rf = TreeRankForest(DecisionTree()).learnModel(X_noemb[train], y[train])\n",
    "    print(clf.oob_score_)\n",
    "    mask_key = \"split{}\".format(i)\n",
    "    metricHelper.masks.update({mask_key: test})\n",
    "    predicted_proba = np.log(clf.predict(X[test])+1e-32)[:,1]\n",
    "    predicted_probas.extend(predicted_proba.tolist())\n",
    "    tests.extend(test.tolist())\n",
    "    metricHelper.update(predicted_proba, mask_key)\n",
    "    probability, prediction, accuracy, recall, precision,auroc, auprc, f1, mrr = metricHelper.get_metrics(\"probability\", \"prediction\", \"accuracy\", \"recall\", \"precision\", \"auroc\", \"auprc\", \"f1\", \"mrr\")\n",
    "    print(\"Accuracy: {}, Recall: {}, Precision: {}, AUROC: {}, AUPRC: {}, F1: {}, MRR: {}, Target: {}\".format(accuracy, recall, precision, auroc, auprc, f1, mrr, mask_key))\n",
    "\n",
    "sorted_indices, sorted_probas = zip(*sorted(zip(tests,predicted_probas)))\n",
    "metricHelper.update(np.asarray(sorted_probas), \"all\")\n",
    "probability, prediction, accuracy, recall, precision,auroc, auprc, f1, mrr = metricHelper.get_metrics(\"probability\", \"prediction\", \"accuracy\", \"recall\", \"precision\", \"auroc\", \"auprc\", \"f1\", \"mrr\")\n",
    "print(\"Accuracy: {}, Recall: {}, Precision: {}, AUROC: {}, AUPRC: {}, F1: {}, MRR: {}, Target: {}\".format(accuracy, recall, precision, auroc, auprc, f1, mrr, \"all\"))\n",
    "ranking = np.argsort(sorted_probas)[::-1]\n",
    "ordered_truth_val = np.take_along_axis(y, ranking, axis=0)\n",
    "get_metrics([ordered_truth_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_monotonic_increasing(array):\n",
    "    for i in range(len(array)-1):\n",
    "        try:\n",
    "            assert array[i] < array[i+1]\n",
    "        except AssertionError:\n",
    "            print(\"Not monotonic increasing between indices {} and {}: {}, {}\".format(i,i+1,array[i],array[i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_monotonic_increasing(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(rs, additional_truth=None, get_hits=[]):\n",
    "        \"\"\"Score is reciprocal of the rank of the first relevant item\n",
    "        First element is 'rank 1'.  Relevance is binary (nonzero is relevant).\n",
    "        Example from http://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
    "        >>> rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "        >>> mean_reciprocal_rank(rs)\n",
    "        0.61111111111111105\n",
    "        >>> rs = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0]])\n",
    "        >>> mean_reciprocal_rank(rs)\n",
    "        0.5\n",
    "        >>> rs = [[0, 0, 0, 1], [1, 0, 0], [1, 0, 0]]\n",
    "        >>> mean_reciprocal_rank(rs)\n",
    "        0.75\n",
    "        Args:\n",
    "            rs: Iterator of relevance scores (list or numpy) in rank order\n",
    "                (first element is the first item)\n",
    "        Returns:\n",
    "            Mean reciprocal rank\n",
    "        \"\"\"\n",
    "        rs_raw = list(np.asarray(r).nonzero()[0] for r in rs if np.sum(r) > 0)\n",
    "        \n",
    "        mrr_raw = np.mean([1. / (r + 1) for sublist in rs_raw for r in sublist]) \n",
    "        mean_rank_raw = np.mean([r + 1 for sublist in rs_raw for r in sublist]) \n",
    "\n",
    "        hitsat5_raw = np.mean([1 if r < 5 else 0 for sublist in rs_raw for r in sublist]) \n",
    "        hitsat10_raw = np.mean([1 if r < 10 else 0 for sublist in rs_raw for r in sublist]) \n",
    "        hitsat20_raw = np.mean([1 if r < 20 else 0 for sublist in rs_raw for r in sublist]) \n",
    "        hitsat50_raw = np.mean([1 if r < 50 else 0 for sublist in rs_raw for r in sublist]) \n",
    "\n",
    "        total_before = np.sum(rs)\n",
    "\n",
    "        rs_filtered = []\n",
    "        if additional_truth is not None:\n",
    "        #if True:\n",
    "            # also remove all known true examples from the other sets\n",
    "            rs_prefiltered = []\n",
    "            for i, additional in enumerate(additional_truth):\n",
    "                to_delete = additional.nonzero()[0]\n",
    "                rs_prefiltered.append(np.delete(rs[i],to_delete)) \n",
    "            \n",
    "            total_after = np.sum(np.sum(r) for r in rs_prefiltered)\n",
    "            assert  total_before == total_after # nothing lost filtering for out-of-sample edges\n",
    "            rs = rs_prefiltered\n",
    "\n",
    "        for r in rs:\n",
    "            while np.sum(r) > 0:\n",
    "                best = r.nonzero()[0][0]\n",
    "                best_r = np.zeros_like(r)\n",
    "                best_r[best] = 1\n",
    "                rs_filtered.append(best_r)\n",
    "                r = np.delete(r, best)\n",
    "\n",
    "        total_after = np.sum(np.sum(r) for r in rs_filtered)\n",
    "        assert total_before == total_after # nothing lost in filtering\n",
    "        assert len(rs_filtered) == total_before # every edge gets its own array\n",
    "        for r in rs_filtered:\n",
    "            assert np.sum(r) == 1 # only one edge in every array\n",
    "\n",
    "        \n",
    "        rs_filtered = list(np.asarray(r).nonzero()[0] for r in rs_filtered if np.sum(r) > 0)\n",
    "        mrr_filtered = np.mean([1. / (r + 1) if r.size else 0. for r in rs_filtered]) \n",
    "        mean_rank_filtered = np.mean([r + 1 if r.size else 0. for r in rs_filtered]) \n",
    "\n",
    "        hitsat5_filtered = np.mean([1 if r < 5 else 0 for sublist in rs_filtered for r in sublist])\n",
    "        hitsat10_filtered = np.mean([1 if r < 10 else 0 for sublist in rs_filtered for r in sublist])\n",
    "        hitsat20_filtered = np.mean([1 if r < 20 else 0 for sublist in rs_filtered for r in sublist]) \n",
    "        hitsat500_filtered = np.mean([1 if r < 500 else 0 for sublist in rs_filtered for r in sublist])\n",
    "\n",
    "        return (mrr_raw, mrr_filtered, mean_rank_raw, mean_rank_filtered, hitsat5_raw, hitsat5_filtered, hitsat10_raw, hitsat10_filtered,\n",
    "            hitsat20_raw, hitsat20_filtered, hitsat50_raw, hitsat500_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99407519f4519b98b376730810e263a694c26610985286a1ae3e6923370f59e8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('n2v')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
